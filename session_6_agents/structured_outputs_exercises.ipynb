{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/agentic-ai-engineering-course/blob/main/session_6_agents/structured_outputs_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry3-Yt0TrcGY"
      },
      "source": [
        "# Structured Outputs\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook teaches you how to reliably extract structured data from Large Language Models (LLMs). Instead of getting free-form text responses, you'll learn to enforce specific data formats that your applications can easily parse and use.\n",
        "\n",
        "**What You'll Learn:**\n",
        "- Why structured outputs are crucial for reliable data extraction from LLMs\n",
        "- How to enforce JSON output formats using prompt engineering techniques\n",
        "- How to leverage Pydantic models for defining and validating complex data structures\n",
        "- How to use Gemini's native structured output capabilities for maximum reliability\n",
        "\n",
        "**What You'll Build:**\n",
        "- A document metadata extractor that returns structured JSON\n",
        "- A Pydantic-based validation system for LLM outputs\n",
        "- A complete structured extraction pipeline using Gemini's native capabilities\n",
        "\n",
        "We will use the `google-genai` library to interact with Google's Gemini models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOy9KMiZkqQ_"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "### Set Up Python Environment\n",
        "\n",
        "Run the following command to install all the required packages to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHVmQx9KkqRA",
        "outputId": "fb135838-df8b-4ba6-ae92-31abacb7750a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.4/275.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.4/108.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m377.2/377.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mgoogle-colab 1.0.0 has requirement requests==2.32.4, but you have requests 2.32.5.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q openai==2.15.0 google-genai==1.55.0 agentic-ai-engineering-course==0.4.6 google-auth==2.43.0 \\\n",
        "  opentelemetry-api==1.37.0 opentelemetry-sdk==1.37.0 opentelemetry-proto==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-http==1.37.0 opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
        "  jedi==0.19.2\n",
        "\n",
        "%pip check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itqfBe69kqRC"
      },
      "source": [
        "### Configure Gemini API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajn_aGRjkqRC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# Try to get API key from Colab secrets, fall back to manual input\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "except Exception:\n",
        "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter Google API Key: \")\n",
        "\n",
        "print(\"[OK] Packages installed and API key configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNxV1h9OkqRC"
      },
      "source": [
        "### Import Key Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VkexZXVkqRD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from utils import pretty_print"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61uRCRaNkqRD"
      },
      "source": [
        "### Initialize the Gemini Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VuBLJO3kqRD"
      },
      "outputs": [],
      "source": [
        "client = genai.Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJgQQMqUkqRF"
      },
      "source": [
        "### Define Constants\n",
        "\n",
        "We will use the `gemini-2.5-flash` model, which is fast and cost-effective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO_bV159kqRF"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV4XllmPkqRH"
      },
      "source": [
        "## 2. Implementing structured outputs from scratch using JSON\n",
        "\n",
        "Sometimes, you don't need the LLM to take an action, but you need its output in a specific, machine-readable format. Forcing the output to be JSON is a common way to achieve this.\n",
        "\n",
        "We can instruct the model to do this by **prompting** clearly describing the desired JSON structure in the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07EqdbRtkqRH"
      },
      "source": [
        "### Example: Extracting Metadata from a Document\n",
        "\n",
        "Let's imagine we have a markdown document and we want to extract key information like a summary, tags, and keywords into a clean JSON object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxbzkgKqkqRI"
      },
      "outputs": [],
      "source": [
        "DOCUMENT = \"\"\"\n",
        "# Q3 2023 Financial Performance Analysis\n",
        "\n",
        "The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement,\n",
        "beating market expectations. These impressive results reflect our successful product strategy\n",
        "and strong market positioning.\n",
        "\n",
        "Our core business segments demonstrated remarkable resilience, with digital services leading\n",
        "the growth at 25% year-over-year. The expansion into new markets has proven particularly\n",
        "successful, contributing to 30% of the total revenue increase.\n",
        "\n",
        "Customer acquisition costs decreased by 10% while retention rates improved to 92%,\n",
        "marking our best performance to date. These metrics, combined with our healthy cash flow\n",
        "position, provide a strong foundation for continued growth into Q4 and beyond.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Analyze the following document and extract metadata from it.\n",
        "The output must be a single, valid JSON object with the following structure:\n",
        "<json>\n",
        "{{\n",
        "    \"summary\": \"A concise summary of the article.\",\n",
        "    \"tags\": [\"list\", \"of\", \"relevant\", \"tags\"],\n",
        "    \"keywords\": [\"list\", \"of\", \"key\", \"concepts\"],\n",
        "    \"quarter\": \"Q...\",\n",
        "    \"growth_rate\": \"...%\",\n",
        "}}\n",
        "</json>\n",
        "\n",
        "Here is the document:\n",
        "<document>\n",
        "{DOCUMENT}\n",
        "</document>\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "\n",
        "pretty_print.wrapped(text=response.text, title=\"Raw LLM Output\", indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ej3XVxokqRJ"
      },
      "outputs": [],
      "source": [
        "def extract_json_from_response(response: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extracts JSON from a response string that is wrapped in <json> or ```json tags.\n",
        "    \"\"\"\n",
        "\n",
        "    response = response.replace(\"<json>\", \"\").replace(\"</json>\", \"\")\n",
        "    response = response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "    return json.loads(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONQVHKzMkqRK"
      },
      "source": [
        "You can now reliably parse the JSON string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab6o9n_RkqRK"
      },
      "outputs": [],
      "source": [
        "parsed_response = extract_json_from_response(response.text)\n",
        "pretty_print.wrapped(\n",
        "    text=[f\"Type of the parsed response: `{type(parsed_response)}`\", json.dumps(parsed_response, indent=2)],\n",
        "    title=\"Parsed JSON Object\",\n",
        "    indent=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQm2ON9fkqRK"
      },
      "source": [
        "## 3. Implementing structured outputs from scratch using Pydantic\n",
        "\n",
        "While prompting for JSON is effective, it can be fragile. A more robust and modern approach is to use **Pydantic**. Pydantic allows you to define data structures as Python classes. This gives you:\n",
        "\n",
        "- **A single source of truth**: The Pydantic model defines the structure.\n",
        "- **Automatic schema generation**: You can easily generate a JSON Schema from the model.\n",
        "- **Data validation**: You can validate the LLM's output against the model to ensure it conforms to the expected structure and types.\n",
        "\n",
        "Let's recreate the previous example using Pydantic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkgffPJskqRL"
      },
      "outputs": [],
      "source": [
        "class DocumentMetadata(BaseModel):\n",
        "    \"\"\"A class to hold structured metadata for a document.\"\"\"\n",
        "\n",
        "    summary: str = Field(description=\"A concise, 1-2 sentence summary of the document.\")\n",
        "    tags: list[str] = Field(description=\"A list of 3-5 high-level tags relevant to the document.\")\n",
        "    keywords: list[str] = Field(description=\"A list of specific keywords or concepts mentioned.\")\n",
        "    quarter: str = Field(description=\"The quarter of the financial year described in the document (e.g, Q3 2023).\")\n",
        "    growth_rate: str = Field(description=\"The growth rate of the company described in the document (e.g, 10%).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y6mk78_kqRM"
      },
      "source": [
        "### Injecting Pydantic Schema into the Prompt\n",
        "\n",
        "We can generate a JSON Schema from our Pydantic model and inject it directly into the prompt. This is a more formal way of telling the LLM what structure to follow.\n",
        "\n",
        "Note how, along with the field type, we can leverage the Field description automatically to clearly specify to the LLM what each field means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1skgyhgkqRM"
      },
      "outputs": [],
      "source": [
        "schema = DocumentMetadata.model_json_schema()\n",
        "schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiU0DtqakqRN"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Please analyze the following document and extract metadata from it.\n",
        "The output must be a single, valid JSON object that conforms to the following JSON Schema:\n",
        "<json>\n",
        "{json.dumps(schema, indent=2)}\n",
        "</json>\n",
        "\n",
        "Here is the document:\n",
        "<document>\n",
        "{DOCUMENT}\n",
        "</document>\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(model=MODEL_ID, contents=prompt)\n",
        "\n",
        "parsed_response = extract_json_from_response(response.text)\n",
        "\n",
        "pretty_print.wrapped(\n",
        "    text=[f\"Type of the parsed response: `{type(parsed_response)}`\", json.dumps(parsed_response, indent=2)],\n",
        "    title=\"Parsed JSON Object\",\n",
        "    indent=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezl0d8nykqRN"
      },
      "source": [
        "As you can see, conceptually, the results are the same. But now, we can easily validate the output with Pydantic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXF8Lkv-kqRN"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    document_metadata = DocumentMetadata.model_validate(parsed_response)\n",
        "    print(\"\\nValidation successful!\")\n",
        "\n",
        "    pretty_print.wrapped(\n",
        "        [\"Type of the validated response: `{type(document_metadata)}`\", document_metadata.model_dump_json(indent=2)],\n",
        "        title=\"Pydantic Validated Object\",\n",
        "        indent=2,\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"\\nValidation failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6yIaajFkqRN"
      },
      "source": [
        "### Exercise: Implement Structured Extraction with Native Gemini Support\n",
        "\n",
        "Now it's your turn! In this exercise, you'll use Gemini's native structured output capabilities to extract metadata from the document.\n",
        "\n",
        "**Learning Goal:**\n",
        "Learn how to leverage Gemini's built-in support for structured outputs using `GenerateContentConfig` and Pydantic schemas.\n",
        "\n",
        "**What You Need to Implement:**\n",
        "1. Create a configuration object that enforces JSON output with schema validation\n",
        "2. Write a simple prompt that wraps the document\n",
        "3. Call the model with the configuration\n",
        "4. Display the validated Pydantic object\n",
        "\n",
        "**Key Concepts:**\n",
        "- `types.GenerateContentConfig` - Configuration class for model generation\n",
        "- `response_mime_type=\"application/json\"` - Forces JSON output format\n",
        "- `response_schema=DocumentMetadata` - Specifies the Pydantic model to validate against\n",
        "- `response.parsed` - Returns the already-validated Pydantic object (no manual parsing needed!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAzXiIPvkqRN",
        "tags": [
          "exercise"
        ]
      },
      "outputs": [],
      "source": [
        "# EXERCISE: Structured extraction with a schema\n",
        "\n",
        "# Hint: start from these variables that already exist above:\n",
        "#   - client, MODEL_ID, DOCUMENT, DocumentMetadata, types, pretty_print\n",
        "\n",
        "# TODO: your code here\n",
        "raise NotImplementedError('Fill in the config, prompt, and model call.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTxGsDlKt-m6"
      },
      "source": [
        "### Validation Check\n",
        "\n",
        "Run the cell below to verify your implementation works correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QoQyZQkt5W8"
      },
      "outputs": [],
      "source": [
        "# # Validation: Check if your implementation is correct\n",
        "\n",
        "# try:\n",
        "#     # Check if response exists and has parsed attribute\n",
        "#     assert 'response' in dir(), \"âŒ 'response' variable not found. Make sure you called generate_content().\"\n",
        "#     assert hasattr(response, 'parsed'), \"âŒ Response doesn't have 'parsed' attribute. Check your config.\"\n",
        "\n",
        "#     # Check if parsed is a DocumentMetadata instance\n",
        "#     assert isinstance(response.parsed, DocumentMetadata), f\"âŒ Expected DocumentMetadata, got {type(response.parsed)}\"\n",
        "\n",
        "#     # Check if all required fields are present\n",
        "#     required_fields = ['summary', 'tags', 'keywords', 'quarter', 'growth_rate']\n",
        "#     for field in required_fields:\n",
        "#         assert hasattr(response.parsed, field), f\"âŒ Missing field: {field}\"\n",
        "#         value = getattr(response.parsed, field)\n",
        "#         assert value is not None and value != \"\", f\"âŒ Field '{field}' is empty\"\n",
        "\n",
        "#     # Check data types\n",
        "#     assert isinstance(response.parsed.summary, str), \"âŒ 'summary' should be a string\"\n",
        "#     assert isinstance(response.parsed.tags, list), \"âŒ 'tags' should be a list\"\n",
        "#     assert isinstance(response.parsed.keywords, list), \"âŒ 'keywords' should be a list\"\n",
        "#     assert len(response.parsed.tags) >= 3, \"âŒ Should have at least 3 tags\"\n",
        "\n",
        "#     print(\"âœ… All validation checks passed!\")\n",
        "#     print(\"\\nğŸ‰ Congratulations! Your implementation is correct.\")\n",
        "#     print(\"\\nYou've successfully:\")\n",
        "#     print(\"  - Created a proper GenerateContentConfig\")\n",
        "#     print(\"  - Used response_mime_type and response_schema correctly\")\n",
        "#     print(\"  - Extracted structured data with native Gemini support\")\n",
        "#     print(\"  - Obtained a validated Pydantic object directly\")\n",
        "\n",
        "# except AssertionError as e:\n",
        "#     print(f\"\\n{e}\")\n",
        "#     print(\"\\nğŸ’¡ Tips:\")\n",
        "#     print(\"  - Make sure you create the config with both response_mime_type and response_schema\")\n",
        "#     print(\"  - Pass the config to generate_content() using config=your_config\")\n",
        "#     print(\"  - Access the parsed result using response.parsed\")\n",
        "# except Exception as e:\n",
        "#     print(f\"\\nâŒ Error: {e}\")\n",
        "#     print(\"\\nğŸ’¡ Make sure you've completed the exercise cell above first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9d52385"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Define a new Pydantic schema to extract **people mentioned** in the document (name, role, sentiment), and re-run the structured extraction.\n",
        "2. Add a field for `risk_factors: list[str]` and compare extraction quality with and without examples in the prompt.\n",
        "3. Wrap the extraction call in a retry loop that re-prompts the model if JSON validation fails.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}