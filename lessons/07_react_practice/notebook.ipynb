{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdZUi2E44tIQ"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "import json\n",
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIh1zHDZBxDk"
      },
      "source": [
        "## Connect to Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl4QQd-Z47rY"
      },
      "outputs": [],
      "source": [
        "# Ensure the GOOGLE_API_KEY environment variable is set.\n",
        "# You can get an API key from Google AI Studio: https://aistudio.google.com/\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Initialize the LLM model (e.g., Gemini)\n",
        "llm_model = genai.GenerativeModel('gemini-2.5-flash')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kLgTbeTBvwt"
      },
      "source": [
        "## Search Tool Definition\n",
        "\n",
        "This is a simple and mocked tool as per the lesson's focus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09szFdH86K6A"
      },
      "outputs": [],
      "source": [
        "def search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific topic or query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query or topic to look up\n",
        "\n",
        "    Returns:\n",
        "        str: Search results containing information about the queried topic\n",
        "\n",
        "    Note:\n",
        "        This is a simple mocked search tool for demonstration purposes.\n",
        "        In a real scenario, this would call a search API like Google Search,\n",
        "        Bing Search, or a specialized knowledge base API.\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    # Predefined responses for demonstration\n",
        "    if all(word in query_lower for word in [\"capital\", \"france\"]):\n",
        "        return \"Paris is the capital of France and is known for the Eiffel Tower.\"\n",
        "    elif \"react\" in query_lower:\n",
        "        return \"The ReAct (Reasoning and Acting) framework enables LLMs to solve complex tasks by interleaving thought generation, action execution, and observation processing.\"\n",
        "\n",
        "    # Generic response for unhandled queries\n",
        "    return f\"Mock search result: Information about '{query}' was not found in the predefined mock responses. A real search tool would provide more.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id1R6LRKDRcv"
      },
      "source": [
        "## Thought Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvS9ww0xflyx"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT_THOUGHT = \"\"\"You are a reasoning agent analyzing the user's question and your current knowledge to determine what information is needed next.\n",
        "\n",
        "Based on the conversation history, think about:\n",
        "1. What information do you currently have?\n",
        "2. What information is still needed to answer the user's question?\n",
        "3. What should be the next step?\n",
        "\n",
        "Provide your detailed reasoning and analysis of the current situation.\"\"\"\n",
        "\n",
        "\n",
        "class ThoughtResponse(BaseModel):\n",
        "    thought: str\n",
        "\n",
        "\n",
        "def generate_thought(scratchpad_content: str) -> str:\n",
        "    \"\"\"Generate a thought using structured output\"\"\"\n",
        "    prompt = f\"{SYSTEM_PROMPT_THOUGHT}\\n\\nConversation so far:\\n{scratchpad_content}\\n\\nWhat is your thought about the next step?\"\n",
        "\n",
        "    response = llm_model.generate_content(\n",
        "        prompt,\n",
        "        generation_config=genai.types.GenerationConfig(\n",
        "            response_mime_type=\"application/json\",\n",
        "            response_schema=ThoughtResponse\n",
        "        )\n",
        "    )\n",
        "\n",
        "    thought_data = json.loads(response.text)\n",
        "    return thought_data[\"thought\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtGC4m-Xsz8R"
      },
      "source": [
        "## Action Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMH6u54tDQyr"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT_ACTION = \"\"\"You are a reasoning agent that takes actions based on your thoughts.\n",
        "\n",
        "Available tools:\n",
        "- search: Use this to find information about a specific topic\n",
        "\n",
        "Choose the appropriate action based on your previous thought. If you need more information, use the search tool. If you have enough information to provide a complete answer, respond directly with your final answer (do not use any tool).\"\"\"\n",
        "\n",
        "\n",
        "def generate_action(scratchpad_content: str) -> tuple[str, str]:\n",
        "    \"\"\"Generate an action using function calling or direct text response\"\"\"\n",
        "    prompt = f\"{SYSTEM_PROMPT_ACTION}\\n\\nConversation so far:\\n{scratchpad_content}\\n\\nBased on your thought, what action should you take?\"\n",
        "\n",
        "    # Configure the model with function declarations\n",
        "    model_with_tools = genai.GenerativeModel(\n",
        "        'gemini-2.5-flash',\n",
        "        tools=[search]\n",
        "    )\n",
        "\n",
        "    response = model_with_tools.generate_content(prompt)\n",
        "\n",
        "    # Check if response contains a function call or text\n",
        "    first_part = response.candidates[0].content.parts[0]\n",
        "\n",
        "    if hasattr(first_part, 'function_call') and first_part.function_call:\n",
        "        # It's a function call\n",
        "        function_call = first_part.function_call\n",
        "        action_name = function_call.name\n",
        "        if action_name == \"search\":\n",
        "            action_arg = function_call.args[\"query\"]\n",
        "        else:\n",
        "            action_arg = \"\"\n",
        "        return action_name, action_arg\n",
        "    else:\n",
        "        # It's a text response (final answer)\n",
        "        return \"finish\", response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moxbYJ2_EqYi"
      },
      "source": [
        "## ReAct Control Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-PSlQ34f1RM"
      },
      "outputs": [],
      "source": [
        "def react_agent_loop(initial_question: str, max_turns: int = 3, verbose: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Implements the main ReAct (Thought -> Action -> Observation) control loop.\n",
        "    Uses structured outputs for thoughts and function calling for actions.\n",
        "    \"\"\"\n",
        "    # The scratchpad stores the history of thoughts, actions, and observations.\n",
        "    scratchpad = []\n",
        "\n",
        "    for turn in range(max_turns):\n",
        "        if verbose:\n",
        "            print(f\"\\n--- Turn {turn + 1}/{max_turns} ---\")\n",
        "\n",
        "        # If first turn, then write the user question\n",
        "        if not scratchpad:\n",
        "            user_question_log = f\"User Question: {initial_question}\"\n",
        "            scratchpad.append(user_question_log)\n",
        "            if verbose:\n",
        "                print(user_question_log)\n",
        "\n",
        "        # Generate thought using structured output\n",
        "        scratchpad_content = \"\\n\".join(scratchpad)\n",
        "        thought = generate_thought(scratchpad_content)\n",
        "        current_thought_log = f\"Thought: {thought}\"\n",
        "        scratchpad.append(current_thought_log)\n",
        "        if verbose:\n",
        "            print(current_thought_log)\n",
        "\n",
        "        # Generate action using function calling\n",
        "        action_name, action_arg = generate_action(scratchpad_content)\n",
        "        current_action_log = f\"Action: {action_name}['{action_arg}']\"\n",
        "        scratchpad.append(current_action_log)\n",
        "        if verbose:\n",
        "            print(current_action_log)\n",
        "\n",
        "        # Handle the action\n",
        "        if action_name == \"search\":\n",
        "            tool_output = search(action_arg)\n",
        "            current_observation_log = f\"Observation: {tool_output}\"\n",
        "            scratchpad.append(current_observation_log)\n",
        "            if verbose:\n",
        "                print(current_observation_log)\n",
        "        elif action_name == \"finish\":\n",
        "            final_answer = action_arg\n",
        "            final_answer_log = f\"Final Answer: {final_answer}\"\n",
        "            scratchpad.append(final_answer_log)\n",
        "            if verbose:\n",
        "                print(final_answer_log)\n",
        "            return final_answer # Terminate the loop and return the answer\n",
        "        else:\n",
        "            # Unknown action\n",
        "            current_observation_log = f\"Observation: Error - Unknown action '{action_name}'. Available tools are [search].\"\n",
        "            scratchpad.append(current_observation_log)\n",
        "            if verbose:\n",
        "                print(current_observation_log)\n",
        "\n",
        "        # Check if max turns reached without completing\n",
        "        if turn == max_turns - 1:\n",
        "            current_observation_log = f\"Observation: Error - Max turns reached without providing final answer.\"\n",
        "            scratchpad.append(current_observation_log)\n",
        "            if verbose:\n",
        "                print(current_observation_log)\n",
        "            return \"Agent did not provide a final answer within the turn limit.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utJSwfTGTAhh"
      },
      "source": [
        "Let's test the `react_agent_loop` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "RGC0R4VO4oEo",
        "outputId": "3d989cc3-3e44-45af-940a-ef0ddedc0af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Turn 1/5 ---\n",
            "User Question: What is the capital of France?\n",
            "Thought: The user is asking a direct factual question about the capital of France. This information is readily available as general knowledge. The next step should be to directly provide the answer to the user.\n",
            "Action: search['capital of France']\n",
            "Observation: Paris is the capital of France and is known for the Eiffel Tower.\n",
            "\n",
            "--- Turn 2/5 ---\n",
            "Thought: I have the user's question: \"What is the capital of France?\" I performed a search action and received the observation: \"Paris is the capital of France and is known for the Eiffel Tower.\" This observation directly answers the user's question. Therefore, all necessary information has been gathered. The next step is to provide the answer to the user.\n",
            "Action: finish['Paris is the capital of France.']\n",
            "Final Answer: Paris is the capital of France.\n"
          ]
        }
      ],
      "source": [
        "# A straightforward question requiring a search.\n",
        "question = \"What is the capital of France?\"\n",
        "final_answer = react_agent_loop(question, max_turns=5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "alwfGkShCtlr",
        "outputId": "432ed622-b8ec-45ac-f29d-9be6a66505b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Turn 1/5 ---\n",
            "User Question: Can you explain the ReAct framework in AI?\n",
            "Thought: The user is asking for an explanation of the ReAct framework. This is a direct knowledge-based question. I possess the necessary information to provide a comprehensive explanation of ReAct. Therefore, the next step is to generate the explanation directly.\n",
            "Action: search['ReAct framework in AI']\n",
            "Observation: The ReAct (Reasoning and Acting) framework enables LLMs to solve complex tasks by interleaving thought generation, action execution, and observation processing.\n",
            "\n",
            "--- Turn 2/5 ---\n",
            "Thought: I have the user's question about the ReAct framework and a concise definition obtained from the previous search (Observation). The definition states that ReAct enables LLMs to solve complex tasks by interleaving thought generation, action execution, and observation processing. While this provides the core concept, a comprehensive explanation requires elaborating on each of these components, how they interact, the benefits of the framework, and potentially an illustrative example. My current information is sufficient to build this detailed explanation without needing further searches. Therefore, the next logical step is to synthesize this information and provide the direct answer to the user's question.\n",
            "Action: finish['The ReAct (Reasoning and Acting) framework is an AI paradigm that allows large language models (LLMs) to tackle complex tasks by combining reasoning and acting. It achieves this by interleaving three key processes:\n",
            "\n",
            "1.  **Thought Generation:** The LLM generates internal thoughts, which are essentially its reasoning process, planning the next steps or considering different approaches.\n",
            "2.  **Action Execution:** Based on its thoughts, the LLM takes an action. This could involve using a tool, querying a knowledge base, or interacting with an environment.\n",
            "3.  **Observation Processing:** After executing an action, the LLM processes the observation, which is the result or feedback from the executed action. This observation then informs the subsequent thought generation, creating a continuous loop of reasoning, acting, and learning from the environment.\n",
            "\n",
            "This iterative process of thinking, acting, and observing allows LLMs to break down complex problems, learn from their interactions, and ultimately arrive at more robust and accurate solutions.']\n",
            "Final Answer: The ReAct (Reasoning and Acting) framework is an AI paradigm that allows large language models (LLMs) to tackle complex tasks by combining reasoning and acting. It achieves this by interleaving three key processes:\n",
            "\n",
            "1.  **Thought Generation:** The LLM generates internal thoughts, which are essentially its reasoning process, planning the next steps or considering different approaches.\n",
            "2.  **Action Execution:** Based on its thoughts, the LLM takes an action. This could involve using a tool, querying a knowledge base, or interacting with an environment.\n",
            "3.  **Observation Processing:** After executing an action, the LLM processes the observation, which is the result or feedback from the executed action. This observation then informs the subsequent thought generation, creating a continuous loop of reasoning, acting, and learning from the environment.\n",
            "\n",
            "This iterative process of thinking, acting, and observing allows LLMs to break down complex problems, learn from their interactions, and ultimately arrive at more robust and accurate solutions.\n"
          ]
        }
      ],
      "source": [
        "# A question about a concept the mock search tool might know.\n",
        "question = \"Can you explain the ReAct framework in AI?\"\n",
        "final_answer = react_agent_loop(question, max_turns=5, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
