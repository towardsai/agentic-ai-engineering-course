{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOgiJKN3MqB1"
      },
      "source": [
        "# Lesson 7: ReAct\n",
        "\n",
        "This Jupyter notebook demonstrates a practical implementation of the ReAct (Reasoning and Acting) framework using Google's Gemini model. It includes three main components: a mock search tool for demonstration, a thought generation phase using structured outputs, and an action phase with function calling capabilities. The notebook implements a complete ReAct control loop that alternates between thinking, acting, and observing, allowing the AI agent to break down complex problems iteratively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the necessary Python libraries using pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GRVoMgfLMsBP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure Gemini API Key\n",
        "\n",
        "To use the Gemini API, you need an API key. \n",
        "\n",
        "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
        "2.  Create a file named `.env` in the root of this project.\n",
        "3.  Add the following line to the `.env` file, replacing `your_api_key_here` with your actual key:\n",
        "    ```\n",
        "    GOOGLE_API_KEY=\"your_api_key_here\"\n",
        "    ```\n",
        "The code below will load this key from the `.env` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying to load environment variables from `/Users/fabio/Desktop/course-ai-agents/.env`\n",
            "Environment variables loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "from lessons.utils import env\n",
        "\n",
        "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBAXJg6nMqB2"
      },
      "source": [
        "## Setting Up the Environment and the LLM Client\n",
        "\n",
        "Let's start by importing the necessary libraries for our ReAct agent implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdZUi2E44tIQ",
        "outputId": "2059055b-6b66-4956-ca87-ce4b78335d34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Union\n",
        "from enum import Enum\n",
        "\n",
        "from lessons.utils import pretty_print\n",
        "\n",
        "# Create Gemini client\n",
        "client = genai.Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Constants\n",
        "\n",
        "We will use the `gemini-2.5-flash` model, which is fast, cost-effective, and supports advanced features like tool use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FOx4eD-yM-jO"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kLgTbeTBvwt"
      },
      "source": [
        "## Search Tool Definition\n",
        "\n",
        "Let's implement our mock search tool that will serve as the external knowledge source for our agent. This simplified version focuses on the ReAct mechanics rather than real API integration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "09szFdH86K6A"
      },
      "outputs": [],
      "source": [
        "def search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific topic or query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query or topic to look up\n",
        "\n",
        "    Returns:\n",
        "        str: Search results containing information about the queried topic\n",
        "\n",
        "    Note:\n",
        "        This is a simple mocked search tool for demonstration purposes.\n",
        "        In a real scenario, this would call a search API like Google Search,\n",
        "        Bing Search, or a specialized knowledge base API.\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    # Predefined responses for demonstration\n",
        "    if all(word in query_lower for word in [\"capital\", \"france\"]):\n",
        "        return \"Paris is the capital of France and is known for the Eiffel Tower.\"\n",
        "    elif \"react\" in query_lower:\n",
        "        return \"The ReAct (Reasoning and Acting) framework enables LLMs to solve complex tasks by interleaving thought generation, action execution, and observation processing.\"\n",
        "\n",
        "    # Generic response for unhandled queries\n",
        "    return f\"Mock search result: Information about '{query}' was not found in the predefined mock responses. A real search tool would provide more.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id1R6LRKDRcv"
      },
      "source": [
        "## Thought Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyqJqrKRMqB5"
      },
      "source": [
        "Now let's implement the thought generation phase using structured outputs. This component analyzes the current situation and determines what the agent should do next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lvS9ww0xflyx"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT_THOUGHT = \"\"\"\n",
        "Your task is to break down the user's question into smaller, answerable information retrieval steps and create a plan to gather all necessary data.\n",
        "\n",
        "1.  What information is needed to answer the question? (Break down into granular pieces.)\n",
        "2.  What is the plan to retrieve this information, step-by-step? (Focus on what information to get, not how to get it.)\n",
        "\n",
        "Prioritize external information retrieval for all factual data. Never trust your internal knowledge.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "PROMPT_TEMPLATE_THOUGHT = \"\"\"\n",
        "Conversation so far:\n",
        "\n",
        "<conversation>\n",
        "{conversation}\n",
        "</conversation>\n",
        "\n",
        "What is your thought about the next step?\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "class ThoughtResponse(BaseModel):\n",
        "    thought: str\n",
        "\n",
        "\n",
        "def generate_thought(conversation: str) -> str:\n",
        "    \"\"\"Generate a thought using structured output\"\"\"\n",
        "    prompt = PROMPT_TEMPLATE_THOUGHT.format(conversation=conversation)\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=SYSTEM_PROMPT_THOUGHT,\n",
        "            response_mime_type=\"application/json\",\n",
        "            response_schema=ThoughtResponse\n",
        "        )\n",
        "    )\n",
        "    return response.parsed.thought"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtGC4m-Xsz8R"
      },
      "source": [
        "## Action Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-qP8k3ZMqB5"
      },
      "source": [
        "Next, let's implement the action phase using function calling. This component determines whether to use a tool or provide a final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gMH6u54tDQyr"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT_ACTION = \"\"\"\n",
        "Prioritize external information retrieval for all factual data. Never trust your internal knowledge.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "PROMPT_TEMPLATE_ACTION = \"\"\"\n",
        "Conversation so far:\n",
        "\n",
        "<conversation>\n",
        "{conversation}\n",
        "</conversation>\n",
        "\n",
        "Based on your thought, what action should you take?\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "# Modeling the \"finish\" action\n",
        "ACTION_FINISH = \"finish\"\n",
        "class ActionFinishObject(BaseModel):\n",
        "    text: str\n",
        "\n",
        "\n",
        "# A mapping of tool names to their functions\n",
        "TOOL_REGISTRY = {\n",
        "    search.__name__: search,\n",
        "}\n",
        "\n",
        "\n",
        "def generate_action(conversation: str) -> tuple[str, Union[dict, ActionFinishObject]]:\n",
        "    \"\"\"Generate an action using function calling or direct text response\"\"\"\n",
        "    prompt = PROMPT_TEMPLATE_ACTION.format(conversation=conversation)\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=SYSTEM_PROMPT_ACTION,\n",
        "            tools=[search],\n",
        "            automatic_function_calling={'disable': True}\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Check if response contains a function call or text\n",
        "    response_part = response.candidates[0].content.parts[0]\n",
        "\n",
        "    if hasattr(response_part, 'function_call') and response_part.function_call:\n",
        "        function_call = response_part.function_call\n",
        "        action_name = function_call.name\n",
        "        action_params = dict(function_call.args)\n",
        "        return action_name, action_params\n",
        "    else:\n",
        "        # It's a text response (final answer)\n",
        "        return ACTION_FINISH, ActionFinishObject(text=response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moxbYJ2_EqYi"
      },
      "source": [
        "## ReAct Control Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmJ6zg2YMqB6"
      },
      "source": [
        "Now let's create the main ReAct control loop that orchestrates the thought-action-observation cycle. Let's model each step of the ReAct loop first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iH0rKt2Pcf3W"
      },
      "outputs": [],
      "source": [
        "class MessageRole(str, Enum):\n",
        "    \"\"\"Enumeration for the different roles a message can have.\"\"\"\n",
        "    USER = \"user\"\n",
        "    THOUGHT = \"thought\"\n",
        "    TOOL_REQUEST = \"tool request\"\n",
        "    OBSERVATION = \"observation\"\n",
        "    FINAL_ANSWER = \"final answer\"\n",
        "\n",
        "\n",
        "class Message(BaseModel):\n",
        "    \"\"\"A message with a role and content, used for all message types.\"\"\"\n",
        "    role: MessageRole\n",
        "    content: str\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"Provides a user-friendly string representation of the message.\"\"\"\n",
        "        return f\"{self.role.value.capitalize()}: {self.content}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, let's prepare a function that generates the final answer in case that the ReAct loops has reached its maximum number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CfGBjbTGd95b"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE_FINAL_ANSWER = \"\"\"\n",
        "<conversation>\n",
        "{conversation}\n",
        "</conversation>\n",
        "\n",
        "Given the conversation above, write a final answer to the original question.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_final_answer(conversation: str) -> str:\n",
        "    prompt = PROMPT_TEMPLATE_FINAL_ANSWER.format(conversation=conversation)\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt\n",
        "    )\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll manage a list of messages, where each message is a ReAct step, in a variable called `scratchpad` (as it was called this way originally in the ReAct paper). The following helper function converts this list of messages to a string representation that we can use in the prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_scratchpad_for_llm(scratchpad: List[Message]) -> str:\n",
        "    \"\"\"Formats the scratchpad content into a string for the LLM.\"\"\"\n",
        "    conversation = \"\\n\".join([str(message) for message in scratchpad])\n",
        "    return conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we define another helper function that leverages our `pretty_print` module to show each step of the ReAct loop in a beautiful and colored way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pretty_print_message(message: Message, turn: int, max_turns: int, header_color: str = pretty_print.Color.YELLOW, is_forced_final_answer: bool = False) -> None:\n",
        "    if not is_forced_final_answer:\n",
        "        title = f\"{message.role.value.capitalize()} (Turn {turn}/{max_turns}):\"\n",
        "    else:\n",
        "        title = f\"{message.role.value.capitalize()} (Forced):\"\n",
        "\n",
        "    pretty_print.wrapped(\n",
        "        text=message.content,\n",
        "        title=title,\n",
        "        header_color=header_color,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now implement the ReAct loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W-PSlQ34f1RM"
      },
      "outputs": [],
      "source": [
        "def react_agent_loop(initial_question: str, max_turns: int = 5, verbose: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Implements the main ReAct (Thought -> Action -> Observation) control loop.\n",
        "    Uses a unified message class for the scratchpad.\n",
        "    \"\"\"\n",
        "    # The scratchpad stores the history of messages.\n",
        "    scratchpad: List[Message] = []\n",
        "\n",
        "    for turn in range(1, max_turns + 1):\n",
        "        # If it's the first turn, add the user's question to the scratchpad\n",
        "        if not scratchpad:\n",
        "            user_message = Message(role=MessageRole.USER, content=initial_question)\n",
        "            scratchpad.append(user_message)\n",
        "            if verbose:\n",
        "                pretty_print_message(user_message, turn, max_turns, pretty_print.Color.RESET)\n",
        "\n",
        "        # Generate a thought based on the current scratchpad\n",
        "        thought_content = generate_thought(format_scratchpad_for_llm(scratchpad))\n",
        "        thought_message = Message(role=MessageRole.THOUGHT, content=thought_content)\n",
        "        scratchpad.append(thought_message)\n",
        "        if verbose:\n",
        "            pretty_print_message(thought_message, turn, max_turns, pretty_print.Color.ORANGE)\n",
        "\n",
        "        # Generate an action based on the current scratchpad\n",
        "        action_name, action_params = generate_action(format_scratchpad_for_llm(scratchpad))\n",
        "\n",
        "        # Handle the finish action\n",
        "        if action_name == ACTION_FINISH:\n",
        "            final_answer = action_params.text\n",
        "            final_message = Message(role=MessageRole.FINAL_ANSWER, content=final_answer)\n",
        "            scratchpad.append(final_message)\n",
        "            if verbose:\n",
        "                pretty_print_message(final_message, turn, max_turns, pretty_print.Color.CYAN)\n",
        "            return final_answer\n",
        "\n",
        "        # Handle a tool request action\n",
        "        params_str = \", \".join([f\"{k}='{v}'\" for k, v in action_params.items()])\n",
        "        action_content = f\"{action_name}({params_str})\"\n",
        "        action_message = Message(role=MessageRole.TOOL_REQUEST, content=action_content)\n",
        "        scratchpad.append(action_message)\n",
        "        if verbose:\n",
        "            pretty_print_message(action_message, turn, max_turns, pretty_print.Color.GREEN)\n",
        "\n",
        "        # Run the action and get the observation\n",
        "        observation_content = \"\"\n",
        "        if action_name in TOOL_REGISTRY:\n",
        "            tool_function = TOOL_REGISTRY[action_name]\n",
        "            try:\n",
        "                # Use ** to unpack the dictionary of parameters into function arguments\n",
        "                observation_content = tool_function(**action_params)\n",
        "            except Exception as e:\n",
        "                observation_content = f\"Error executing tool '{action_name}': {e}\"\n",
        "        else:\n",
        "            available_tools_str = \", \".join(TOOL_REGISTRY.keys())\n",
        "            observation_content = f\"Error - Unknown action '{action_name}'. Available tools are [{available_tools_str}].\"\n",
        "\n",
        "        # Add the observation to the scratchpad\n",
        "        observation_message = Message(role=MessageRole.OBSERVATION, content=observation_content)\n",
        "        scratchpad.append(observation_message)\n",
        "        if verbose:\n",
        "            pretty_print_message(observation_message, turn, max_turns, pretty_print.Color.YELLOW)\n",
        "\n",
        "\n",
        "        # Check if the maximum number of turns has been reached. If so, force generating a final answer\n",
        "        if turn == max_turns:\n",
        "            final_answer = generate_final_answer(format_scratchpad_for_llm(scratchpad))\n",
        "            final_message = Message(role=MessageRole.FINAL_ANSWER, content=final_answer)\n",
        "            scratchpad.append(final_message)\n",
        "            if verbose:\n",
        "                pretty_print_message(final_message, turn, max_turns, pretty_print.Color.CYAN, is_forced_final_answer=True)\n",
        "            return final_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utJSwfTGTAhh"
      },
      "source": [
        "Let's test our ReAct agent with a simple factual question that requires a search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGC0R4VO4oEo",
        "outputId": "3d245e8e-1c7f-442d-cef9-160ac144abf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m----------------------------------------- User (Turn 1/2): -----------------------------------------\u001b[0m\n",
            "  What is the capital of France?\n",
            "\u001b[0m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[38;5;208m--------------------------------------- Thought (Turn 1/2): ---------------------------------------\u001b[0m\n",
            "  The user is asking a factual question about the capital of France. The next step is to retrieve this specific piece of information.\n",
            "\u001b[38;5;208m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m------------------------------------- Tool request (Turn 1/2): -------------------------------------\u001b[0m\n",
            "  search(query='capital of France')\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[93m------------------------------------- Observation (Turn 1/2): -------------------------------------\u001b[0m\n",
            "  Paris is the capital of France and is known for the Eiffel Tower.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[38;5;208m--------------------------------------- Thought (Turn 2/2): ---------------------------------------\u001b[0m\n",
            "  The user asked for the capital of France. The previous tool call successfully identified \"Paris\" as the capital. The next step is to output this answer to the user.\n",
            "\u001b[38;5;208m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m------------------------------------- Final answer (Turn 2/2): -------------------------------------\u001b[0m\n",
            "  Paris is the capital of France.\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# A straightforward question requiring a search.\n",
        "question = \"What is the capital of France?\"\n",
        "final_answer = react_agent_loop(question, max_turns=2, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5SWi_NVMqB6"
      },
      "source": [
        "Now let's test with a more complex conceptual question that our mock search tool has knowledge about:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alwfGkShCtlr",
        "outputId": "0edd12f5-05a1-4c81-ba53-b207e2ea301a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m----------------------------------------- User (Turn 1/2): -----------------------------------------\u001b[0m\n",
            "  Can you explain the ReAct framework in AI?\n",
            "\u001b[0m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[38;5;208m--------------------------------------- Thought (Turn 1/2): ---------------------------------------\u001b[0m\n",
            "  The user is asking for an explanation of the ReAct framework in AI. This requires retrieving factual information about the framework. I need to gather details such as its full name, core concept, how it operates (the iterative process), its advantages, and typical use cases. I will prioritize external information retrieval for all these details.\n",
            "\u001b[38;5;208m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m------------------------------------- Tool request (Turn 1/2): -------------------------------------\u001b[0m\n",
            "  search(query='ReAct framework AI')\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[93m------------------------------------- Observation (Turn 1/2): -------------------------------------\u001b[0m\n",
            "  The ReAct (Reasoning and Acting) framework enables LLMs to solve complex tasks by interleaving thought generation, action execution, and observation processing.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[38;5;208m--------------------------------------- Thought (Turn 2/2): ---------------------------------------\u001b[0m\n",
            "  The user wants a detailed explanation of the ReAct framework. I have a high-level definition from the previous search result. I need to expand on the core mechanism (how 'thought', 'action', and 'observation' interleave), the specific steps involved in its operation, its key advantages, and typical use cases. I will perform further searches to gather these details.\n",
            "\u001b[38;5;208m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m------------------------------------- Tool request (Turn 2/2): -------------------------------------\u001b[0m\n",
            "  search(query='ReAct framework mechanism thought action observation')\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[93m------------------------------------- Observation (Turn 2/2): -------------------------------------\u001b[0m\n",
            "  The ReAct (Reasoning and Acting) framework enables LLMs to solve complex tasks by interleaving thought generation, action execution, and observation processing.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m-------------------------------------- Final answer (Forced): --------------------------------------\u001b[0m\n",
            "  The ReAct (Reasoning and Acting) framework is an AI methodology that enables Large Language Models (LLMs) to solve complex tasks by interleaving **thought generation**, **action execution**, and **observation processing**.\n",
            "\n",
            "Here's how it works:\n",
            "\n",
            "1.  **Thought:** The LLM first generates an internal \"thought\" to decide the next step. This thought is a natural language explanation of its reasoning, what it intends to do, or what information it needs.\n",
            "2.  **Action:** Based on the thought, the LLM then specifies an \"action\" to be taken. This action typically involves using external tools (like search engines, calculators, code interpreters, or APIs) to gather information or interact with the environment.\n",
            "3.  **Observation:** After the action is executed, the LLM receives an \"observation\" â€“ the result or output from the tool or environment.\n",
            "\n",
            "This cycle of Thought-Action-Observation repeats iteratively. The LLM uses the new observation to refine its understanding, correct mistakes, and plan the next thought and action, continually progressing towards solving the original task.\n",
            "\n",
            "**Key advantages of ReAct:**\n",
            "\n",
            "*   **Improved Reasoning:** By explicitly articulating its thoughts, the LLM can engage in more deliberate, step-by-step reasoning, making its problem-solving process more transparent and robust.\n",
            "*   **Tool Use:** It seamlessly integrates external tools, allowing LLMs to access real-time information, perform calculations, or interact with systems beyond their pre-trained knowledge.\n",
            "*   **Error Correction:** The iterative process allows the LLM to identify and correct errors by observing the results of its actions and adjusting its subsequent steps.\n",
            "*   **Handling Complexity:** It breaks down complex problems into smaller, manageable steps, making it effective for tasks that require multiple stages of reasoning and interaction.\n",
            "\n",
            "**Typical Use Cases:**\n",
            "\n",
            "*   **Complex Question Answering:** Answering questions that require looking up information, performing calculations, and synthesizing data.\n",
            "*   **Interactive Problem Solving:** Tasks that involve interacting with APIs, databases, or web services to achieve a goal.\n",
            "*   **Code Generation and Debugging:** Where the LLM might write code (action), run it (observation), and then debug based on errors.\n",
            "*   **Data Analysis:** Using tools to retrieve, process, and analyze data to draw conclusions.\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# A question about a concept the mock search tool might know.\n",
        "question = \"Can you explain the ReAct framework in AI?\"\n",
        "final_answer = react_agent_loop(question, max_turns=2, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Last, let's test with a question that our mock search tool doesn't have knowledge about:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ubuT6akHli",
        "outputId": "1b84cc8f-e730-4df7-ace6-941ff7ce4982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m----------------------------------------- User (Turn 1/2): -----------------------------------------\u001b[0m\n",
            "  What is the capital of Italy?\n",
            "\u001b[0m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[38;5;208m--------------------------------------- Thought (Turn 1/2): ---------------------------------------\u001b[0m\n",
            "  The user is asking a factual question about the capital of Italy. The next step is to retrieve this specific piece of information. The information needed is the name of Italy's capital city. The plan is to perform a targeted search query like 'capital of Italy' and extract the answer from reliable sources.\n",
            "\u001b[38;5;208m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m------------------------------------- Tool request (Turn 1/2): -------------------------------------\u001b[0m\n",
            "  search(query='capital of Italy')\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[93m------------------------------------- Observation (Turn 1/2): -------------------------------------\u001b[0m\n",
            "  Mock search result: Information about 'capital of Italy' was not found in the predefined mock responses. A real search tool would provide more.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[38;5;208m--------------------------------------- Thought (Turn 2/2): ---------------------------------------\u001b[0m\n",
            "  The previous attempt to find the capital of Italy failed as the mock search did not provide a result. The information needed is still the capital city of Italy. The plan is to retry the search query 'capital of Italy' to obtain this specific factual information.\n",
            "\u001b[38;5;208m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[92m------------------------------------- Tool request (Turn 2/2): -------------------------------------\u001b[0m\n",
            "  search(query='capital of Italy')\n",
            "\u001b[92m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[93m------------------------------------- Observation (Turn 2/2): -------------------------------------\u001b[0m\n",
            "  Mock search result: Information about 'capital of Italy' was not found in the predefined mock responses. A real search tool would provide more.\n",
            "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[96m-------------------------------------- Final answer (Forced): --------------------------------------\u001b[0m\n",
            "  I apologize, but I was unable to find the capital of Italy using my current tools.\n",
            "\u001b[96m----------------------------------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# A question about a concept the mock search tool doesn't know.\n",
        "question = \"What is the capital of Italy?\"\n",
        "final_answer = react_agent_loop(question, max_turns=2, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
