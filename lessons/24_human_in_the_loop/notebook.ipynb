{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 24: Human-in-the-Loop for Brown Writing Workflow\n",
    "\n",
    "In this lesson, we'll explore how to implement human-in-the-loop capabilities in the Brown writing workflow. We'll learn how to integrate human feedback into the article review and editing process, expose the workflows as MCP tools for seamless integration with AI assistants like Claude and Cursor, and create a collaborative writing experience where AI and human expertise combine.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "- Understand the importance of human feedback and human-in-the-loop in AI writing workflows\n",
    "- Learn how to implement the HumanFeedback entity and integrate it into the ArticleReviewer node\n",
    "- Explore two new editing workflows: edit article and edit selected text\n",
    "- Discover how to expose Brown as an MCP server with tools, prompts, and resources\n",
    "- See how to integrate Brown with MCP clients like Cursor for a coding-like writing experience\n",
    "\n",
    "> [!NOTE]\n",
    "> ðŸ’¡ Remember that you can also run `brown` as a standalone Python package by going to `lessons/writing_workflow/` and following the instructions from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we define some standard Magic Python commands to autoreload Python packages whenever they change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Python Environment\n",
    "\n",
    "To set up your Python virtual environment using `uv` and load it into the Notebook, follow the step-by-step instructions from the `Course Admin` lesson from the beginning of the course.\n",
    "\n",
    "**TL/DR:** Be sure the correct kernel pointing to your `uv` virtual environment is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API\n",
    "\n",
    "To configure the Gemini API, follow the step-by-step instructions in the `Course Admin` lesson.\n",
    "\n",
    "Here is a quick checklist of what you need to run this notebook:\n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/api-keys).\n",
    "2.  From the root of your project, run: `cp .env.example .env` \n",
    "3.  Within the `.env` file, fill in the `GOOGLE_API_KEY` variable:\n",
    "\n",
    "Now, the code below will load the key from the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from `/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import env\n",
    "\n",
    "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Key Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from utils import pretty_print\n",
    "\n",
    "nest_asyncio.apply()  # Allow nested async usage in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Required Files\n",
    "\n",
    "We need to download the configuration files and input data that Brown uses for article generation and editing.\n",
    "\n",
    "First, let's download the configs folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf configs\n",
    "!curl -L -o configs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/configs.zip\n",
    "!unzip configs.zip\n",
    "!rm -rf configs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the inputs folder containing profiles, examples, and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf inputs\n",
    "!curl -L -o inputs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/inputs.zip\n",
    "!unzip inputs.zip\n",
    "!rm -rf inputs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify what we downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_guideline.md   \u001b[1m\u001b[36minputs\u001b[m\u001b[m/                notebook_guideline.md\n",
      "\u001b[1m\u001b[36mconfigs\u001b[m\u001b[m/               notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define constants to reference these directories throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs directory exists: True\n",
      "Inputs directory exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIGS_DIR = Path(\"configs\")\n",
    "INPUTS_DIR = Path(\"inputs\")\n",
    "\n",
    "print(f\"Configs directory exists: {CONFIGS_DIR.exists()}\")\n",
    "print(f\"Inputs directory exists: {INPUTS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples directory exists: True\n",
      "Profiles directory exists: True\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES_DIR = Path(\"inputs/examples/course_lessons\")\n",
    "PROFILES_DIR = Path(\"inputs/profiles\")\n",
    "\n",
    "print(f\"Examples directory exists: {EXAMPLES_DIR.exists()}\")\n",
    "print(f\"Profiles directory exists: {PROFILES_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load a simpler example that runs faster and is easier to understand. At the end, we will load a larger sample that is closer to what we do on our end to generate professional articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples directory exists: True\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_DIR = Path(\"inputs/tests/01_sample_small\")\n",
    "\n",
    "print(f\"Samples directory exists: {SAMPLE_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding Human-In-The-Loop In Our Writing Workflow\n",
    "\n",
    "After generating an article using the writing workflow we explained in Lessons 22 and 23, you'll likely want to refine it further. Writing is highly subjective, and even the best AI-generated content benefits from human review and editing.\n",
    "\n",
    "The perfect balance between AI and human expertise is to use AI to generate and automate parts of your work, then have you, as the domain expert, review and refine it. Known as the AI generation - human validation loop. \n",
    "\n",
    "This is exactly what we've designed the Brown writing workflow to support.\n",
    "\n",
    "### The Human-in-the-Loop Design\n",
    "\n",
    "We designed Brown to easily introduce humans into the loop between generating the first version of an article and refining it through additional review and editing cycles with human feedback. This means:\n",
    "\n",
    "1. We can use a low number of review loops during initial article generation to reduce costs and latency\n",
    "2. After reviewing the generated article, we can dynamically run additional review and editing workflows with human feedback\n",
    "3. We can edit either the entire article or just selected sections based on your needs\n",
    "\n",
    "### Decoupling Workflows with MCP\n",
    "\n",
    "To enable this human-in-the-loop approach, we needed to decouple the article generation workflow from the editing workflows. We used MCP servers to achieve this separation, where:\n",
    "\n",
    "- The `generate_article` workflow is one independent MCP tool\n",
    "- The `edit_article` workflow is another independent MCP tool\n",
    "- The `edit_selected_text` workflow is a third independent MCP tool\n",
    "\n",
    "This architecture allows you to generate an article, review it, and then selectively apply additional editing workflows with your human feedback until you're satisfied with the results.\n",
    "\n",
    "Here's how the workflow looks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/images/l24_writing_workflow.png\" alt=\"Workflow\" height=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram shows how Brown as an MCP server exposes three main tools, with a human feedback loop that allows iterative refinement until you're satisfied with the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introducing Human Feedback Into the Article Reviewer\n",
    "\n",
    "Let's see how we introduced human feedback into our Article Reviewer Node. We'll start by explaining the `HumanFeedback` entity, then show how it's integrated into the `ArticleReviewer` node, and finally demonstrate it with a working example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The HumanFeedback Entity\n",
    "\n",
    "The `HumanFeedback` entity is a simple but Pydantic model that encapsulates human feedback for the article review process.\n",
    "\n",
    "Source: `brown.entities.reviews`\n",
    "```python\n",
    "class HumanFeedback(BaseModel, ContextMixin):\n",
    "    content: str\n",
    "\n",
    "    def to_context(self) -> str:\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    {self.content}\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Human Feedback in ArticleReviewer\n",
    "\n",
    "Now let's see how the `ArticleReviewer` node integrates human feedback into the review process. We'll focus only on the relevant sections.\n",
    "\n",
    "Source: `brown.nodes.article_reviewer`\n",
    "\n",
    "1. **Initialization with Human Feedback**\n",
    "```python\n",
    "def __init__(\n",
    "    self,\n",
    "    to_review: Article | SelectedText,\n",
    "    article_guideline: ArticleGuideline,\n",
    "    model: Runnable,\n",
    "    article_profiles: ArticleProfiles,\n",
    "    human_feedback: HumanFeedback | None = None,\n",
    ") -> None:\n",
    "    self.to_review = to_review\n",
    "    self.article_guideline = article_guideline\n",
    "    self.article_profiles = article_profiles\n",
    "    self.human_feedback = human_feedback\n",
    "\n",
    "    super().__init__(model, toolkit=Toolkit(tools=[]))\n",
    "```\n",
    "\n",
    "The `ArticleReviewer` now accepts an optional `human_feedback` parameter. This allows the reviewer to work with or without human input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Human Feedback in the System Prompt**\n",
    "\n",
    "The system prompt includes a dedicated section for human feedback:\n",
    "```python\n",
    "system_prompt_template = \"\"\"\n",
    "You are Brown, an expert article writer, editor and reviewer specialized in reviewing technical, educative and informational articles.\n",
    "\n",
    "...\n",
    "\n",
    "## Human Feedback\n",
    "\n",
    "Along with the expected requirements, a human already reviewed the article and provided the following feedback:\n",
    "\n",
    "{human_feedback}\n",
    "\n",
    "If empty, completely ignore it, otherwise the feedback will ALWAYS be used in two ways:\n",
    "1. First you will use the <human_feedback> to guide your reviewing process against the requirements. This will help you understand \n",
    "on what rules to focus on as this directly highlights what the user wants to improve.\n",
    "2. Secondly you will extract one or more action points based on the <human_feedback>. Depending on how many ideas, topics or suggestions \n",
    "the <human_feedback> contains you will generate from 1 to N action points. Each <human_feedback> review will contain a single action point. \n",
    "3. As long the <human_feedback> is not empty, you will always return at least 1 action point, but you will return more action points \n",
    "if the feedback touches multiple ideas. \n",
    "\n",
    "Here is an example of a reviewed based on the human feedback:\n",
    "<example_of_human_feedback_action_point>\n",
    "Review(\n",
    "    profile=\"human_feedback\",\n",
    "    location=\"Article level\",\n",
    "    comment=\"Add all the points from the article guideline to the article.\"\n",
    ")\n",
    "</example_of_human_feedback_action_point>\n",
    "\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "This section instructs the LLM on how to use human feedback:\n",
    "- Use it to guide the review process and focus on specific rules\n",
    "- Extract action points from the feedback (1 to N depending on how many ideas are present)\n",
    "- Always return at least 1 action point if feedback is provided\n",
    "- Each action point becomes a review with `profile=\"human_feedback\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Injecting Human Feedback into the Prompt**\n",
    "\n",
    "When the reviewer runs, it injects the human feedback into the system prompt:\n",
    "\n",
    "```python\n",
    "async def ainvoke(self) -> ArticleReviews | SelectedTextReviews:\n",
    "    system_prompt = self.system_prompt_template.format(\n",
    "        human_feedback=self.human_feedback.to_context() if self.human_feedback else \"\",\n",
    "        article=self.article.to_context(),\n",
    "        article_guideline=self.article_guideline.to_context(),\n",
    "        character_template=self.article_profiles.character.to_context(),\n",
    "        article_template=self.article_profiles.article.to_context(),\n",
    "        structure_template=self.article_profiles.structure.to_context(),\n",
    "        mechanics_template=self.article_profiles.mechanics.to_context(),\n",
    "        terminology_template=self.article_profiles.terminology.to_context(),\n",
    "        tonality_template=self.article_profiles.tonality.to_context(),\n",
    "    )\n",
    "    ...\n",
    "```\n",
    "\n",
    "If `human_feedback` is provided, it's converted to XML context format and injected. Otherwise, an empty string is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Example: Using ArticleReviewer with Human Feedback\n",
    "\n",
    "Let's see a practical example of using the `ArticleReviewer` with human feedback. We'll load our sample article, article guideline, and profiles, then provide human feedback to guide the review process.\n",
    "\n",
    "First, let's import the necessary components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-26 17:26:07.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading environment file from `.env`\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.entities.reviews import HumanFeedback\n",
    "from brown.loaders import (\n",
    "    MarkdownArticleExampleLoader,\n",
    "    MarkdownArticleGuidelineLoader,\n",
    "    MarkdownArticleLoader,\n",
    "    MarkdownArticleProfilesLoader,\n",
    ")\n",
    "from brown.models import SupportedModels, get_model\n",
    "from brown.nodes.article_reviewer import ArticleReviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the sample inputs. We'll use the same article and guidelines from the test sample directory as we used in previous lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 1: Loading Context\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Guideline: 6,751 characters\n",
      "âœ“ Article: 6,982 characters\n",
      "âœ“ Profiles: 6 profiles loaded\n",
      "âœ“ Examples: 2 article examples\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\"STEP 1: Loading Context\", width=100)\n",
    "\n",
    "# Load guideline\n",
    "guideline_loader = MarkdownArticleGuidelineLoader(uri=Path(\"article_guideline.md\"))\n",
    "article_guideline = guideline_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load profiles\n",
    "profiles_input = {\n",
    "    \"article\": PROFILES_DIR / \"article_profile.md\",\n",
    "    \"character\": PROFILES_DIR / \"character_profiles\" / \"paul_iusztin.md\",\n",
    "    \"mechanics\": PROFILES_DIR / \"mechanics_profile.md\",\n",
    "    \"structure\": PROFILES_DIR / \"structure_profile.md\",\n",
    "    \"terminology\": PROFILES_DIR / \"terminology_profile.md\",\n",
    "    \"tonality\": PROFILES_DIR / \"tonality_profile.md\",\n",
    "}\n",
    "profiles_loader = MarkdownArticleProfilesLoader(uri=profiles_input)\n",
    "profiles = profiles_loader.load()\n",
    "\n",
    "# Load examples\n",
    "examples_loader = MarkdownArticleExampleLoader(uri=EXAMPLES_DIR)\n",
    "article_examples = examples_loader.load()\n",
    "\n",
    "article_loader = MarkdownArticleLoader(uri=\"article.md\")\n",
    "article = article_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "print(f\"âœ“ Guideline: {len(article_guideline.content):,} characters\")\n",
    "print(f\"âœ“ Article: {len(article.content):,} characters\")\n",
    "print(f\"âœ“ Profiles: {len(profiles_input)} profiles loaded\")\n",
    "print(f\"âœ“ Examples: {len(article_examples.examples)} article examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a reminder on how the article looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m--------------------------------- Article (first 4000 characters) ---------------------------------\u001b[0m\n",
      "  \n",
      "<article>\n",
      "    # Workflows vs. Agents: The Critical Decision Every AI Engineer Faces\n",
      "### How to choose between predictable control and autonomous flexibility when building AI applications.\n",
      "\n",
      "When building AI applications, engineers face a critical architectural decision early on. Should you create a predictable, step-by-step workflow where you control every action, or build an autonomous agent that can think and decide for itself? This choice impacts everything from development time and cost to reliability and user experience. It is a fundamental decision that often determines if an AI application will be successful in production.\n",
      "\n",
      "By the end of this lesson, you will understand the fundamental differences between LLM workflows and AI agents, know when to use each, and recognize how to combine their strengths in hybrid approaches.\n",
      "\n",
      "## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a database or calling an API. Think of it like a recipe where each step is explicitly defined. The key characteristic is that the path is determined in advance, resulting in a deterministic or rule-based system. This gives you predictable execution, explicit control over the application's flow, and makes the system easier to test and debug. Because you control every step, you know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. Instead, the agent uses a reasoning process to plan its actions based on the task and the current state of its environment. This process is often modeled on frameworks like ReAct (Reason, Act, Observe). This allows agents to be adaptive and capable of handling new or unexpected situations through LLM-driven autonomy. They can select tools, execute actions, evaluate the outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent (LLM) Receives Goal\"]\n",
      "    B --> C[\"Plan/Reason (LLM)\"]\n",
      "    C --> D[\"Select Tool\"]\n",
      "    D --> E[\"Execute Action (Tool Call)\"]\n",
      "    E --> F[\"Observe Environment/Feedback\"]\n",
      "    F --> G{\"Evaluate Outcome\"}\n",
      "    G -->|\"Satisfactory\"| H[\"Stop/Achieve Goal\"]\n",
      "    G -->|\"Needs Adjustment\"| C\n",
      "```\n",
      "Image 2: Flowchart illustrating an AI agent's dynamic decision-making process driven by an LLM.\n",
      "\n",
      "## Choosing Your Path\n",
      "\n",
      "The core difference between these two approaches lies in a single trade-off: developer-defined logic versus LLM-driven autonomy [[2]](https://decodingml.substack.com/p/llmops-for-production-agentic-rag), [[3]](https://towardsdatascience.com/a-developers-guide-to-building-scalable-ai-workflows-vs-agents/). Workflows offer high reliability at the cost of flexibility, while agents offer high flexibility at the cost of reliability.\n",
      "\n",
      "https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e64d5e0-7ef1-4e7f-b441-3bf1fef4ff9a_1276x818.png \n",
      "Image 3: The trade-off between an agent's level of control and application reliability. (Image by Iusztin, P. from [Exploring the difference between agents and workflows [2]](https://decodingml.substack.com/p/llmops-for-production-agentic-rag))\n",
      "\n",
      "### When to use LLM workflows\n",
      "\n",
      "W\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(f\"{article.to_context()[:4000]}\", title=\"Article (first 4000 characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create human feedback and run the article reviewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running article review with human feedback...\n",
      "\n",
      "Generated 19 reviews\n"
     ]
    }
   ],
   "source": [
    "human_feedback = HumanFeedback(\n",
    "    content=\"\"\"Make the introduction more engaging and catchy. \n",
    "Also, expand on the definition of both workflows and agents from the first section\"\"\"\n",
    ")\n",
    "\n",
    "# Create the article reviewer\n",
    "model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_reviewer = ArticleReviewer(\n",
    "    to_review=article,\n",
    "    article_guideline=article_guideline,\n",
    "    model=model,\n",
    "    article_profiles=profiles,\n",
    "    human_feedback=human_feedback,\n",
    ")\n",
    "\n",
    "print(\"Running article review with human feedback...\")\n",
    "reviews = await article_reviewer.ainvoke()\n",
    "print(f\"\\nGenerated {len(reviews.reviews)} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the reviews, especially focusing on the human feedback reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- Human Feedback Reviews --------------------------------------\u001b[0m\n",
      "  Found 2 reviews based on human feedback\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------- 1. Human Feedback Review -------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"profile\": \"human_feedback\",\n",
      "  \"location\": \"Article level\",\n",
      "  \"comment\": \"Make the introduction more engaging and catchy.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------- 2. Human Feedback Review -------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"profile\": \"human_feedback\",\n",
      "  \"location\": \"Understanding the Spectrum: From Workflows to Agents - First section\",\n",
      "  \"comment\": \"Expand on the definition of both workflows and agents from the first section.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import pretty_print\n",
    "\n",
    "# Print human feedback reviews\n",
    "human_feedback_reviews = [r for r in reviews.reviews if r.profile == \"human_feedback\"]\n",
    "pretty_print.wrapped(\n",
    "    f\"Found {len(human_feedback_reviews)} reviews based on human feedback\", title=\"Human Feedback Reviews\"\n",
    ")\n",
    "\n",
    "for i, review in enumerate(human_feedback_reviews, 1):\n",
    "    pretty_print.wrapped(\n",
    "        {\"profile\": review.profile, \"location\": review.location, \"comment\": review.comment},\n",
    "        title=f\"{i}. Human Feedback Review\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see all the other reviews from the profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m--------------------------------------- All Reviews Summary ---------------------------------------\u001b[0m\n",
      "  Generated reviews from 7 different profile types: article_guideline, article_profile, human_feedback, mechanics_profile, structure_profile, terminology_profile, tonality_profile\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  ARTICLE_GUIDELINE: 7 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - Article level] The introduction's length is 123 words, exceeding the guideline of 100 words....\n",
      "  2. [Understanding the Spectrum: From Workflows to Agents - Second paragraph] The article states 'We will look at their core properties and how they are used, rather than their t...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  ARTICLE_PROFILE: 3 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The introduction, while stating the problem, is not as engaging and captivating as it could be, as h...\n",
      "  2. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The introduction is primarily focused on the 'why' (problem) and then states 'By the end of this les...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  HUMAN_FEEDBACK: 2 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Article level] Make the introduction more engaging and catchy....\n",
      "  2. [Understanding the Spectrum: From Workflows to Agents - First section] Expand on the definition of both workflows and agents from the first section....\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  MECHANICS_PROFILE: 1 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Choosing Your Path - Fourth paragraph] The sentence 'If not designed well, there can be huge security concerns, especially with operations ...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STRUCTURE_PROFILE: 3 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Choosing Your Path - Fourth paragraph] The paragraph 'Agents excel at dynamic problem-solving like open-ended research or complex customer ...\n",
      "  2. [Choosing Your Path - Fourth paragraph] The sentence 'Agents excel at dynamic problem-solving like open-ended research or complex customer s...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  TERMINOLOGY_PROFILE: 2 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The phrase 'critical decision that often determines if an AI application will be successful in produ...\n",
      "  2. [Choosing Your Path - First paragraph] The sentence 'The core difference between these two approaches lies in a single trade-off: developer...\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  TONALITY_PROFILE: 1 reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  1. [Introduction: The Critical Decision Every AI Engineer Faces - First paragraph] The opening statement 'When building AI applications, engineers face a critical architectural decisi...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_types = set(r.profile for r in reviews.reviews)\n",
    "\n",
    "pretty_print.wrapped(\n",
    "    f\"Generated reviews from {len(profile_types)} different profile types: {', '.join(sorted(profile_types))}\",\n",
    "    title=\"All Reviews Summary\",\n",
    ")\n",
    "print()\n",
    "\n",
    "for profile_type in sorted(profile_types):\n",
    "    profile_reviews = [r for r in reviews.reviews if r.profile == profile_type]\n",
    "    pretty_print.wrapped(f\"{profile_type.upper()}: {len(profile_reviews)} reviews\")\n",
    "    for i, review in enumerate(profile_reviews[:2], 1):  # Show first 2 of each type\n",
    "        print(f\"  {i}. [{review.location}] {review.comment[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the reviewer generated reviews from multiple sources:\n",
    "- Human feedback reviews that directly address your specific requests\n",
    "- Profile-based reviews (article, structure, mechanics, terminology, tonality) that ensure adherence to the style guidelines\n",
    "\n",
    "The human feedback reviews always have `profile=\"human_feedback\"` and create action points based on your feedback. These reviews will be used by the article writer to edit the article according to your instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing the Article Editing Workflow\n",
    "\n",
    "Now that we understand how human feedback integrates with the article reviewer, let's explore the `edit_article` workflow. This workflow reviews and edits an existing article based on human feedback and the expected requirements.\n",
    "\n",
    "The edit article workflow contains only one loop of the same reviewing-editing logic we already use within the generate article workflow. \n",
    "\n",
    "Also, the edit article workflow follows the same clean architecture pattern we've used throughout Brown. It leverages the app layer to orchestrate nodes and entities, keeping the code modular and maintainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Building the Edit Article Workflow\n",
    "\n",
    "The workflow is built using LangGraph's functional API. Here's how it's structured:\n",
    "\n",
    "Source: `brown.workflows.edit_article`\n",
    "```python\n",
    "def build_edit_article_workflow(checkpointer: BaseCheckpointSaver):\n",
    "    \"\"\"Create an edit article workflow with checkpointer.\n",
    "\n",
    "    Args:\n",
    "        checkpointer: Checkpointer to use for workflow persistence.\n",
    "\n",
    "    Returns:\n",
    "        Configured workflow entrypoint\n",
    "    \"\"\"\n",
    "\n",
    "    return entrypoint(checkpointer=checkpointer)(_edit_article_workflow)\n",
    "```\n",
    "\n",
    "The `build_edit_article_workflow` function is a factory that creates the workflow with a checkpointer for persistence. It uses LangGraph's `@entrypoint` decorator to wrap the main workflow function.\n",
    "\n",
    "The workflow expects an `EditArticleInput` typed dictionary:\n",
    "\n",
    "```python\n",
    "class EditArticleInput(TypedDict):\n",
    "    dir_path: Path\n",
    "    human_feedback: str\n",
    "```\n",
    "\n",
    "This input specifies:\n",
    "- `dir_path`: The directory containing the article and all supporting files (guideline, profiles, research, etc.)\n",
    "- `human_feedback`: The human feedback string to guide the editing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Edit Article Workflow Logic\n",
    "\n",
    "The main workflow function orchestrates the entire editing process:\n",
    "```python\n",
    "async def _edit_article_workflow(inputs: EditArticleInput, config: RunnableConfig) -> str:\n",
    "    writer = get_stream_writer()\n",
    "\n",
    "    # Progress: Loading context\n",
    "    writer(WorkflowProgress(progress=0, message=\"Loading context\").model_dump(mode=\"json\"))\n",
    "    context = {}\n",
    "    loaders = build_loaders(app_config)\n",
    "    for context_name, loader in loaders.items():\n",
    "        loader = cast(Loader, loader)\n",
    "        context[context_name] = loader.load(working_uri=inputs[\"dir_path\"])\n",
    "\n",
    "    human_feedback = HumanFeedback(content=inputs[\"human_feedback\"])\n",
    "    writer(WorkflowProgress(progress=5, message=\"Loaded context\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Reviewing\n",
    "    writer(WorkflowProgress(progress=20, message=\"Reviewing article\").model_dump(mode=\"json\"))\n",
    "    reviews = await generate_reviews(context[\"article\"], human_feedback, context[\"article_guideline\"], context[\"profiles\"])\n",
    "    writer(WorkflowProgress(progress=40, message=\"Generated reviews\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Editing\n",
    "    writer(WorkflowProgress(progress=60, message=\"Editing article\").model_dump(mode=\"json\"))\n",
    "    article = await edit_based_on_reviews(\n",
    "        context[\"article_guideline\"], context[\"research\"], context[\"profiles\"], context[\"examples\"], reviews\n",
    "    )\n",
    "    writer(WorkflowProgress(progress=80, message=\"Edited article\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Complete\n",
    "    writer(WorkflowProgress(progress=100, message=\"Article editing completed\").model_dump(mode=\"json\"))\n",
    "\n",
    "    return f\"\"\"\n",
    "Here is the edited article:\n",
    "{article.to_context()}\n",
    "\n",
    "Here is what you have to do with the edited article:\n",
    "- print the edited article to the console for the user to see\n",
    "- give a quick summary of the changes you made\n",
    "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
    "- in case you haven't changed anything, just say that you haven't changed anything\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "The workflow follows these steps:\n",
    "1. **Load context**: Use the loader builders to load the article, guideline, profiles, research, and examples from the directory\n",
    "2. **Create human feedback**: Convert the feedback string into a `HumanFeedback` entity\n",
    "3. **Generate reviews**: Run the article reviewer with human feedback to generate reviews\n",
    "4. **Edit based on reviews**: Run the article writer with the reviews to produce an edited article\n",
    "5. **Return instructions**: Return the edited article along with instructions for the MCP client on what to do next\n",
    "\n",
    "Notice how steps 3 and 4 are identical to the ones from the writing workflow you learned in lesson 23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Generating Reviews\n",
    "\n",
    "The `generate_reviews` task creates reviews by running the `ArticleReviewer` node:\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_reviews(\n",
    "    article: Article,\n",
    "    human_feedback: HumanFeedback,\n",
    "    article_guideline: ArticleGuideline,\n",
    "    article_profiles: ArticleProfiles,\n",
    ") -> ArticleReviews:\n",
    "    model, _ = build_model(app_config, node=\"review_article\")\n",
    "    article_reviewer = ArticleReviewer(\n",
    "        to_review=article,\n",
    "        article_guideline=article_guideline,\n",
    "        article_profiles=article_profiles,\n",
    "        human_feedback=human_feedback,\n",
    "        model=model,\n",
    "    )\n",
    "    reviews = await article_reviewer.ainvoke()\n",
    "\n",
    "    return cast(ArticleReviews, reviews)\n",
    "```\n",
    "\n",
    "This task:\n",
    "- Builds the model from the app config for the \"review_article\" node\n",
    "- Creates an `ArticleReviewer` with the article, guideline, profiles, and human feedback\n",
    "- Uses LangGraph's `@task` decorator with a retry policy for resilience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Editing Based on Reviews\n",
    "\n",
    "The `edit_based_on_reviews` task creates an edited article using the `ArticleWriter` node:\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def edit_based_on_reviews(\n",
    "    article_guideline: ArticleGuideline,\n",
    "    research: Research,\n",
    "    article_profiles: ArticleProfiles,\n",
    "    article_examples: ArticleExamples,\n",
    "    reviews: ArticleReviews,\n",
    ") -> Article:\n",
    "    model, _ = build_model(app_config, node=\"edit_article\")\n",
    "    article_writer = ArticleWriter(\n",
    "        article_guideline=article_guideline,\n",
    "        research=research,\n",
    "        article_profiles=article_profiles,\n",
    "        media_items=MediaItems.build(),\n",
    "        article_examples=article_examples,\n",
    "        reviews=reviews,\n",
    "        model=model,\n",
    "    )\n",
    "    article = await article_writer.ainvoke()\n",
    "\n",
    "    return cast(Article, article)\n",
    "```\n",
    "\n",
    "This task:\n",
    "- Builds the model from the app config for the \"edit_article\" node\n",
    "- Creates an `ArticleWriter` with all necessary context and the reviews to address\n",
    "- Also uses the `@task` decorator with retry policy\n",
    "\n",
    "Notice how the `ArticleWriter` works in \"editing mode\" when provided with `reviews`. It uses the same writer node from article generation, but the reviews guide it to make specific changes rather than writing from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Running the Edit Article Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Building workflow...\n",
      "\n",
      "2. Configuring workflow...\n",
      "\n",
      "   âœ“ Thread ID: a8309001-6f52-48a0-b2b7-92f73d5f005e\n",
      "3. Running workflow...\n",
      "   This will take several minutes...\n",
      "\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 0,\n",
      "  \"message\": \"Loading context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 5,\n",
      "  \"message\": \"Loaded context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 20,\n",
      "  \"message\": \"Reviewing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 40,\n",
      "  \"message\": \"Generated reviews\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 60,\n",
      "  \"message\": \"Editing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 80,\n",
      "  \"message\": \"Edited article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 100,\n",
      "  \"message\": \"Article editing completed\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Output ----------------------------------------------\u001b[0m\n",
      "  \n",
      "Here is the edited article:\n",
      "\n",
      "<article>\n",
      "    # Workflows vs. Agents: The Critical Decision Every AI Engineer Faces\n",
      "### How to choose between predictable control and autonomous flexibility when building AI applications.\n",
      "\n",
      "Every AI engineer faces a core architectural dilemma: build a predictable, step-by-step workflow, or create an autonomous agent that thinks and decides for itself? This choice impacts development time, costs, reliability, and user experience. It is a decision that shapes the success of an AI application in production.\n",
      "\n",
      "This lesson will help you understand the differences between LLM workflows and AI agents, know when to use each, and learn how to combine their strengths in hybrid approaches.\n",
      "\n",
      "## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a database or calling an API. For example, a workflow might take a user query, retrieve relevant documents from a database, summarize them with an LLM, and then send the summary to the user. The path is determined in advance, resulting in a deterministic or rule-based system. This gives you predictable execution, explicit control over the application's flow, and makes the system easier to test and debug. You know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. Instead, the agent uses a reasoning process to plan its actions based on the task and the current state of its environment. This process is often modeled on frameworks like ReAct (Reason, Act, Observe).\n",
      "\n",
      "For instance, an agent tasked with booking a flight might first search for available flights, then check prices, and finally present options to the user, adapting its steps if a flight is unavailable or too expensive. This allows agents to be adaptive and capable of handling new or unexpected situations through LLM-driven autonomy. They can select tools, execute actions, evaluate the outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent (LLM) Receives Goal\"]\n",
      "    B --> C[\"Plan/Reason (LLM)\"]\n",
      "    C --> D[\"Select Tool\"]\n",
      "    D --> E[\"Execute Action (Tool Call)\"]\n",
      "    E --> F[\"Observe Environment/Feedback\"]\n",
      "    F --> G{\"Evaluate Outcome\"}\n",
      "    G -->|\"Satisfactory\"| H[\"Stop/Achieve Goal\"]\n",
      "    G -->|\"Needs Adjustment\"| C\n",
      "```\n",
      "Image 2: Flowchart illustrating an AI agent's dynamic decision-making process driven by an LLM.\n",
      "\n",
      "## Choosing Your Path\n",
      "\n",
      "The core difference between these two approaches lies in a single trade-off: developer-defined logic versus LLM-driven autonomy [[2]](https://decodingml.substack.com/p/llmops-for-production-agentic-rag), [[3]](https://towardsdatascience.com/a-developers-guide-to-building-scalable-ai-workflows-vs-agents/). Workflows offer high reliability at the cost of flexibility, while agents offer high flexibility at the cost of reliability.\n",
      "\n",
      "https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e64d5e0-7ef1-4e7f-b441-3bf1fef4ff9a_1276x818.png \n",
      "Image 3: The trade-off between an agent's level of control and application reliability. (Image by Iusztin, P. from [Exploring the difference between agents and workflows [2]](https://decodingml.substack.com/p/llmops-for-production-agentic-rag))\n",
      "\n",
      "### When to use LLM workflows\n",
      "\n",
      "Workflows are ideal for repeatable tasks with defined steps. This includes pipelines for data extraction and transformation from sources like the web, Slack, Zoom calls, Notion, and Google Drive. They are also great for automated report or email generation from multiple data sources, repetitive daily tasks such as sending emails or posting social media updates, and content generation or repurposing, like transforming articles into social media posts. Their strength is predictability, ensuring reliable results, easier debugging, and lower costs by using specialized models. The main weakness is rigidity; they cannot handle unexpected scenarios, and adding features can become complex.\n",
      "\n",
      "### When to use AI agents\n",
      "\n",
      "Agents excel at dynamic problem-solving. This includes open-ended research and synthesis, such as researching about World War II, dynamic problem-solving like debugging code or complex customer support, and interactive task completion in unfamiliar environments, like booking a flight without specifying exact sites. Their strength is flexibility in handling ambiguity. However, this autonomy makes them more prone to errors. Agents are non-deterministic, so performance, latency, and costs can vary with each call, making them unreliable. They require larger LLMs that generalize better, which are more costly. Agents also often need more LLM calls to understand user intent and take actions, increasing costs per call. If not designed well, there can be huge security concerns, especially with write operations, where an agent could delete data or send inappropriate emails. Ultimately, agents are hard to debug and evaluate.\n",
      "\n",
      "### Hybrid Approaches\n",
      "\n",
      "Most real-world systems are not purely one or the other. They often blend elements of both, creating a hybrid system. In reality, we have a spectrum, a gradient between LLM workflows and AI agents, where a system adopts what is best from both worlds depending on its use cases. A common pattern is to use a workflow for predictable parts of a task and delegate ambiguous steps to an agent. For example, a system might use a human-in-the-loop workflow, where the agent proposes an action, and a human verifies it before execution.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Human Input\"] --> B[\"LLM Call (AI Generation)\"]\n",
      "    B --> C[\"Action in Environment\"]\n",
      "    C --> D[\"Feedback from Environment\"]\n",
      "    D --> E{\"Human Review/Verification\"}\n",
      "    E -->|\"Approved\"| G[\"Stop/Final Output\"]\n",
      "    E -->|\"Rejected\"| F[\"Continue/Refine\"]\n",
      "    F --> A\n",
      "```\n",
      "Image 4: A flowchart illustrating an AI generation and human verification loop with iterative refinement. (Source [Exploring the difference between agents and workflows [2]](https://decodingml.substack.com/p/llmops-for-production-agentic-rag))\n",
      "\n",
      "## The Challenges of Every AI Engineer\n",
      "\n",
      "Understanding the spectrum from LLM workflows to AI agents is a core part of AI engineering. This choice helps determine if your application will succeed in production. Building AI systems means addressing recurring challenges daily. These include data integration, where you build pipelines to pull information from Slack, web APIs, SQL databases, and data lakes, ensuring only high-quality data reaches your AI system. Another challenge is the cost-performance trap, where sophisticated agents deliver impressive results but cost a lot per user interaction, making them economically unfeasible for many applications. Finally, security concerns arise when autonomous agents with powerful write permissions could send wrong emails, delete critical files, or expose sensitive data.\n",
      "\n",
      "In our next lesson, we will explore context engineering, a skill for building both workflows and agents.\n",
      "\n",
      "## References\n",
      "\n",
      "1. Bouchard, L-F. (n.d.). *Real agents vs. workflows: The truth behind AI 'agents'*. YouTube. https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s\n",
      "2. Iusztin, P. (n.d.). *Exploring the difference between agents and workflows*. Decoding AI Magazine. https://decodingml.substack.com/p/llmops-for-production-agentic-rag\n",
      "3. (n.d.). *A developerâ€™s guide to building scalable AI: Workflows vs agents*. Towards Data Science. https://towardsdatascience.com/a-developers-guide-to-building-scalable-ai-workflows-vs-agents/\n",
      "4. Google. (n.d.). *Gemini CLI*. GitHub. https://github.com/google-gemini/gemini-cli/blob/main/README.md\n",
      "</article>\n",
      "\n",
      "\n",
      "Here is what you have to do with the edited article:\n",
      "- print the edited article to the console for the user to see\n",
      "- give a quick summary of the changes you made\n",
      "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
      "- in case you haven't changed anything, just say that you haven't changed anything\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  WORKFLOW COMPLETED\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from brown.memory import build_in_memory_checkpointer\n",
    "from brown.workflows.edit_article import build_edit_article_workflow\n",
    "\n",
    "async with build_in_memory_checkpointer() as checkpointer:\n",
    "    print(\"1. Building workflow...\\n\")\n",
    "    workflow = build_edit_article_workflow(checkpointer=checkpointer)\n",
    "\n",
    "    print(\"2. Configuring workflow...\\n\")\n",
    "    thread_id = str(uuid.uuid4())\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    print(f\"   âœ“ Thread ID: {thread_id}\")\n",
    "\n",
    "    print(\"3. Running workflow...\")\n",
    "    print(\"   This will take several minutes...\\n\")\n",
    "\n",
    "    async for event in workflow.astream(\n",
    "        {\n",
    "            \"dir_path\": SAMPLE_DIR,\n",
    "            \"human_feedback\": \"\"\"\n",
    "Make the introduction more engaging, catchy and shorter. \n",
    "Also, expand on the definition of both workflows and agents from the first section\"\"\",\n",
    "        },\n",
    "        config=config,\n",
    "        stream_mode=[\"custom\", \"values\"],\n",
    "    ):\n",
    "        event_type, event_data = event\n",
    "        if event_type == \"custom\":\n",
    "            pretty_print.wrapped(event_data, title=\"Event\")\n",
    "        elif event_type == \"values\":\n",
    "            pretty_print.wrapped(event_data, title=\"Output\")\n",
    "\n",
    "pretty_print.wrapped(\"WORKFLOW COMPLETED\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the workflow's output is the edited article. \n",
    "\n",
    "We will explain in more depth the impact of running the review-editing workflow alongside human feedback in the video at the end of the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 The Power of Human Feedback\n",
    "\n",
    "The edit article workflow demonstrates a key advantage of our architecture:\n",
    "\n",
    "**We can use a low number of review loops during initial article generation, and further run them dynamically with a human in the loop when necessary, with more human guidance.**\n",
    "\n",
    "This means:\n",
    "- Initial generation is faster and cheaper with fewer automatic review iterations\n",
    "- We don't assume how many iterations we need to have an ideal output, but let you decide\n",
    "- The workflow runs additional review and editing cycles guided by your feedback\n",
    "- You can repeat this process until satisfied with the results\n",
    "\n",
    "This approach balances efficiency with quality, using AI to handle the heavy lifting while keeping you in control of the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementing the Selected Text Editing Workflow\n",
    "\n",
    "While the edit article workflow handles entire article edits, you'll often want to refine just a specific section. The `edit_selected_text` workflow enables precise, focused edits on selected text portions.\n",
    "\n",
    "The workflow structure is almost identical to `edit_article`, thanks to our clean architecture. The main difference is that it operates on a `SelectedText` entity instead of the full `Article`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Building the Edit Selected Text Workflow\n",
    "\n",
    "The workflow builder follows the same pattern:\n",
    "\n",
    "Source: `brown.workflows.edit_selected_text`\n",
    "```python\n",
    "def build_edit_selected_text_workflow(checkpointer: BaseCheckpointSaver):\n",
    "    \"\"\"Create an edit selected text workflow with checkpointer.\n",
    "\n",
    "    Args:\n",
    "        checkpointer: Checkpointer to use for workflow persistence.\n",
    "\n",
    "    Returns:\n",
    "        Configured workflow entrypoint\n",
    "    \"\"\"\n",
    "\n",
    "    return entrypoint(checkpointer=checkpointer)(_edit_selected_text_workflow)\n",
    "```\n",
    "\n",
    "The workflow expects an `EditSelectedTextInput` typed dictionary:\n",
    "\n",
    "```python\n",
    "class EditSelectedTextInput(TypedDict):\n",
    "    dir_path: Path\n",
    "    human_feedback: str\n",
    "    selected_text: str\n",
    "    number_line_before_selected_text: int\n",
    "    number_line_after_selected_text: int\n",
    "```\n",
    "\n",
    "This input specifies:\n",
    "- `dir_path`: The directory containing the article and supporting files\n",
    "- `human_feedback`: Human feedback to guide the editing\n",
    "- `selected_text`: The specific text portion to edit\n",
    "- `number_line_before_selected_text`: The starting line number in the article\n",
    "- `number_line_after_selected_text`: The ending line number in the article\n",
    "\n",
    "The line numbers help the workflow locate the selected text within the larger article context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 The Edit Selected Text Workflow Logic\n",
    "\n",
    "The main workflow function is structurally similar to `edit_article`:\n",
    "```python\n",
    "async def _edit_selected_text_workflow(inputs: EditSelectedTextInput, config: RunnableConfig) -> str:\n",
    "    writer = get_stream_writer()\n",
    "\n",
    "    # Progress: Loading context\n",
    "    writer(WorkflowProgress(progress=0, message=\"Loading context\").model_dump(mode=\"json\"))\n",
    "    context = {}\n",
    "    loaders = build_loaders(app_config)\n",
    "    for context_name, loader in loaders.items():\n",
    "        loader = cast(Loader, loader)\n",
    "        context[context_name] = loader.load(working_uri=inputs[\"dir_path\"])\n",
    "\n",
    "    selected_text = SelectedText(\n",
    "        article=context[\"article\"],\n",
    "        content=inputs[\"selected_text\"],\n",
    "        first_line_number=inputs[\"number_line_before_selected_text\"],\n",
    "        last_line_number=inputs[\"number_line_after_selected_text\"],\n",
    "    )\n",
    "    human_feedback = HumanFeedback(content=inputs[\"human_feedback\"])\n",
    "    writer(WorkflowProgress(progress=5, message=\"Loaded context\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Reviewing\n",
    "    writer(WorkflowProgress(progress=20, message=\"Reviewing selected text\").model_dump(mode=\"json\"))\n",
    "    reviews = await generate_reviews(selected_text, human_feedback, context[\"article_guideline\"], context[\"profiles\"])\n",
    "    writer(WorkflowProgress(progress=40, message=\"Generated reviews\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Editing\n",
    "    writer(WorkflowProgress(progress=60, message=\"Editing selected text\").model_dump(mode=\"json\"))\n",
    "    selected_text = await edit_based_on_reviews(\n",
    "        context[\"article_guideline\"], context[\"research\"], context[\"profiles\"], context[\"examples\"], reviews\n",
    "    )\n",
    "    writer(WorkflowProgress(progress=80, message=\"Edited selected text\").model_dump(mode=\"json\"))\n",
    "\n",
    "    # Progress: Complete\n",
    "    writer(WorkflowProgress(progress=100, message=\"Selected text editing completed\").model_dump(mode=\"json\"))\n",
    "\n",
    "    return f\"\"\"\n",
    "Here is the edited selected text:\n",
    "{selected_text.to_context()}\n",
    "\n",
    "Here is what you have to do with edited selected text:\n",
    "- print the edited selected text to the console for the user to see\n",
    "- give a quick summary of the changes you made\n",
    "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
    "- in case you haven't changed anything, just say that you haven't changed anything\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "The workflow follows these steps:\n",
    "1. **Load context**: Load the full article and supporting files\n",
    "2. **Create selected text entity**: Build a `SelectedText` entity that contains the selected portion, the full article for context, and line numbers\n",
    "3. **Create human feedback**: Convert the feedback string to a `HumanFeedback` entity\n",
    "4. **Generate reviews**: Review the selected text with human feedback\n",
    "5. **Edit based on reviews**: Edit the selected text based on the reviews\n",
    "6. **Return instructions**: Return the edited selected text with instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Generating Reviews for Selected Text\n",
    "\n",
    "The `generate_reviews` task for selected text is nearly identical to the article version:\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_reviews(\n",
    "    selected_text: SelectedText,\n",
    "    human_feedback: HumanFeedback,\n",
    "    article_guideline: ArticleGuideline,\n",
    "    article_profiles: ArticleProfiles,\n",
    ") -> SelectedTextReviews:\n",
    "    model, _ = build_model(app_config, node=\"review_selected_text\")\n",
    "    selected_text_reviewer = ArticleReviewer(\n",
    "        to_review=selected_text,\n",
    "        human_feedback=human_feedback,\n",
    "        article_guideline=article_guideline,\n",
    "        article_profiles=article_profiles,\n",
    "        model=model,\n",
    "    )\n",
    "    reviews = await selected_text_reviewer.ainvoke()\n",
    "\n",
    "    return cast(SelectedTextReviews, reviews)\n",
    "```\n",
    "\n",
    "The key difference is:\n",
    "- It takes a `SelectedText` instead of `Article`\n",
    "- It returns `SelectedTextReviews` instead of `ArticleReviews`\n",
    "- It uses the \"review_selected_text\" node config\n",
    "\n",
    "The `ArticleReviewer` node is smart enough to handle both cases. When given a `SelectedText`, it focuses reviews on that portion while using the full article as context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Editing Selected Text Based on Reviews\n",
    "\n",
    "The `edit_based_on_reviews` task for selected text also follows the same pattern:\n",
    "```python\n",
    "@task(retry_policy=retry_policy)\n",
    "async def edit_based_on_reviews(\n",
    "    article_guideline: ArticleGuideline,\n",
    "    research: Research,\n",
    "    article_profiles: ArticleProfiles,\n",
    "    article_examples: ArticleExamples,\n",
    "    reviews: SelectedTextReviews,\n",
    ") -> SelectedText:\n",
    "    model, _ = build_model(app_config, node=\"edit_selected_text\")\n",
    "    article_writer = ArticleWriter(\n",
    "        article_guideline=article_guideline,\n",
    "        research=research,\n",
    "        article_profiles=article_profiles,\n",
    "        media_items=MediaItems.build(),\n",
    "        article_examples=article_examples,\n",
    "        reviews=reviews,\n",
    "        model=model,\n",
    "    )\n",
    "    edited_selected_text = cast(SelectedText, await article_writer.ainvoke())\n",
    "\n",
    "    return edited_selected_text\n",
    "```\n",
    "\n",
    "This task:\n",
    "- Takes `SelectedTextReviews` instead of `ArticleReviews`\n",
    "- Returns `SelectedText` instead of `Article`\n",
    "- Uses the \"edit_selected_text\" node config\n",
    "\n",
    "Again, the `ArticleWriter` node handles both article and selected text editing seamlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Why Edit Selected Text?\n",
    "\n",
    "The edit selected text workflow is crucial because:\n",
    "\n",
    "**Most often we don't want to edit the whole article, but just a small section, or apply the human feedback just to a small section.**\n",
    "\n",
    "This workflow enables:\n",
    "- Faster and cheaper edits by focusing on specific sections\n",
    "- More precise changes without affecting other parts of the article\n",
    "- Iterative refinement of individual paragraphs or sections\n",
    "- Better control over the editing process\n",
    "\n",
    "Combined with the edit article workflow, you have complete flexibility to refine content at any granularity you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Running the Edit Selected Text Workflow\n",
    "\n",
    "First, explictly load the selected text that we want to edit from the sample article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- Selected text to edit --------------------------------------\u001b[0m\n",
      "  \n",
      "To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a database or calling an API. Think of it like a recipe where each step is explicitly defined. The key characteristic is that the path is determined in advance, resulting in a deterministic or rule-based system. This gives you predictable execution, explicit control over the application's flow, and makes the system easier to test and debug. Because you control every step, you know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. Instead, the agent uses a reasoning process to plan its actions based on the task and the current state of its environment. This process is often modeled on frameworks like ReAct (Reason, Act, Observe). This allows agents to be adaptive and capable of handling new or unexpected situations through LLM-driven autonomy. They can select tools, execute actions, evaluate the outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent (LLM) Receives Goal\"]\n",
      "    B --> C[\"Plan/Reason (LLM)\"]\n",
      "    C --> D[\"Select Tool\"]\n",
      "    D --> E[\"Execute Action (Tool Call)\"]\n",
      "    E --> F[\"Observe Environment/Feedback\"]\n",
      "    F --> G{\"Evaluate Outcome\"}\n",
      "    G -->|\"Satisfactory\"| H[\"Stop/Achieve Goal\"]\n",
      "    G -->|\"Needs Adjustment\"| C\n",
      "```\n",
      "Image 2: Flowchart illustrating an AI agent's dynamic decision-making process driven by an LLM.\n",
      "\n",
      "## Choosing Your Path\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "article = MarkdownArticleLoader(uri=\"article.md\").load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "start_line = 8\n",
    "end_line = 42\n",
    "selected_text = \"\\n\".join(article.content.split(\"\\n\")[start_line:end_line])\n",
    "pretty_print.wrapped(selected_text, title=\"Selected text to edit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, call the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Building workflow...\n",
      "\n",
      "2. Configuring workflow...\n",
      "\n",
      "   âœ“ Thread ID: f281995f-fef6-4e9f-8887-9cedc09c0710\n",
      "3. Running workflow...\n",
      "   This will take several minutes...\n",
      "\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 0,\n",
      "  \"message\": \"Loading context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 5,\n",
      "  \"message\": \"Loaded context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 20,\n",
      "  \"message\": \"Reviewing selected text\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 40,\n",
      "  \"message\": \"Generated reviews\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 60,\n",
      "  \"message\": \"Editing selected text\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 80,\n",
      "  \"message\": \"Edited selected text\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 100,\n",
      "  \"message\": \"Selected text editing completed\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Output ----------------------------------------------\u001b[0m\n",
      "  \n",
      "Here is the edited selected text:\n",
      "\n",
      "<selected_text>\n",
      "    \n",
      "    <content>To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It combines LLM calls with other operations like reading from a database or calling an API. Each step is explicitly defined, much like a recipe. The path is predefined, resulting in a deterministic, rule-based system, similar to classic programming.\n",
      "\n",
      "This offers predictable execution and explicit control over the application's flow. It makes the system easier to test and debug, as you know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. The agent uses a reasoning process to plan its actions based on the task and environment. This is often modeled on frameworks like ReAct, which cycles through Reason, Act, and Observe.\n",
      "\n",
      "Agents are adaptive and handle new situations through LLM-driven autonomy. They strategize, break down tasks, and plan steps, acting like an intelligent assistant. They select tools, execute actions, evaluate outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent (LLM) Receives Goal\"]\n",
      "    B --> C[\"Plan/Reason (LLM)\"]\n",
      "    C --> D[\"Select Tool\"]\n",
      "    D --> E[\"Execute Action (Tool Call)\"]\n",
      "    E --> F[\"Observe Environment/Feedback\"]\n",
      "    F --> G{\"Evaluate Outcome\"}\n",
      "    G -->|\"Satisfactory\"| H[\"Stop/Achieve Goal\"]\n",
      "    G -->|\"Needs Adjustment\"| C\n",
      "```\n",
      "Image 2: Flowchart illustrating an AI agent's dynamic decision-making process driven by an LLM.\n",
      "\n",
      "## Choosing Your Path</content>\n",
      "    <first_line_number>8</first_line_number>\n",
      "    <last_line_number>42</last_line_number>\n",
      "</selected_text>\n",
      "\n",
      "\n",
      "Here is what you have to do with edited selected text:\n",
      "- print the edited selected text to the console for the user to see\n",
      "- give a quick summary of the changes you made\n",
      "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
      "- in case you haven't changed anything, just say that you haven't changed anything\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  WORKFLOW COMPLETED\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.workflows.edit_selected_text import build_edit_selected_text_workflow\n",
    "\n",
    "async with build_in_memory_checkpointer() as checkpointer:\n",
    "    print(\"1. Building workflow...\\n\")\n",
    "    workflow = build_edit_selected_text_workflow(checkpointer=checkpointer)\n",
    "\n",
    "    print(\"2. Configuring workflow...\\n\")\n",
    "    thread_id = str(uuid.uuid4())\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    print(f\"   âœ“ Thread ID: {thread_id}\")\n",
    "\n",
    "    print(\"3. Running workflow...\")\n",
    "    print(\"   This will take several minutes...\\n\")\n",
    "    async for event in workflow.astream(\n",
    "        {\n",
    "            \"dir_path\": SAMPLE_DIR,\n",
    "            \"human_feedback\": \"Expand on the definition of both workflows and agents.\",\n",
    "            \"selected_text\": selected_text,\n",
    "            \"number_line_before_selected_text\": start_line,\n",
    "            \"number_line_after_selected_text\": end_line,\n",
    "        },\n",
    "        config=config,\n",
    "        stream_mode=[\"custom\", \"values\"],\n",
    "    ):\n",
    "        event_type, event_data = event\n",
    "        if event_type == \"custom\":\n",
    "            pretty_print.wrapped(event_data, title=\"Event\")\n",
    "        elif event_type == \"values\":\n",
    "            pretty_print.wrapped(event_data, title=\"Output\")\n",
    "\n",
    "pretty_print.wrapped(\"WORKFLOW COMPLETED\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the workflow's output is the edited piece of selected text. As with the edit article workflow, we will explain in more depth the impact of running the review-editing workflow alongside human feedback in the video at the end of the lesson.\n",
    "\n",
    "Now, let's move one step closer and see how to properly integrate these two new workflows into a person's daily workflow by serving them as an MCP Server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Serving Brown as an MCP Server\n",
    "\n",
    "Now we'll see how Brown exposes all its workflows as an MCP server. This allows external applications like Claude Desktop and Cursor to use Brown's capabilities through the Model Context Protocol.\n",
    "\n",
    "All the MCP code lives in the `brown.mcp` module, keeping the serving layer completely separate from the domain, app, and infrastructure layers. This separation allows us to potentially serve Brown through different interfaces (CLI, FastAPI, etc.) without changing the core logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 MCP Server and Tools\n",
    "\n",
    "The MCP server is built using FastMCP (the same as the Nova Deep Research Agent, the first capstone project) and exposes three main tools:\n",
    "\n",
    "Source: `brown.mcp.server`\n",
    "```python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Brown MCP Server\")\n",
    "\n",
    "@mcp.tool\n",
    "async def generate_article(dir_path: Path, ctx: Context) -> str:\n",
    "    \"\"\"Generate an article from scratch using Brown's article generation workflow.\n",
    "    \n",
    "    Args:\n",
    "        dir_path: Path to the directory containing article resources\n",
    "        ctx: MCP context for streaming progress updates\n",
    "        \n",
    "    Returns:\n",
    "        A string containing a success confirmation message\n",
    "    \"\"\"\n",
    "    async with build_short_term_memory(app_config) as checkpointer:\n",
    "        generate_article_workflow = build_generate_article_workflow(checkpointer=checkpointer)\n",
    "        \n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        async for chunk in generate_article_workflow.astream({\"dir_path\": dir_path}, config=config, stream_mode=[\"custom\", \"values\"]):\n",
    "            _, chunk_data = chunk\n",
    "            await parse_message(chunk_data, ctx)\n",
    "    \n",
    "    return \"Article generation completed successfully!\"\n",
    "\n",
    "@mcp.tool\n",
    "async def edit_article(\n",
    "    article_path: str,\n",
    "    human_feedback: str,\n",
    "    ctx: Context,\n",
    ") -> str:\n",
    "    \"\"\"Edit an entire article based on human feedback.\n",
    "    \n",
    "    Args:\n",
    "        article_path: Path to the article that has to be edited\n",
    "        human_feedback: User's feedback or instructions for editing\n",
    "        ctx: MCP context for streaming progress updates\n",
    "        \n",
    "    Returns:\n",
    "        The fully edited article content plus instructions\n",
    "    \"\"\"\n",
    "    async with build_short_term_memory(app_config) as checkpointer:\n",
    "        edit_article_workflow = build_edit_article_workflow(checkpointer=checkpointer)\n",
    "        \n",
    "        dir_path = Path(article_path).parent\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        final_result = None\n",
    "        async for chunk in edit_article_workflow.astream(\n",
    "            {\"dir_path\": Path(dir_path), \"human_feedback\": human_feedback},\n",
    "            config=config,\n",
    "            stream_mode=[\"custom\", \"values\"],\n",
    "        ):\n",
    "            chunk_type, chunk_data = chunk\n",
    "            await parse_message(chunk_data, ctx)\n",
    "            \n",
    "            if chunk_type == \"values\":\n",
    "                final_result = chunk_data\n",
    "        \n",
    "    return final_result or \"Article editing completed successfully!\"\n",
    "\n",
    "@mcp.tool\n",
    "async def edit_selected_text(\n",
    "    article_path: str,\n",
    "    human_feedback: str,\n",
    "    selected_text: str,\n",
    "    first_line_number: int,\n",
    "    last_line_number: int,\n",
    "    ctx: Context,\n",
    ") -> str:\n",
    "    \"\"\"Edit a selected section of an article based on human feedback.\n",
    "    \n",
    "    Args:\n",
    "        article_path: Path to the article containing the selected text\n",
    "        human_feedback: User's feedback or instructions\n",
    "        selected_text: The specific text selected from the article\n",
    "        first_line_number: Line number where the selected text starts\n",
    "        last_line_number: Line number where the selected text ends\n",
    "        ctx: MCP context for streaming progress updates\n",
    "        \n",
    "    Returns:\n",
    "        The fully edited selected text plus instructions\n",
    "    \"\"\"\n",
    "    async with build_short_term_memory(app_config) as checkpointer:\n",
    "        edit_selected_text_workflow = build_edit_selected_text_workflow(checkpointer=checkpointer)\n",
    "        \n",
    "        dir_path = Path(article_path).parent\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        final_result = None\n",
    "        async for chunk in edit_selected_text_workflow.astream(\n",
    "            {\n",
    "                \"dir_path\": Path(dir_path),\n",
    "                \"human_feedback\": human_feedback,\n",
    "                \"selected_text\": selected_text,\n",
    "                \"number_line_before_selected_text\": first_line_number,\n",
    "                \"number_line_after_selected_text\": last_line_number,\n",
    "            },\n",
    "            config=config,\n",
    "            stream_mode=[\"custom\", \"values\"],\n",
    "        ):\n",
    "            chunk_type, chunk_data = chunk\n",
    "            await parse_message(chunk_data, ctx)\n",
    "            \n",
    "            if chunk_type == \"values\":\n",
    "                final_result = chunk_data\n",
    "        \n",
    "    return final_result or \"Selected text editing completed successfully!\"\n",
    "```\n",
    "\n",
    "**Each tool:**\n",
    "\n",
    "- Builds the appropriate workflow with an in memory checkpointer, similar to how we ran the workflows so far in these lessons\n",
    "- Creates a unique thread ID for each workflow execution\n",
    "- Most importantly, has detailed pydocs and signatures that will be used by the MCP client to understand what tool to call and how to call it. \n",
    "\n",
    "- Streams progress updates to the MCP client via the `ctx` (context) parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running one of these tools, let's take a look at how we report the progress from each tool through `parse_message` function:\n",
    "```python\n",
    "async def parse_message(chunk_data: dict, ctx: Context, prefix: str = \"\") -> None:\n",
    "    \"\"\"Parse and report workflow streaming messages to the MCP client.\n",
    "\n",
    "    Args:\n",
    "        chunk_data: The streaming data from the workflow, can be a string message\n",
    "                   or a dictionary containing progress information.\n",
    "        ctx: MCP context for sending messages and progress updates to the client.\n",
    "        prefix: Optional prefix to add to all messages for context identification.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If chunk_data is not a supported type (str or dict).\n",
    "    \"\"\"\n",
    "\n",
    "    if prefix:\n",
    "        prefix = f\"{prefix}: \"\n",
    "\n",
    "    if isinstance(chunk_data, str):\n",
    "        await ctx.info(f\"{prefix}{chunk_data}\")\n",
    "    elif isinstance(chunk_data, dict):\n",
    "        message = WorkflowProgress(**chunk_data)\n",
    "        await ctx.info(f\"{prefix}{message.progress}%: {message.message}\")\n",
    "        await ctx.report_progress(progress=message.progress, total=100, message=f\"{prefix}{message.message}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported chunk data type: {type(chunk_data)}\")\n",
    "```\n",
    "\n",
    "Now, let's see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Running the Edit Selected Text Tool\n",
    "\n",
    "Let's see a practical example of using the `edit_selected_text` tool. We'll use the in-memory MCP client to call the tool directly.\n",
    "\n",
    "First, let's import the MCP server and create an in-memory client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-26 17:28:25.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.mcp.server\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mInitializing Brown MCP Server...\u001b[0m\n",
      "\u001b[32m2025-11-26 17:28:25.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.mcp.server\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mBrown MCP Server initialized successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.mcp.server import mcp\n",
    "from fastmcp import Client\n",
    "\n",
    "# Create an in-memory client\n",
    "mcp_client = Client(mcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the `edit_selected_text` tool on a specific set of paragraphs. We'll use the sample example when we ran the workflow directly as a LangGraph workflow.\n",
    "\n",
    "Let's remember how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m-------------------------------------- Selected text to edit --------------------------------------\u001b[0m\n",
      "  \n",
      "To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a database or calling an API. Think of it like a recipe where each step is explicitly defined. The key characteristic is that the path is determined in advance, resulting in a deterministic or rule-based system. This gives you predictable execution, explicit control over the application's flow, and makes the system easier to test and debug. Because you control every step, you know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. Instead, the agent uses a reasoning process to plan its actions based on the task and the current state of its environment. This process is often modeled on frameworks like ReAct (Reason, Act, Observe). This allows agents to be adaptive and capable of handling new or unexpected situations through LLM-driven autonomy. They can select tools, execute actions, evaluate the outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent (LLM) Receives Goal\"]\n",
      "    B --> C[\"Plan/Reason (LLM)\"]\n",
      "    C --> D[\"Select Tool\"]\n",
      "    D --> E[\"Execute Action (Tool Call)\"]\n",
      "    E --> F[\"Observe Environment/Feedback\"]\n",
      "    F --> G{\"Evaluate Outcome\"}\n",
      "    G -->|\"Satisfactory\"| H[\"Stop/Achieve Goal\"]\n",
      "    G -->|\"Needs Adjustment\"| C\n",
      "```\n",
      "Image 2: Flowchart illustrating an AI agent's dynamic decision-making process driven by an LLM.\n",
      "\n",
      "## Choosing Your Path\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "article = MarkdownArticleLoader(uri=\"article.md\").load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "start_line = 8\n",
    "end_line = 42\n",
    "selected_text = \"\\n\".join(article.content.split(\"\\n\")[start_line:end_line])\n",
    "pretty_print.wrapped(selected_text, title=\"Selected text to edit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the tool with human feedback:\n",
    "\n",
    "**Note how we get all these beautiful progress messages while we call the edit selected text workflow!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/26/25 17:28:25] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: Editing selected text from file                 <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         inputs/tests/01_sample_small/article.md                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/26/25 17:28:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: Editing selected text from file                 \u001b]8;id=702713;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=792198;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         inputs/tests/01_sample_small/article.md                                 \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: Using directory `inputs/tests/01_sample_small`  <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         as context                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: Using directory `inputs/tests/01_sample_small`  \u001b]8;id=762305;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=923375;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         as context                                                              \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Editing selected text from file </span>     <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">inputs/tests/01_sample_small/article.md'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'Editing selected text from file \u001b[0m     \u001b]8;id=571742;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703373;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32minputs/tests/01_sample_small/article.md'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                 \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Using directory </span>                     <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">`inputs/tests/01_sample_small` as context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'Using directory \u001b[0m                     \u001b]8;id=780915;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=593038;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m`inputs/tests/01_sample_small` as context'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"Default Project\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=019ac0c7-b897-70a3-971f-16bb615f23a2&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>%: Loading context                             <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m0\u001b[0m%: Loading context                             \u001b]8;id=646869;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=881603;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0%: Loading context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span> <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'0%: Loading context'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m \u001b]8;id=829152;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=834023;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>%: Loaded context                              <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m5\u001b[0m%: Loaded context                              \u001b]8;id=7236;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848036;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5%: Loaded context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>  <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'5%: Loaded context'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m  \u001b]8;id=299448;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=124036;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>%: Reviewing selected text                    <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m20\u001b[0m%: Reviewing selected text                    \u001b]8;id=109908;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=858345;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20%: Reviewing selected text'</span>,       <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'20%: Reviewing selected text'\u001b[0m,       \u001b]8;id=69464;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=455933;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                           \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/26/25 17:28:54] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>%: Generated reviews                          <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/26/25 17:28:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m40\u001b[0m%: Generated reviews                          \u001b]8;id=130273;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=885144;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'40%: Generated reviews'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>:    <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'40%: Generated reviews'\u001b[0m, \u001b[32m'extra'\u001b[0m:    \u001b]8;id=927586;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=145816;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                                    \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>%: Editing selected text                      <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m60\u001b[0m%: Editing selected text                      \u001b]8;id=959854;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=731202;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'60%: Editing selected text'</span>,         <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'60%: Editing selected text'\u001b[0m,         \u001b]8;id=3517;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=912453;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                           \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/26/25 17:29:16] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>%: Edited selected text                       <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/26/25 17:29:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m80\u001b[0m%: Edited selected text                       \u001b]8;id=487123;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=994848;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'80%: Edited selected text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'80%: Edited selected text'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b]8;id=152174;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=937592;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                                                    \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>%: Selected text editing completed           <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client: \u001b[1;36m100\u001b[0m%: Selected text editing completed           \u001b]8;id=80669;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=921276;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'100%: Selected text editing </span>         <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">completed'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'100%: Selected text editing \u001b[0m         \u001b]8;id=432986;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=692862;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mcompleted'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Sending INFO to client:                                                 <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">750</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Here is the edited selected text:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">selected_text</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    </span>                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;content&gt;```xml</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">&lt;selected_text&gt;</span>                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;content&gt;</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">To make the right choice, you first need to understand what LLM </span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">workflows and AI agents are. We will look at their core properties and </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">how they are used, rather than their technical specifics.</span>               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">### LLM Workflows</span>                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">An LLM workflow is a sequence of tasks orchestrated by </span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">developer-written code. It can involve LLM calls, reading from </span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">databases, or calling APIs. Each step is explicitly defined, like a </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">detailed recipe.</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">This predefined path ensures deterministic, rule-based execution. You </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">get predictable results and explicit control, making workflows easier </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">to test and debug. You know exactly where failures occur and how to fix</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">them.</span>                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```mermaid</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">graph TD</span>                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    A</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Start\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> --&gt; B</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Validate Input\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    B --&gt; C</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"LLM Call\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    C --&gt; D</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Process Data\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    D --&gt; E</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Call External API\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    E --&gt; F</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Store Data\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    F --&gt; G</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"End\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```</span>                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Image </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">: A flowchart illustrating a deterministic LLM workflow with </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">clear start and end points, including an LLM call and data operations.</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">### AI Agents</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">AI agents are systems where an LLM dynamically decides the sequence of </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">steps, reasoning, and actions to achieve a goal. Their path is not </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">predefined. The agent plans its actions based on the task and its </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">environment.</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">This dynamic process, often modeled on frameworks like ReAct </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">Reason, </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Act, Observe</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">, allows agents to be adaptive. They handle new situations</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">through LLM-driven autonomy, selecting tools, executing actions, and </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">correcting their course </span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.youtube.com/watch?v=kQxr-uOxw2o&amp;t=1s).</span>                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">Now that we have a clear understanding of what LLM workflows and AI </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">agents are, let's explore their core differences and when to choose </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">each approach for your AI applications.</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">## Choosing Your Path&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">content</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;first_line_number&gt;</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">first_line_number</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;last_line_number&gt;</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">last_line_number</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">selected_text</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">```&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">content</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;first_line_number&gt;</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">first_line_number</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">    &lt;last_line_number&gt;</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">last_line_number</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">selected_text</span><span style=\"font-weight: bold\">&gt;</span>                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Here is what you have to do with edited selected text:                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - print the edited selected text to the console for the user to see     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - give a quick summary of the changes you made                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - always apply the changes to the source file without waiting for the   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         user to explicitly ask you to do so                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         - in case you haven't changed anything, just say that you haven't       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         changed anything                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Sending INFO to client:                                                 \u001b]8;id=868250;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=75235;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/server/context.py#750\u001b\\\u001b[2m750\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         Here is the edited selected text:                                       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m<\u001b[0m\u001b[1;95mselected_text\u001b[0m\u001b[39m>\u001b[0m                                                         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    \u001b[0m                                                                    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <content>```xml\u001b[0m                                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m<selected_text>\u001b[0m                                                         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <content>\u001b[0m                                                           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mTo make the right choice, you first need to understand what LLM \u001b[0m        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mworkflows and AI agents are. We will look at their core properties and \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mhow they are used, rather than their technical specifics.\u001b[0m               \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m### LLM Workflows\u001b[0m                                                       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mAn LLM workflow is a sequence of tasks orchestrated by \u001b[0m                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mdeveloper-written code. It can involve LLM calls, reading from \u001b[0m         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mdatabases, or calling APIs. Each step is explicitly defined, like a \u001b[0m    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mdetailed recipe.\u001b[0m                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mThis predefined path ensures deterministic, rule-based execution. You \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mget predictable results and explicit control, making workflows easier \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mto test and debug. You know exactly where failures occur and how to fix\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mthem.\u001b[0m                                                                   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```mermaid\u001b[0m                                                              \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mgraph TD\u001b[0m                                                                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    A\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Start\"\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m --> B\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Validate Input\"\u001b[0m\u001b[1;39m]\u001b[0m                                  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    B --> C\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"LLM Call\"\u001b[0m\u001b[1;39m]\u001b[0m                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    C --> D\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Process Data\"\u001b[0m\u001b[1;39m]\u001b[0m                                             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    D --> E\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Call External API\"\u001b[0m\u001b[1;39m]\u001b[0m                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    E --> F\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Store Data\"\u001b[0m\u001b[1;39m]\u001b[0m                                               \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    F --> G\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"End\"\u001b[0m\u001b[1;39m]\u001b[0m                                                      \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```\u001b[0m                                                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mImage \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m: A flowchart illustrating a deterministic LLM workflow with \u001b[0m    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mclear start and end points, including an LLM call and data operations.\u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m### AI Agents\u001b[0m                                                           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mAI agents are systems where an LLM dynamically decides the sequence of \u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39msteps, reasoning, and actions to achieve a goal. Their path is not \u001b[0m     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mpredefined. The agent plans its actions based on the task and its \u001b[0m      \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39menvironment.\u001b[0m                                                            \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mThis dynamic process, often modeled on frameworks like ReAct \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mReason, \u001b[0m  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mAct, Observe\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, allows agents to be adaptive. They handle new situations\u001b[0m \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mthrough LLM-driven autonomy, selecting tools, executing actions, and \u001b[0m   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mcorrecting their course \u001b[0m                                                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m(\u001b[0m\u001b[4;94mhttps://www.youtube.com/watch?\u001b[0m\u001b[4;94mv\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94mkQxr\u001b[0m\u001b[4;94m-uOxw2o&\u001b[0m\u001b[4;94mt\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94m1s\u001b[0m\u001b[4;94m)\u001b[0m\u001b[4;94m.\u001b[0m                \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39mNow that we have a clear understanding of what LLM workflows and AI \u001b[0m    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39magents are, let's explore their core differences and when to choose \u001b[0m    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39meach approach for your AI applications.\u001b[0m                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m## Choosing Your Path<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mcontent\u001b[0m\u001b[39m>\u001b[0m                                         \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <first_line_number>\u001b[0m\u001b[1;36m8\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mfirst_line_number\u001b[0m\u001b[39m>\u001b[0m                            \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <last_line_number>\u001b[0m\u001b[1;36m42\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mlast_line_number\u001b[0m\u001b[39m>\u001b[0m                             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mselected_text\u001b[0m\u001b[39m>\u001b[0m                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m```<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mcontent\u001b[0m\u001b[39m>\u001b[0m                                                           \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <first_line_number>\u001b[0m\u001b[1;36m8\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mfirst_line_number\u001b[0m\u001b[39m>\u001b[0m                            \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m    <last_line_number>\u001b[0m\u001b[1;36m42\u001b[0m\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mlast_line_number\u001b[0m\u001b[39m>\u001b[0m                             \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mselected_text\u001b[0m\u001b[1m>\u001b[0m                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Here is what you have to do with edited selected text:                  \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - print the edited selected text to the console for the user to see     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - give a quick summary of the changes you made                          \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - always apply the changes to the source file without waiting for the   \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         user to explicitly ask you to do so                                     \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         - in case you haven't changed anything, just say that you haven't       \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         changed anything                                                        \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                 \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/26/25 17:29:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Received INFO from server: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'msg'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\nHere is the edited selected </span>       <a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">text:\\n\\n&lt;selected_text&gt;\\n    \\n    &lt;content&gt;```xml\\n&lt;selected_text&gt;\\n  </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">&lt;content&gt;\\nTo make the right choice, you first need to understand what </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">LLM workflows and AI agents are. We will look at their core properties </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">and how they are used, rather than their technical specifics.\\n\\n### LLM</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Workflows\\n\\nAn LLM workflow is a sequence of tasks orchestrated by </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">developer-written code. It can involve LLM calls, reading from </span>          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">databases, or calling APIs. Each step is explicitly defined, like a </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">detailed recipe.\\n\\nThis predefined path ensures deterministic, </span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">rule-based execution. You get predictable results and explicit control, </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">making workflows easier to test and debug. You know exactly where </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">failures occur and how to fix them.\\n\\n```mermaid\\ngraph TD\\n    </span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">A[\"Start\"] --&gt; B[\"Validate Input\"]\\n    B --&gt; C[\"LLM Call\"]\\n    C --&gt; </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">D[\"Process Data\"]\\n    D --&gt; E[\"Call External API\"]\\n    E --&gt; F[\"Store </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">Data\"]\\n    F --&gt; G[\"End\"]\\n```\\nImage 1: A flowchart illustrating a </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">deterministic LLM workflow with clear start and end points, including an</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">LLM call and data operations.\\n\\n### AI Agents\\n\\nAI agents are systems </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">where an LLM dynamically decides the sequence of steps, reasoning, and </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">actions to achieve a goal. Their path is not predefined. The agent plans</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">its actions based on the task and its environment.\\n\\nThis dynamic </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">process, often modeled on frameworks like ReAct (Reason, Act, Observe), </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">allows agents to be adaptive. They handle new situations through </span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">LLM-driven autonomy, selecting tools, executing actions, and correcting </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">their course </span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">[[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&amp;t=1s).\\n\\nNow that we </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">have a clear understanding of what LLM workflows and AI agents are, </span>     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">let\\'s explore their core differences and when to choose each approach </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">for your AI applications.\\n\\n## Choosing Your Path&lt;/content&gt;\\n    </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">&lt;first_line_number&gt;8&lt;/first_line_number&gt;\\n    </span>                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">&lt;last_line_number&gt;42&lt;/last_line_number&gt;\\n&lt;/selected_text&gt;\\n```&lt;/content&gt;</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\\n    &lt;first_line_number&gt;8&lt;/first_line_number&gt;\\n    </span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">&lt;last_line_number&gt;42&lt;/last_line_number&gt;\\n&lt;/selected_text&gt;\\n\\n\\nHere is </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">what you have to do with edited selected text:\\n- print the edited </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">selected text to the console for the user to see\\n- give a quick summary</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">of the changes you made\\n- always apply the changes to the source file </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">without waiting for the user to explicitly ask you to do so\\n- in case </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">you haven\\'t changed anything, just say that you haven\\'t changed </span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">anything\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/26/25 17:29:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received INFO from server: \u001b[1m{\u001b[0m\u001b[32m'msg'\u001b[0m: \u001b[32m'\\nHere is the edited selected \u001b[0m       \u001b]8;id=623404;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py\u001b\\\u001b[2mlogging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=792673;file:///Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents/.venv/lib/python3.12/site-packages/fastmcp/client/logging.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mtext:\\n\\n\u001b[0m\u001b[32m<\u001b[0m\u001b[32mselected_text\u001b[0m\u001b[32m>\\n    \\n    <content>```xml\\n<selected_text>\\n  \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m<content>\\nTo make the right choice, you first need to understand what \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mLLM workflows and AI agents are. We will look at their core properties \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mand how they are used, rather than their technical specifics.\\n\\n### LLM\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mWorkflows\\n\\nAn LLM workflow is a sequence of tasks orchestrated by \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mdeveloper-written code. It can involve LLM calls, reading from \u001b[0m          \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mdatabases, or calling APIs. Each step is explicitly defined, like a \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mdetailed recipe.\\n\\nThis predefined path ensures deterministic, \u001b[0m         \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mrule-based execution. You get predictable results and explicit control, \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mmaking workflows easier to test and debug. You know exactly where \u001b[0m       \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mfailures occur and how to fix them.\\n\\n```mermaid\\ngraph TD\\n    \u001b[0m        \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mA\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Start\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m --> B\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Validate Input\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    B --> C\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"LLM Call\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    C --> \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mD\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Process Data\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    D --> E\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Call External API\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    E --> F\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Store \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mData\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n    F --> G\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"End\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n```\\nImage 1: A flowchart illustrating a \u001b[0m    \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mdeterministic LLM workflow with clear start and end points, including an\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mLLM call and data operations.\\n\\n### AI Agents\\n\\nAI agents are systems \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mwhere an LLM dynamically decides the sequence of steps, reasoning, and \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mactions to achieve a goal. Their path is not predefined. The agent plans\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mits actions based on the task and its environment.\\n\\nThis dynamic \u001b[0m      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mprocess, often modeled on frameworks like ReAct \u001b[0m\u001b[32m(\u001b[0m\u001b[32mReason, Act, Observe\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mallows agents to be adaptive. They handle new situations through \u001b[0m        \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mLLM-driven autonomy, selecting tools, executing actions, and correcting \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mtheir course \u001b[0m                                                            \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.youtube.com/watch?\u001b[0m\u001b[32mv\u001b[0m\u001b[32m=\u001b[0m\u001b[32mkQxr\u001b[0m\u001b[32m-uOxw2o&\u001b[0m\u001b[32mt\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nNow that we \u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mhave a clear understanding of what LLM workflows and AI agents are, \u001b[0m     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mlet\\'s explore their core differences and when to choose each approach \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mfor your AI applications.\\n\\n## Choosing Your Path</content>\\n    \u001b[0m       \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m<first_line_number>8</first_line_number>\\n    \u001b[0m                           \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m<last_line_number>42</last_line_number>\\n</selected_text>\\n```</content>\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\\n    <first_line_number>8</first_line_number>\\n    \u001b[0m                     \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m<last_line_number>42</last_line_number>\\n</selected_text\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n\\n\\nHere is \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mwhat you have to do with edited selected text:\\n- print the edited \u001b[0m      \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mselected text to the console for the user to see\\n- give a quick summary\u001b[0m \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mof the changes you made\\n- always apply the changes to the source file \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mwithout waiting for the user to explicitly ask you to do so\\n- in case \u001b[0m  \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32myou haven\\'t changed anything, just say that you haven\\'t changed \u001b[0m       \u001b[2m             \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32manything\\n'\u001b[0m, \u001b[32m'extra'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m                                              \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------ Edit Selected Text Result ------------------------------------\u001b[0m\n",
      "  \n",
      "Here is the edited selected text:\n",
      "\n",
      "<selected_text>\n",
      "    \n",
      "    <content>```xml\n",
      "<selected_text>\n",
      "    <content>\n",
      "To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can involve LLM calls, reading from databases, or calling APIs. Each step is explicitly defined, like a detailed recipe.\n",
      "\n",
      "This predefined path ensures deterministic, rule-based execution. You get predictable results and explicit control, making workflows easier to test and debug. You know exactly where failures occur and how to fix them.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Validate Input\"]\n",
      "    B --> C[\"LLM Call\"]\n",
      "    C --> D[\"Process Data\"]\n",
      "    D --> E[\"Call External API\"]\n",
      "    E --> F[\"Store Data\"]\n",
      "    F --> G[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. Their path is not predefined. The agent plans its actions based on the task and its environment.\n",
      "\n",
      "This dynamic process, often modeled on frameworks like ReAct (Reason, Act, Observe), allows agents to be adaptive. They handle new situations through LLM-driven autonomy, selecting tools, executing actions, and correcting their course [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "Now that we have a clear understanding of what LLM workflows and AI agents are, let's explore their core differences and when to choose each approach for your AI applications.\n",
      "\n",
      "## Choosing Your Path</content>\n",
      "    <first_line_number>8</first_line_number>\n",
      "    <last_line_number>42</last_line_number>\n",
      "</selected_text>\n",
      "```</content>\n",
      "    <first_line_number>8</first_line_number>\n",
      "    <last_line_number>42</last_line_number>\n",
      "</selected_text>\n",
      "\n",
      "\n",
      "Here is what you have to do with edited selected text:\n",
      "- print the edited selected text to the console for the user to see\n",
      "- give a quick summary of the changes you made\n",
      "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
      "- in case you haven't changed anything, just say that you haven't changed anything\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    result = await mcp_client.call_tool(\n",
    "        \"edit_selected_text\",\n",
    "        {\n",
    "            \"article_path\": str(SAMPLE_DIR / \"article.md\"),\n",
    "            \"human_feedback\": \"Expand on the definition of both workflows and agents. Improve the first diagram.\",\n",
    "            \"selected_text\": selected_text,\n",
    "            \"first_line_number\": start_line,\n",
    "            \"last_line_number\": end_line,\n",
    "        },\n",
    "    )\n",
    "    pretty_print.wrapped(\n",
    "        result.data,\n",
    "        title=\"Edit Selected Text Result\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ **Important Observation**\n",
    "\n",
    "Now the question is how do we apply these changes to the original article?\n",
    "\n",
    "Note the text after the `selected_text` XML block we have the following instructions:\n",
    "```text\n",
    "Here is what you have to do with edited selected text:\n",
    "- print the edited selected text to the console for the user to see\n",
    "- give a quick summary of the changes you made\n",
    "- always apply the changes to the source file without waiting for the user to explicitly ask you to do so\n",
    "- in case you haven't changed anything, just say that you haven't changed anything\n",
    "```\n",
    "\n",
    "This instructs the tool consumer, which is the MCP client, such as Cursor, what to do with the new version of the selected text. In this use case, using these instructions, we instruct the MCP Client to always apply these changes to the original article. Otherwise, the edited selected text will be showed within the tool output, but never applied as a patch to the original article.\n",
    "\n",
    "When using this with tools such as Cursor, it will show you the `diff` experience where you have to manually accept the new changes, improving even more the whole human in the loop experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 MCP Prompts\n",
    "\n",
    "MCP prompts provide pre-configured templates that MCP clients can use to easily trigger a tool or a composition of tools (remember the example from Nova the deep research agent). Brown exposes three prompts corresponding to the three tools as an easy way to interface with its functionality:\n",
    "\n",
    "\n",
    "```python\n",
    "@mcp.prompt\n",
    "def generate_article_prompt(dir_path: Path) -> str:\n",
    "    \"\"\"Retrieve a prompt that will trigger the article generation workflow.\"\"\"\n",
    "    return f\"\"\"\n",
    "Using Brown hosted as an MCP server, generate an article using all the necessary resources from \n",
    "the following directory: `{dir_path}`. Don't check if any expected files are missing, just trigger \n",
    "the \"generate_article\" tool of the Brown MCP Server, which will take care of everything.\n",
    "\"\"\"\n",
    "\n",
    "@mcp.prompt\n",
    "def edit_article_prompt(human_feedback: str = \"\") -> str:\n",
    "    \"\"\"Retrieve a prompt that will trigger the article editing workflow.\"\"\"\n",
    "    return f\"\"\"\n",
    "Using Brown hosted as an MCP server, edit an entire article based on human feedback \n",
    "and other expected requirements. Don't check if any expected files are missing, \n",
    "just trigger the \"edit_article\" tool of the Brown MCP Server, which will take care \n",
    "of everything.\n",
    "\n",
    "Human feedback:\n",
    "<human_feedback>\n",
    "{human_feedback}\n",
    "</human_feedback>\n",
    "\n",
    "If the <human_feedback> is empty, you will infer it from the previous messages. If there are no other messages \n",
    "to infer from, use an empty string. Don't ever fill it in with things such as \"Please provide more details\" or\n",
    "fill it in with generic stuff.\n",
    "\"\"\"\n",
    "\n",
    "@mcp.prompt\n",
    "def edit_selected_text_prompt(human_feedback: str = \"\") -> str:\n",
    "    \"\"\"Retrieve a prompt that will trigger the selected text editing workflow.\"\"\"\n",
    "    return f\"\"\"\n",
    "Using Brown hosted as an MCP server, edit the selected text from the article based on human feedback and \n",
    "other expected requirements. Don't check if any expected files are missing, just trigger the \"edit_selected_text\" \n",
    "tool of the Brown MCP Server, which will take care of everything.\n",
    "\n",
    "Human feedback:\n",
    "<human_feedback>\n",
    "{human_feedback}\n",
    "</human_feedback>\n",
    "\n",
    "If the <human_feedback> is empty, you will infer it from the previous messages. If there are no other messages \n",
    "to infer from, use an empty string. Don't ever fill it in with things such as \"Please provide more details\" or\n",
    "fill it in with generic stuff.\n",
    "\"\"\"\n",
    "```\n",
    "These prompts make it easy for users to trigger the MCP's server tool without reading any documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we can access the prompts, starting with the one for generating articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ `user` Message ------------------------------------------\u001b[0m\n",
      "  Role: user\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Content: \n",
      "Using Brown hosted as an MCP server, generate an article using all the necessary resources from \n",
      "the following directory: `inputs/tests/01_sample_small`. Don't check if any expected files are missing, just trigger \n",
      "the \"generate_article\" tool of the Brown MCP Server, which will take care of everything.\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    result = await mcp_client.get_prompt(\n",
    "        \"generate_article_prompt\",\n",
    "        {\n",
    "            \"dir_path\": SAMPLE_DIR,\n",
    "        },\n",
    "    )\n",
    "    for message in result.messages:\n",
    "        pretty_print.wrapped(\n",
    "            [\n",
    "                f\"Role: {message.role}\",\n",
    "                f\"Content: {str(message.content.text)}\",\n",
    "            ],\n",
    "            title=f\"`{message.role}` Message\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look how the one for editing a piece of selected text looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ `user` Message ------------------------------------------\u001b[0m\n",
      "  Role: user\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Content: \n",
      "Using Brown hosted as an MCP server, edit the selected text from the article based on human feedback and \n",
      "other expected requirements. Don't check if any expected files are missing, just trigger the \"edit_selected_text\" \n",
      "tool of the Brown MCP Server, which will take care of everything.\n",
      "\n",
      "Human feedback:\n",
      "<human_feedback>\n",
      "{\"content\":\"Make the introduction more engaging and catchy. \\nAlso, expand on the definition of both workflows and agents from the first section\"}\n",
      "</human_feedback>\n",
      "\n",
      "If the <human_feedback> is empty, you will infer it from the previous messages. If there are no other messages \n",
      "to infer from, use an empty string. Don't ever fill it in with things such as \"Please provide more details\" or\n",
      "fill it in with generic stuff.\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    result = await mcp_client.get_prompt(\n",
    "        \"edit_selected_text_prompt\",\n",
    "        {\n",
    "            \"human_feedback\": human_feedback,\n",
    "        },\n",
    "    )\n",
    "    for message in result.messages:\n",
    "        pretty_print.wrapped(\n",
    "            [\n",
    "                f\"Role: {message.role}\",\n",
    "                f\"Content: {str(message.content.text)}\",\n",
    "            ],\n",
    "            title=f\"`{message.role}` Message\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `edit_article_prompt` is almost identical to `edit_selected_text_prompt`. Thus, we will skip it.\n",
    "\n",
    "Still, the real beauty of using prompts through MCP Servers is when we actually plug in the server into a client such as Cursor that has access to a chatbot that can pick up on the instructions from the retrieved prompts and follows the instructions from it such as calling the generate article tool.\n",
    "\n",
    "This makes prompts an amazing way to interface with MCP Server, for example describing workflows that use the MCP Server tools in various ways, and passing them directly to the client, without letting the consumer worry about how to use them.\n",
    "\n",
    "We will illustrate this in the video attached to this lesson where we will show how this works in Cursor, but a similar behavior applies in other MCP clients, such as Claude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 MCP Resources\n",
    "\n",
    "MCP resources provide read-only access to configuration and state information. Brown exposes resources for accessing the app configuration and profiles:\n",
    "```python\n",
    "@mcp.resource(\"resource://config/app\", mime_type=\"application/json\")\n",
    "def get_app_config() -> dict:\n",
    "    \"\"\"Get the application configuration for Brown Agent as an MCP resource.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The application configuration including:\n",
    "            - Model configurations for each workflow node\n",
    "            - File paths for profiles, examples, and context files\n",
    "            - Number of review iterations and workflow settings\n",
    "            - Temperature and other model parameters\n",
    "    \"\"\"\n",
    "    return app_config.model_dump(mode=\"json\")\n",
    "\n",
    "@mcp.resource(\"resource://profiles/character\")\n",
    "def get_character_profile() -> str:\n",
    "    \"\"\"Get the character profile resource for Brown Agent.\n",
    "    \n",
    "    Returns:\n",
    "        str: The character profile content in markdown format\n",
    "    \"\"\"\n",
    "    return __get_profile(\"character\")\n",
    "```\n",
    "\n",
    "Resources allow MCP clients to understand how Brown is configured without modifying any state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the resources to see the MCP server configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------ `get_app_config` Resource ------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"uri\": \"resource://config/app\",\n",
      "  \"name\": \"get_app_config\",\n",
      "  \"description\": \"Get the application configuration for Brown Agent as an MCP resource.\\n\\nThis resource provides access to the complete Brown Agent configuration,\\nincluding model settings, file paths, and workflow parameters. The configuration\\nis loaded from YAML files and converted to a JSON-serializable format.\\n\\nReturns:\\n    dict: The application configuration as a JSON-serializable dictionary containing:\\n        - Model configurations for each workflow node (write_article, review_article, etc.)\\n        - File paths for profiles, examples, and context files\\n        - Number of review iterations and workflow settings\\n        - Temperature and other model parameters\\n        - Tool configurations and model assignments\",\n",
      "  \"mime_type\": \"application/json\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------- `get_character_profile` Resource ---------------------------------\u001b[0m\n",
      "  {\n",
      "  \"uri\": \"resource://profiles/character\",\n",
      "  \"name\": \"get_character_profile\",\n",
      "  \"description\": \"Get the character profile resource for Brown Agent as an MCP resource.\\n\\nThis resource provides access to the character-specific writing persona\\nthat the Brown Agent uses for consistent article generation and editing.\\nThe character profile defines the voice, perspective, and personal style\\nthat should be reflected in the generated content.\\n\\nThe profile is loaded using the same builders pattern as the workflows,\\nensuring consistency across the Brown Agent system.\\n\\nReturns:\\n    str: The character profile content in markdown format, loaded from\\n         the configured character profile file.\\n\\nRaises:\\n    ValueError: If the character profile cannot be loaded or is not found.\\n\\nExample:\\n    The character profile typically includes information about:\\n    - Writing voice and tone preferences\\n    - Personal background and expertise areas\\n    - Preferred terminology and expressions\\n    - Communication style and approach\",\n",
      "  \"mime_type\": \"text/plain\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    resources = await mcp_client.list_resources()\n",
    "\n",
    "    for resource in resources:\n",
    "        resource_dict = {\n",
    "            \"uri\": str(resource.uri),\n",
    "            \"name\": resource.name,\n",
    "            \"description\": resource.description,\n",
    "            \"mime_type\": resource.mimeType,\n",
    "        }\n",
    "        if hasattr(resource, \"_meta\") and resource._meta:\n",
    "            fastmcp_meta = resource._meta.get(\"_fastmcp\", {})\n",
    "            resource_dict[\"tags\"] = fastmcp_meta.get(\"tags\", [])\n",
    "\n",
    "        pretty_print.wrapped(\n",
    "            resource_dict,\n",
    "            title=f\"`{resource.name}` Resource\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look into each resource independently starting with the app configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------------- App Configuration ----------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"context\": {\n",
      "    \"article_guideline_loader\": \"markdown\",\n",
      "    \"article_guideline_uri\": \"article_guideline.md\",\n",
      "    \"research_loader\": \"markdown\",\n",
      "    \"research_uri\": \"research.md\",\n",
      "    \"article_loader\": \"markdown\",\n",
      "    \"article_renderer\": \"markdown\",\n",
      "    \"article_uri\": \"article.md\",\n",
      "    \"profiles_loader\": \"markdown\",\n",
      "    \"profiles_uri\": \"inputs/profiles\",\n",
      "    \"character_profile\": \"paul_iusztin.md\",\n",
      "    \"examples_loader\": \"markdown\",\n",
      "    \"examples_uri\": \"inputs/examples/course_lessons\"\n",
      "  },\n",
      "  \"memory\": {\n",
      "    \"checkpointer\": \"in_memory\"\n",
      "  },\n",
      "  \"num_reviews\": 2,\n",
      "  \"nodes\": {\n",
      "    \"generate_media_items\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {\n",
      "        \"mermaid_diagram_generator\": {\n",
      "          \"name\": \"mermaid_diagram_generator\",\n",
      "          \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "          \"config\": {\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_k\": null,\n",
      "            \"n\": 1,\n",
      "            \"response_modalities\": null,\n",
      "            \"include_thoughts\": false,\n",
      "            \"thinking_budget\": null,\n",
      "            \"max_output_tokens\": null,\n",
      "            \"max_retries\": 6,\n",
      "            \"mocked_response\": null\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"write_article\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.7,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"review_article\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"edit_article\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.1,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"review_selected_text\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    },\n",
      "    \"edit_selected_text\": {\n",
      "      \"model_id\": \"google_genai:gemini-2.5-flash\",\n",
      "      \"config\": {\n",
      "        \"temperature\": 0.1,\n",
      "        \"top_k\": null,\n",
      "        \"n\": 1,\n",
      "        \"response_modalities\": null,\n",
      "        \"include_thoughts\": false,\n",
      "        \"thinking_budget\": null,\n",
      "        \"max_output_tokens\": null,\n",
      "        \"max_retries\": 6,\n",
      "        \"mocked_response\": null\n",
      "      },\n",
      "      \"tools\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "async with mcp_client:\n",
    "    content = await mcp_client.read_resource(\"resource://config/app\")\n",
    "\n",
    "    pretty_print.wrapped(\n",
    "        json.loads(content[0].text),\n",
    "        title=\"App Configuration\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the character profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------------- Character Profile ----------------------------------------\u001b[0m\n",
      "  ## About Paul Iusztin\n",
      "\n",
      "Iâ€™m **Paul Iusztin**. A 29 years old senior AI Engineer and content creator.\n",
      "\n",
      "I help engineers ship AI products.\n",
      "\n",
      "Iâ€™m the author of the bestseller LLM Engineerâ€™s Handbook, lead instructor of the Agentic AI Engineering course, founding AI Engineer of a San Francisco start-up, and obsessed with making knowledge accessible through AI.\n",
      "\n",
      "With over 10 years of experience and 20 apps shipped, I teach AI Engineering as I wanted to at the beginning of my career. End-to-end. From idea to production. From data collection to deploying, monitoring and evaluation. With a focus on AI principles, software patterns and infrastructure systems that will thrive in a future dominated by AI coding tools.\n",
      "\n",
      "My ultimate goal is to help other engineers escape the PoC purgatory and x10 their AI Engineering skills.\n",
      "\n",
      "I'm also the founder of the **Decoding AI Magazine**, a place for real-world guides takingÂ you from the PoC purgatoryÂ to shipping AI products that work.\n",
      "\n",
      "I founded this magazine to solve the problem I faced for the first five years of my career: escaping the â€œPoC purgatory.â€ I realized that finding a team that knows how to ship AI software is rare. Too many AI projects get stuck at Jupyter Notebooks or fancy demos that never see a real user.\n",
      "\n",
      "Decoding AI is the solution. Itâ€™s your weekly hub for learning how to design, build, and ship production-grade AI systems. End-to-end. From idea to production. From data collection to deploying, monitoring and evaluation. With a focus on AI principles, software patterns and infrastructure systems that will thrive in a future dominated by AI coding tools.\n",
      "\n",
      "Stop building prototypes. Start shipping AI that works.\n",
      "\n",
      "## Niche\n",
      "\n",
      "**Broad:** AI Engineering, AI Systems, Software Engineering, Ops\n",
      "**Specialized**: RAG, LLMs, AI Agents, AI Workflows, LLMOps, AI Evals, AI Monitoring, AI Infrastructure, Serving AI Applications, Memory\n",
      "**Vibe:** premium, minimalistic, high-quality content, straight-to-the-point content (the opposite of FOMO), zero hype, artsy, builder mindset, deep and real\n",
      "\n",
      "## Similar Personas\n",
      "\n",
      "- Andrew Ng\n",
      "- Chip Huyen\n",
      "- Sebastian Raschka\n",
      "- Louis-FranÃ§ois Bouchard\n",
      "- Maxime Labonne\n",
      "- Jason Liu\n",
      "- Lex Fridman\n",
      "- Aleksa Gordic\n",
      "\n",
      "## My Core Content Pillars I Always Talk About\n",
      "\n",
      "1. Shipping Production-Ready AI\n",
      "2. Practical Learning for AI Engineers\n",
      "3. Behind-the-Scenes of Building in Public\n",
      "4. AI for Founders & Technical Teams \n",
      "\n",
      "## Style\n",
      "\n",
      "- **Real:** Showing the engineering, social, and economic truth behind AI and content creation\n",
      "- **Trust:** No FOMO, just real engineering focusing on what matters\n",
      "- **Minimalist:** Straight to the point engineering. Use only what is required to get shit done.\n",
      "- **Simple:** â€œKeep it simpleâ€ should be the motto of your persona. Focus on what matters while avoiding FOMO and fluff just to get attention\n",
      "- **Controversy:**\n",
      "    - Talk about what everybody thinks, but they're too afraid to say out loud.\n",
      "    - Going against the flow, Gary Marcus style: \"LLMs are stupid,\" \"Agents are stupid,â€ \"LangChain is stupid\".\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with mcp_client:\n",
    "    content = await mcp_client.read_resource(\"resource://profiles/character\")\n",
    "\n",
    "    pretty_print.wrapped(\n",
    "        content[0].text,\n",
    "        title=\"Character Profile\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Clean Separation of MCP Layer\n",
    "\n",
    "Notice how all the MCP code lives in the `brown.mcp` module and simply imports from other layers:\n",
    "\n",
    "- **Domain layer**: Imports entities like `Article`, `HumanFeedback`, `Review`\n",
    "- **App layer**: Imports workflows like `build_edit_article_workflow`, `build_edit_selected_text_workflow`\n",
    "- **Infrastructure layer**: Imports builders like `build_loaders`, `build_short_term_memory`\n",
    "\n",
    "The MCP layer is just a thin serving/interface layer that orchestrates the other components. This separation means:\n",
    "\n",
    "- We can serve Brown through different methods (CLI, FastAPI, gRPC) without changing core logic\n",
    "- The MCP code is independent and can be modified without affecting other layers\n",
    "- We can easily add new MCP tools, prompts, or resources\n",
    "- Testing is easier because each layer has clear boundaries\n",
    "\n",
    "This is a key advantage of using clean architecture principles throughout the Brown project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Brown's MCP Server Through the CLI\n",
    "\n",
    "Brown includes a command-line interface that lets you interact with the MCP server directly from your terminal. This is useful for scripting, automation, and quick testing.\n",
    "\n",
    "The CLI script is located at `lessons/writing_workflow/scripts/brown_mcp_cli.py` and provides three main commands:\n",
    "\n",
    "1. **generate-article**: Generate an article from scratch\n",
    "2. **edit-article**: Edit an entire article based on human feedback\n",
    "3. **edit-selected-text**: Edit a selected section of an article\n",
    "\n",
    "âš ï¸ You can run these only from the Brown standalone project from `lessons/writing_workflow`.\n",
    "\n",
    "### Usage Examples\n",
    "\n",
    "Here is how the CLI commands look like:\n",
    "```bash\n",
    "# Generate an article\n",
    "python scripts/brown_mcp_cli.py generate-article --dir-path /path/to/article\n",
    "\n",
    "# Edit an entire article\n",
    "python scripts/brown_mcp_cli.py edit-article \\\n",
    "    --dir-path /path/to/article \\\n",
    "    --human-feedback \"Make the introduction more engaging\"\n",
    "\n",
    "# Edit selected text\n",
    "python scripts/brown_mcp_cli.py edit-selected-text \\\n",
    "    --dir-path /path/to/article \\\n",
    "    --human-feedback \"Make this shorter. Remove all em-dashes.\" \\\n",
    "    --first-line 10 \\\n",
    "    --last-line 20\n",
    "```\n",
    "\n",
    "The CLI uses the in-memory MCP client to call the MCP server tools, providing a simple interface for Brown's capabilities.\n",
    "\n",
    "### How to run it?\n",
    "\n",
    "> [!NOTE]\n",
    "> ðŸ’¡ For more details on running these CLI commands while using Brown as a standalone project, see the documentation from [lessons/writing_workflow](../writing_workflow/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using Brown's MCP Server Through the Cursor IDE\n",
    "\n",
    "The real power of Brown comes when integrating it with MCP clients like Cursor. This creates a writing experience similar to coding with AI assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Cursor Configuration\n",
    "\n",
    "To use Brown with Cursor, you need to configure it in your `.cursor/mcp.json` file (similar to what we did for Nova, the research agent).\n",
    "\n",
    "Open up this repository with Cursor and add the following config within your `.cursor/mcp.json` file. Create it, if it doesn't exists:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"brown\": {\n",
    "            \"command\": \"uv\",\n",
    "            \"args\": [\n",
    "                \"--directory\",\n",
    "                \"lessons/writing_workflow/\",\n",
    "                \"run\",\n",
    "                \"python\",\n",
    "                \"-m\",\n",
    "                \"brown.mcp.server\"\n",
    "            ],\n",
    "            \"cwd\": \"${workspaceFolder}\",\n",
    "            \"env\": {\n",
    "                \"ENV_FILE_PATH\": \"${workspaceFolder}/.env\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "...or if you already have other `mcpServers` added like the deep research agent, add `brown` along them, like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"nova\": {\n",
    "            \"command\": \"uv\",\n",
    "            \"args\": [\n",
    "                \"--directory\",\n",
    "                \"lessons/research_agent_part_2/mcp_server\",\n",
    "                \"run\",\n",
    "                \"-m\",\n",
    "                \"src.server\",\n",
    "                \"--transport\",\n",
    "                \"stdio\"\n",
    "            ],\n",
    "            \"cwd\": \"${workspaceFolder}\",\n",
    "            \"env\": {\n",
    "                \"ENV_FILE_PATH\": \"${workspaceFolder}/.env\"\n",
    "            }\n",
    "        },\n",
    "        \"brown\": {\n",
    "            \"command\": \"uv\",\n",
    "            \"args\": [\n",
    "                \"--directory\",\n",
    "                \"lessons/writing_workflow/\",\n",
    "                \"run\",\n",
    "                \"python\",\n",
    "                \"-m\",\n",
    "                \"brown.mcp.server\"\n",
    "            ],\n",
    "            \"cwd\": \"${workspaceFolder}\",\n",
    "            \"env\": {\n",
    "                \"ENV_FILE_PATH\": \"${workspaceFolder}/.env\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "This configuration tells Cursor:\n",
    "\n",
    "- The name of the MCP server (\"brown\", \"nova\")\n",
    "- How to launch the server using `uv` and Python\n",
    "- The working directory\n",
    "- Where to load the environment variables. Ensure your `.env` file is located at `${workspaceFolder}/.env`, where `${workspaceFolder}` is the root of the project.\n",
    "\n",
    "Once configured, go to Cursor's settings `Tools & MCP` section and ensure it has discovered `brown` (with a green light) as an MCP server with tools, prompts and resources available.\n",
    "\n",
    "More on how to use Brown with Cursor in the video from the lesson!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 The Brown + Human-in-the-Loop Writing Experience\n",
    "\n",
    "With Brown integrated into Cursor, your writing workflow becomes:\n",
    "\n",
    "1. **Generate Initial Article**: Use the `generate_article` tool or prompt to create a first draft\n",
    "2. **Review as Human Expert**: Read through the generated article with your domain expertise\n",
    "3. **Provide Feedback**: Select sections that need improvement and provide specific feedback\n",
    "4. **AI Edits**: Use `edit_article` or `edit_selected_text` tools to refine based on your feedback\n",
    "5. **Iterate**: Repeat steps 2-4 until satisfied with the article\n",
    "\n",
    "This creates a collaborative experience where:\n",
    "- AI handles the heavy lifting of writing and editing\n",
    "- You guide the direction with your expertise and feedback\n",
    "- The workflow is fast and iterative\n",
    "- You maintain full control over the final output\n",
    "\n",
    "## 9. Running Brown Through the MCP Server (Video)\n",
    "\n",
    "We've created a video demonstration showing how to use Brown's human-in-the-loop features, while using it through the MCP Server in Cursor.\n",
    "\n",
    "[Link to video demonstration will be provided]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this lesson, we've explored how to implement human-in-the-loop capabilities in the Brown writing workflow. Let's recap what we've learned and look at future possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We've Learned\n",
    "\n",
    "1. **Human-in-the-Loop**: We learned how to design AI workflows that balance automation with human expertise, allowing AI to handle heavy lifting while keeping humans in control\n",
    "\n",
    "2. **Edit Article Workflow**: We implemented the `edit_article` workflow that reviews and edits entire articles based on human feedback and expected requirements\n",
    "\n",
    "3. **Edit Selected Text Workflow**: We built the `edit_selected_text` workflow for precise, focused edits on specific article sections\n",
    "\n",
    "4. **MCP Server**: We served Brown as an MCP server with tools, prompts, and resources while respecting clean architecture principles\n",
    "\n",
    "5. **Cursor Integration**: We learned how to integrate Brown with Cursor to create a coding-like writing experience with human-in-the-loop editing\n",
    "\n",
    "The key insight is that we can use a low number of review loops during initial article generation, then dynamically run additional editing workflows with human feedback when necessary. This approach is both efficient and effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Extension Ideas\n",
    "\n",
    "Here are some ways you can extend Brown to fit your needs:\n",
    "\n",
    "1. **Hook Brown to Claude Desktop**: Instead of using Cursor, integrate Brown with Claude Desktop for a different AI assistant experience\n",
    "\n",
    "2. **Use Resource Templates** to parameterize the writing profiles and easily add support for all the available profiles. [More here](https://gofastmcp.com/servers/resources#resource-templates).\n",
    "\n",
    "3. **Serve Brown through FastAPI**: Replace the MCP server with a FastAPI REST API for web-based integrations\n",
    "\n",
    "4. **Add Guideline Review Tool**: Create a workflow to review and edit your article guidelines themselves, helping you refine your inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Up Brown\n",
    "\n",
    "With this lesson, we've wrapped up our exploration of the Brown writing workflow. We've covered:\n",
    "\n",
    "- **Lesson 22**: Foundation of the writing workflow with entities, nodes, and basic workflows\n",
    "- **Lesson 23**: The evaluator-optimizer pattern with article reviews and iterative refinement\n",
    "- **Lesson 24**: Human-in-the-loop implementation with MCP server integration\n",
    "\n",
    "Together, these lessons show how to build a production-ready AI writing system that:\n",
    "- Generates high-quality articles from research and guidelines\n",
    "- Uses multiple review loops to ensure quality\n",
    "- Integrates human feedback for iterative refinement\n",
    "- Exposes capabilities through standard protocols like MCP\n",
    "- Maintains clean architecture for extensibility and maintainability\n",
    "\n",
    "In future lessons, we'll explore how to orchestrate Nova and Brown as a multi-agent system. \n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Brown Package**: Explore `lessons/writing_workflow`\n",
    "- **Configuration Examples**: Check `configs/` for different configurations\n",
    "- **Test Data**: Use `inputs/tests/` for additional testing scenarios\n",
    "- **Writing Profiles**: Check `inputs/profiles/` for more profile templates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
