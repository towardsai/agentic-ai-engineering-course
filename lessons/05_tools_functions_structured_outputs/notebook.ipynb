{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools and Structured Outputs with Gemini\n",
    "\n",
    "This notebook explores two powerful features for building capable AI agents with Large Language Models (LLMs): **Tools (Function Calling)** and **Structured Outputs**. We will use the `google-genai` library to interact with Google's Gemini models.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "1.  **Understand and implement tool use (function calling)** to allow an LLM to interact with external systems.\n",
    "2.  **Enforce structured data formats (JSON)** from an LLM for reliable data extraction.\n",
    "3.  **Leverage Pydantic models** to define and manage complex data structures for both function arguments and structured outputs, improving code robustness and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the necessary Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -q google-generativeai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API Key\n",
    "\n",
    "To use the Gemini API, you need an API key. \n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
    "2.  Create a file named `.env` in the root of this project.\n",
    "3.  Add the following line to the `.env` file, replacing `your_api_key_here` with your actual key:\n",
    "    ```\n",
    "    GEMINI_API_KEY=\"your_api_key_here\"\n",
    "    ```\n",
    "The code below will load this key from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY_ROOT_DIR=`/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "REPOSITORY_ROOT_DIR = Path().absolute().parent.parent\n",
    "print(f\"REPOSITORY_ROOT_DIR=`{REPOSITORY_ROOT_DIR}`\")\n",
    "\n",
    "try:\n",
    "    load_dotenv(dotenv_path=REPOSITORY_ROOT_DIR / \".env\")\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"dotenv package not found. Please install it with 'pip install python-dotenv'\"\n",
    "    )\n",
    "\n",
    "assert \"GOOGLE_API_KEY\" in os.environ, \"`GOOGLE_API_KEY` is not set\"\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Generative Model\n",
    "\n",
    "We will use the `gemini-1.5-flash-latest` model, which is fast, cost-effective, and supports advanced features like tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing tool calls from scratch\n",
    "\n",
    "LLMs are trained on text and can't perform actions in the real world on their own. **Tools** (or **Function Calling**) are the mechanism we use to bridge this gap. We provide the LLM with a list of available tools, and it can decide which one to use and with what arguments to fulfill a user's request.\n",
    "\n",
    "The process is a loop:\n",
    "1.  **You**: Send the LLM a prompt and a list of available tools.\n",
    "2.  **LLM**: Responds with a `function_call` request, specifying the tool and arguments.\n",
    "3.  **You**: Execute the requested function in your code.\n",
    "4.  **You**: Send the function's output back to the LLM.\n",
    "5.  **LLM**: Uses the tool's output to generate a final, user-facing response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Mock Tools\n",
    "\n",
    "Let's create two simple, mocked functions. One simulates searching Google Drive, and the other simulates sending a Discord message. The function docstrings are crucial, as the LLM uses them to understand what each tool does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_drive(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for a file on Google Drive and returns its content or a summary.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to find the file, e.g., 'Q3 earnings report'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representing the search results, including file names and summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"---> Searching Google Drive for: '{query}'\")\n",
    "    # In a real scenario, this would interact with the Google Drive API.\n",
    "    # Here, we mock the response for demonstration.\n",
    "    if \"q3 earnings report\" in query.lower():\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"files\": [\n",
    "                    {\n",
    "                        \"name\": \"Q3_Earnings_Report_2024.pdf\",\n",
    "                        \"id\": \"file12345\",\n",
    "                        \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return json.dumps({\"files\": []})\n",
    "\n",
    "\n",
    "def send_discord_message(channel_id: str, message: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a message to a specific Discord channel.\n",
    "\n",
    "    Args:\n",
    "        channel_id (str): The ID of the channel to send the message to, e.g., '#finance'.\n",
    "        message (str): The content of the message to send.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string confirming the action, e.g., '{\"status\": \"success\"}'.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"---> Sending message to Discord channel '{channel_id}': '{message}'\")\n",
    "    # Mocking a successful API call\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"status\": \"success\",\n",
    "            \"channel\": channel_id,\n",
    "            \"message_preview\": f\"{message[:50]}...\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_sum(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the sum of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): The first number.\n",
    "        b (int): The second number.\n",
    "\n",
    "    Returns:\n",
    "        int: The sum of the two numbers.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_google_drive_declaration = {\n",
    "    \"name\": \"search_google_drive\",\n",
    "    \"description\": \"Searches for a file on Google Drive and returns its content or a summary.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query to find the file, e.g., 'Q3 earnings report'.\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "send_discord_message_declaration = {\n",
    "    \"name\": \"send_discord_message\",\n",
    "    \"description\": \"Sends a message to a specific Discord channel.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"channel_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The ID of the channel to send the message to, e.g., '#finance'.\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The content of the message to send.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"channel_id\", \"message\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "calculate_sum_declaration = {\n",
    "    \"name\": \"calculate_sum\",\n",
    "    \"description\": \"Calculates the sum of two numbers.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The first number.\",\n",
    "            },\n",
    "            \"b\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The second number.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "TOOLS = {\n",
    "    \"search_google_drive\": {\n",
    "        \"handler\": search_google_drive,\n",
    "        \"declaration\": search_google_drive_declaration,\n",
    "    },\n",
    "    \"send_discord_message\": {\n",
    "        \"handler\": send_discord_message,\n",
    "        \"declaration\": send_discord_message_declaration,\n",
    "    },\n",
    "    \"calculate_sum\": {\n",
    "        \"handler\": calculate_sum,\n",
    "        \"declaration\": calculate_sum_declaration,\n",
    "    },\n",
    "}\n",
    "TOOLS_BY_NAME = {tool_name: tool[\"handler\"] for tool_name, tool in TOOLS.items()}\n",
    "TOOLS_SCHEMA = [tool[\"declaration\"] for tool in TOOLS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_google_drive': <function __main__.search_google_drive(query: str) -> str>,\n",
       " 'send_discord_message': <function __main__.send_discord_message(channel_id: str, message: str) -> str>,\n",
       " 'calculate_sum': <function __main__.calculate_sum(a: int, b: int) -> int>}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOLS_BY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_google_drive',\n",
       "  'description': 'Searches for a file on Google Drive and returns its content or a summary.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': \"The search query to find the file, e.g., 'Q3 earnings report'.\"}},\n",
       "   'required': ['query']}},\n",
       " {'name': 'send_discord_message',\n",
       "  'description': 'Sends a message to a specific Discord channel.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'channel_id': {'type': 'string',\n",
       "     'description': \"The ID of the channel to send the message to, e.g., '#finance'.\"},\n",
       "    'message': {'type': 'string',\n",
       "     'description': 'The content of the message to send.'}},\n",
       "   'required': ['channel_id', 'message']}},\n",
       " {'name': 'calculate_sum',\n",
       "  'description': 'Calculates the sum of two numbers.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'number', 'description': 'The first number.'},\n",
       "    'b': {'type': 'number', 'description': 'The second number.'}},\n",
       "   'required': ['a', 'b']}}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOLS_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can use tools to help the user. \n",
    "\n",
    "In case you need to use a tool from the provided list of tools, output the tool name and the arguments in the following format:\n",
    "TOOL_CALL: {{\"name\": \"tool_name\", \"args\": {{\"arg1\": \"value1\", \"arg2\": \"value2\"}}}}\n",
    "\n",
    "If you need to use a tool call, OUTPUT ONLY THE TOOL CALL, such as:\n",
    "<output>\n",
    "```tool_call\n",
    "{{\"name\": \"tool_name\", \"args\": {{\"arg1\": \"value1\", \"arg2\": \"value2\"}}}}\n",
    "```\n",
    "</output>\n",
    "\n",
    "If there is no need to use a tool, just output the response directly.\n",
    "\n",
    "<tool_definitions>\n",
    "{tools}\n",
    "</tool_definitions>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```tool_call\\n{\"name\": \"search_google_drive\", \"args\": {\"query\": \"Q3 earnings report\"}}\\n```'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
    "the #finance channel on Discord.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SYSTEM_PROMPT.format(tools=str(TOOLS)),\n",
    "    USER_PROMPT\n",
    "]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=messages,\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"search_google_drive\", \"args\": {\"query\": \"Q3 earnings report\"}}'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_tool_call(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the tool call from the response text.\n",
    "    \"\"\"\n",
    "    return response_text.split(\"```tool_call\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "tool_call_str = extract_tool_call(response.text)\n",
    "tool_call_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_google_drive', 'args': {'query': 'Q3 earnings report'}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = json.loads(tool_call_str)\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search_google_drive(query: str) -> str>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler = TOOLS_BY_NAME[tool_call[\"name\"]]\n",
    "tool_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Searching Google Drive for: 'Q3 earnings report'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler(**tool_call[\"args\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing tool calls with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt: \n",
      "Please find the Q3 earnings report on Google Drive and send a summary of it to \n",
      "the #finance channel on Discord.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(**search_google_drive_declaration),\n",
    "            types.FunctionDeclaration(**send_discord_message_declaration),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=tools,\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 1. First call to the model\n",
    "print(f\"User Prompt: {USER_PROMPT}\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=USER_PROMPT,\n",
    "    config=config,\n",
    ")\n",
    "response_message = response.candidates[0].content.parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'query': 'Q3 earnings report'}, name='search_google_drive'), function_response=None, text=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(id=None, args={'query': 'Q3 earnings report'}, name='search_google_drive')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search_google_drive(query: str) -> str>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler = TOOLS_BY_NAME[response_message.function_call.name]\n",
    "tool_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Searching Google Drive for: 'Q3 earnings report'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_handler(**response_message.function_call.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implementing tool calls with Gemini: Running tools in a loop\n",
    "\n",
    "Now, let's create a scenario where we ask the agent to perform a multi-step task: find a report and then communicate its findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt: \n",
      "You are a helpful assistant that can use tools to help the user.\n",
      "\n",
      "\n",
      "<tool_definitions>\n",
      "{TOOLS}\n",
      "</tool_definitions>\n",
      "\n",
      "<user_prompt>\n",
      "{prompt}\n",
      "</user_prompt>\n",
      "\n",
      "\n",
      "Model's first response: id=None args={'query': 'Q3 earnings report'} name='search_google_drive'\n",
      "---> Searching Google Drive for: 'Q3 earnings report'\n",
      "\n",
      "Sending tool result back to model: {\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}\n",
      "\n",
      "Model's next response: video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={'channel_id': '#finance', 'message': 'Q3 Earnings Report: Revenue increased by 20%, user engagement grew by 15%, exceeding expectations. বিস্তারিত জানতে: file12345'}, name='send_discord_message') function_response=None text=None\n",
      "---> Sending message to Discord channel '#finance': 'Q3 Earnings Report: Revenue increased by 20%, user engagement grew by 15%, exceeding expectations. বিস্তারিত জানতে: file12345'\n",
      "\n",
      "Sending tool result back to model: {\"status\": \"success\", \"channel\": \"#finance\", \"message_preview\": \"Q3 Earnings Report: Revenue increased by 20%, user...\"}\n",
      "\n",
      "Model's next response: video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={'message': 'Q3 Earnings Report: Revenue increased by 20%, user engagement grew by 15%, exceeding expectations. See file file12345 for details.', 'channel_id': '#finance'}, name='send_discord_message') function_response=None text=None\n",
      "---> Sending message to Discord channel '#finance': 'Q3 Earnings Report: Revenue increased by 20%, user engagement grew by 15%, exceeding expectations. See file file12345 for details.'\n",
      "\n",
      "Sending tool result back to model: {\"status\": \"success\", \"channel\": \"#finance\", \"message_preview\": \"Q3 Earnings Report: Revenue increased by 20%, user...\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's next response: video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={'message': 'Q3 Earnings Report: Revenue increased by 20%, user engagement grew by 15%, exceeding expectations. More details: file12345', 'channel_id': '#finance'}, name='send_discord_message') function_response=None text=None\n",
      "\n",
      "--- Final Agent Response ---\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Rewrite this to show how we can run tool calls in a loop until no \n",
    "# other function calls are needed.\n",
    "\n",
    "\n",
    "# Create a lookup for the actual Python functions\n",
    "tool_functions = {\n",
    "    func.__name__: func for func in [search_google_drive, send_discord_message]\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(**search_google_drive_declaration),\n",
    "            types.FunctionDeclaration(**send_discord_message_declaration),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=tools,\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 1. First call to the model\n",
    "print(f\"User Prompt: {prompt}\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=USER_PROMPT,\n",
    "    config=config,\n",
    ")\n",
    "response_message = response.candidates[0].content.parts[0]\n",
    "\n",
    "print(f\"\\nModel's first response: {response_message.function_call}\")\n",
    "\n",
    "# Keep a list of messages to send back to the model\n",
    "messages = [response.candidates[0].content]\n",
    "\n",
    "# Loop to handle multiple function calls\n",
    "max_iterations = 3\n",
    "while hasattr(response_message, \"function_call\") and max_iterations > 0:\n",
    "    function_call = response_message.function_call\n",
    "    function_name = function_call.name\n",
    "\n",
    "    # 2. Execute the function requested by the model\n",
    "    if function_name in tool_functions:\n",
    "        selected_function = tool_functions[function_name]\n",
    "        args = {key: value for key, value in function_call.args.items()}\n",
    "        tool_result = selected_function(**args)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown function call: {function_name}\")\n",
    "\n",
    "    # 3. Send the result back to the model\n",
    "    print(f\"\\nSending tool result back to model: {tool_result}\")\n",
    "    function_response_part = types.Part(\n",
    "        function_response=types.FunctionResponse(\n",
    "            name=function_name, response=json.loads(tool_result)\n",
    "        )\n",
    "    )\n",
    "    messages.append(function_response_part)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=messages,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # The model may call another function or return a text response\n",
    "    response_message = response.candidates[0].content.parts[0]\n",
    "    messages.append(response.candidates[0].content)\n",
    "\n",
    "    print(f\"\\nModel's next response: {response_message}\")\n",
    "\n",
    "    max_iterations -= 1\n",
    "\n",
    "# 4. Print the final, user-facing answer\n",
    "print(\"\\n--- Final Agent Response ---\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementing structured outputs from scratch using JSON\n",
    "\n",
    "Sometimes, you don't need the LLM to take an action, but you need its output in a specific, machine-readable format. Forcing the output to be JSON is a common way to achieve this.\n",
    "\n",
    "We can instruct the model to do this by:\n",
    "1.  **Prompting**: Clearly describe the desired JSON structure in the prompt.\n",
    "2.  **Configuration**: Setting `response_mime_type` to `\"application/json\"` in the generation configuration, which forces the model's output to be a valid JSON object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Extracting Metadata from a Document\n",
    "\n",
    "Let's imagine we have a markdown document and we want to extract key information like a summary, tags, and keywords into a clean JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"summary\": \"The article discusses the advancements in AI, focusing on autonomous agents and their ability to perform complex tasks using LLMs. Key topics include the ReAct framework, tool use, and long-term planning.\",\n",
      "  \"tags\": [\"AI\", \"autonomous agents\", \"LLMs\", \"ReAct framework\", \"tool use\", \"long-term planning\"],\n",
      "  \"keywords\": [\"AI agents\", \"Large Language Models\", \"autonomous agents\", \"ReAct\", \"tool use\", \"planning\"]\n",
      "}\n",
      "\n",
      "--- Parsed JSON Object ---\n",
      "{'summary': 'The article discusses the advancements in AI, focusing on autonomous agents and their ability to perform complex tasks using LLMs. Key topics include the ReAct framework, tool use, and long-term planning.', 'tags': ['AI', 'autonomous agents', 'LLMs', 'ReAct framework', 'tool use', 'long-term planning'], 'keywords': ['AI agents', 'Large Language Models', 'autonomous agents', 'ReAct', 'tool use', 'planning']}\n"
     ]
    }
   ],
   "source": [
    "document = \"\"\"\n",
    "# Article: The Rise of AI Agents\n",
    "\n",
    "This article discusses the recent advancements in AI, focusing on autonomous agents. \n",
    "We explore how Large Language Models (LLMs) are moving beyond simple text generation \n",
    "to perform complex, multi-step tasks. Key topics include the ReAct framework, \n",
    "the importance of tool use, and the challenges of long-term planning. The future \n",
    "of software development may be significantly impacted by these new AI paradigms.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract metadata from it. \n",
    "The output must be a single, valid JSON object with the following structure:\n",
    "{{ \"summary\": \"A concise summary of the article.\", \"tags\": [\"list\", \"of\", \"relevant\", \"tags\"], \"keywords\": [\"list\", \"of\", \"key\", \"concepts\"] }}\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "# Configure the model to output JSON\n",
    "config = types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(response.text)\n",
    "\n",
    "# You can now reliably parse the JSON string\n",
    "metadata_obj = json.loads(response.text)\n",
    "\n",
    "print(\"\\n--- Parsed JSON Object ---\")\n",
    "print(metadata_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementing structured outputs from scratch using Pydantic\n",
    "\n",
    "While prompting for JSON is effective, it can be fragile. A more robust and modern approach is to use **Pydantic**. Pydantic allows you to define data structures as Python classes. This gives you:\n",
    "\n",
    "- **A single source of truth**: The Pydantic model defines the structure.\n",
    "- **Automatic schema generation**: You can easily generate a JSON Schema from the model.\n",
    "- **Data validation**: You can validate the LLM's output against the model to ensure it conforms to the expected structure and types.\n",
    "\n",
    "Let's recreate the previous example using Pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    \"\"\"A class to hold structured metadata for a document.\"\"\"\n",
    "\n",
    "    summary: str = Field(description=\"A concise, 1-2 sentence summary of the document.\")\n",
    "    tags: List[str] = Field(\n",
    "        description=\"A list of 3-5 high-level tags relevant to the document.\"\n",
    "    )\n",
    "    keywords: List[str] = Field(\n",
    "        description=\"A list of specific keywords or concepts mentioned.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Injecting Pydantic Schema into the Prompt\n",
    "\n",
    "We can generate a JSON Schema from our Pydantic model and inject it directly into the prompt. This is a more formal way of telling the LLM what structure to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"summary\": \"This article explores the advancements in AI agents, particularly focusing on autonomous agents powered by Large Language Models. It covers topics like the ReAct framework, tool use, and long-term planning challenges, suggesting a significant impact on the future of software development.\",\n",
      "  \"tags\": [\n",
      "    \"AI Agents\",\n",
      "    \"Large Language Models\",\n",
      "    \"Autonomous Systems\",\n",
      "    \"Software Development\",\n",
      "    \"ReAct Framework\"\n",
      "  ],\n",
      "  \"keywords\": [\n",
      "    \"AI\",\n",
      "    \"LLMs\",\n",
      "    \"ReAct\",\n",
      "    \"tool use\",\n",
      "    \"long-term planning\",\n",
      "    \"autonomous agents\",\n",
      "    \"software development\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "--- Pydantic Validated Object ---\n",
      "summary='This article explores the advancements in AI agents, particularly focusing on autonomous agents powered by Large Language Models. It covers topics like the ReAct framework, tool use, and long-term planning challenges, suggesting a significant impact on the future of software development.' tags=['AI Agents', 'Large Language Models', 'Autonomous Systems', 'Software Development', 'ReAct Framework'] keywords=['AI', 'LLMs', 'ReAct', 'tool use', 'long-term planning', 'autonomous agents', 'software development']\n",
      "\n",
      "Validation successful!\n"
     ]
    }
   ],
   "source": [
    "schema = DocumentMetadata.model_json_schema()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract metadata from it. \n",
    "The output must be a single, valid JSON object that conforms to the following JSON Schema:\n",
    "```json\n",
    "{json.dumps(schema, indent=2)}\n",
    "```\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "config = types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(response.text)\n",
    "\n",
    "# Now, we can validate the output with Pydantic\n",
    "try:\n",
    "    validated_metadata = DocumentMetadata.model_validate_json(response.text)\n",
    "    print(\"\\n--- Pydantic Validated Object ---\")\n",
    "    print(validated_metadata)\n",
    "    print(\"\\nValidation successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nValidation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Using a Pydantic Model as a Tool\n",
    "\n",
    "A more elegant and powerful pattern is to treat our Pydantic model *as a tool*. We can ask the model to \"call\" this Pydantic tool, and the arguments it generates will be our structured data.\n",
    "\n",
    "This combines the power of function calling with the robustness of Pydantic for structured data extraction. It's the recommended approach for complex data extraction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Function Call from LLM ---\n",
      "id=None args={'keywords': ['AI Agents', 'Large Language Models', 'ReAct framework', 'tool use', 'long-term planning'], 'summary': 'Recent advancements in AI have led to the rise of autonomous agents capable of complex tasks, moving beyond simple text generation.', 'tags': ['AI', 'Autonomous Agents', 'LLMs']} name='extract_metadata'\n",
      "\n",
      "--- Pydantic Validated Object ---\n",
      "summary='Recent advancements in AI have led to the rise of autonomous agents capable of complex tasks, moving beyond simple text generation.' tags=['AI', 'Autonomous Agents', 'LLMs'] keywords=['AI Agents', 'Large Language Models', 'ReAct framework', 'tool use', 'long-term planning']\n",
      "\n",
      "Summary: Recent advancements in AI have led to the rise of autonomous agents capable of complex tasks, moving beyond simple text generation.\n",
      "Tags: ['AI', 'Autonomous Agents', 'LLMs']\n"
     ]
    }
   ],
   "source": [
    "# The Pydantic class 'DocumentMetadata' is now our 'tool'\n",
    "extraction_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        types.FunctionDeclaration(\n",
    "            name=\"extract_metadata\",\n",
    "            description=\"Extracts structured metadata from a document.\",\n",
    "            parameters=DocumentMetadata.model_json_schema(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[extraction_tool],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "response_message = response.candidates[0].content.parts[0]\n",
    "\n",
    "if hasattr(response_message, \"function_call\"):\n",
    "    function_call = response_message.function_call\n",
    "    print(\"--- Function Call from LLM ---\")\n",
    "    print(function_call)\n",
    "\n",
    "    # The arguments are our structured data\n",
    "    metadata_args = {key: val for key, val in function_call.args.items()}\n",
    "\n",
    "    # We can now validate and use this data with our Pydantic model\n",
    "    try:\n",
    "        validated_metadata = DocumentMetadata(**metadata_args)\n",
    "        print(\"\\n--- Pydantic Validated Object ---\")\n",
    "        print(validated_metadata)\n",
    "        print(f\"\\nSummary: {validated_metadata.summary}\")\n",
    "        print(f\"Tags: {validated_metadata.tags}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nValidation failed: {e}\")\n",
    "else:\n",
    "    print(\"The model did not call the extraction tool.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Implementing structured ouputs using Gemini and Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentMetadata(summary='This article examines the progress in AI, specifically regarding autonomous agents and their ability to handle complex tasks using Large Language Models. It highlights tool use, the ReAct framework, and long-term planning challenges.', tags=['AI', 'Autonomous Agents', 'Large Language Models', 'Software Development'], keywords=['AI Agents', 'LLMs', 'ReAct framework', 'tool use', 'long-term planning'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = types.GenerateContentConfig(\n",
    "    response_mime_type=\"application/json\", response_schema=DocumentMetadata\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "response.parsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
