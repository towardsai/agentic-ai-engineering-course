{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools and Structured Outputs with Gemini\n",
    "\n",
    "This notebook explores two powerful features for building capable AI agents with Large Language Models (LLMs): **Tools (Function Calling)** and **Structured Outputs**. We will use the `google-genai` library to interact with Google's Gemini models.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "1.  **Understand and implement tool use (function calling)** to allow an LLM to interact with external systems.\n",
    "2.  **Enforce structured data formats (JSON)** from an LLM for reliable data extraction.\n",
    "3.  **Leverage Pydantic models** to define and manage complex data structures for both function arguments and structured outputs, improving code robustness and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API Key\n",
    "\n",
    "To use the Gemini API, you need an API key. \n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
    "2.  Create a file named `.env` in the root of this project.\n",
    "3.  Add the following line to the `.env` file, replacing `your_api_key_here` with your actual key:\n",
    "    ```\n",
    "    GEMINI_API_KEY=\"your_api_key_here\"\n",
    "    ```\n",
    "The code below will load this key from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY_ROOT_DIR=`/Users/pauliusztin/Documents/01_projects/TAI/course-ai-agents`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "REPOSITORY_ROOT_DIR = Path().absolute().parent.parent\n",
    "print(f\"REPOSITORY_ROOT_DIR=`{REPOSITORY_ROOT_DIR}`\")\n",
    "\n",
    "try:\n",
    "    load_dotenv(dotenv_path=REPOSITORY_ROOT_DIR / \".env\")\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"dotenv package not found. Please install it with 'pip install python-dotenv'\"\n",
    "    )\n",
    "\n",
    "assert \"GOOGLE_API_KEY\" in os.environ, \"`GOOGLE_API_KEY` is not set\"\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Generative Model\n",
    "\n",
    "We will use the `gemini-1.5-flash-latest` model, which is fast, cost-effective, and supports advanced features like tool use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part 1: Using Tools (Function Calling)\n",
    "\n",
    "LLMs are trained on text and can't perform actions in the real world on their own. **Tools** (or **Function Calling**) are the mechanism we use to bridge this gap. We provide the LLM with a list of available tools, and it can decide which one to use and with what arguments to fulfill a user's request.\n",
    "\n",
    "The process is a loop:\n",
    "1.  **You**: Send the LLM a prompt and a list of available tools.\n",
    "2.  **LLM**: Responds with a `function_call` request, specifying the tool and arguments.\n",
    "3.  **You**: Execute the requested function in your code.\n",
    "4.  **You**: Send the function's output back to the LLM.\n",
    "5.  **LLM**: Uses the tool's output to generate a final, user-facing response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Mock Tools\n",
    "\n",
    "Let's create two simple, mocked functions. One simulates searching Google Drive, and the other simulates sending a Discord message. The function docstrings are crucial, as the LLM uses them to understand what each tool does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_drive(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for a file on Google Drive and returns its content or a summary.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to find the file, e.g., 'Q3 earnings report'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representing the search results, including file names and summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"---> Searching Google Drive for: '{query}'\")\n",
    "    # In a real scenario, this would interact with the Google Drive API.\n",
    "    # Here, we mock the response for demonstration.\n",
    "    if \"q3 earnings report\" in query.lower():\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"files\": [\n",
    "                    {\n",
    "                        \"name\": \"Q3_Earnings_Report_2024.pdf\",\n",
    "                        \"id\": \"file12345\",\n",
    "                        \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return json.dumps({\"files\": []})\n",
    "\n",
    "\n",
    "def send_discord_message(channel_id: str, message: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a message to a specific Discord channel.\n",
    "\n",
    "    Args:\n",
    "        channel_id (str): The ID of the channel to send the message to, e.g., '#finance'.\n",
    "        message (str): The content of the message to send.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string confirming the action, e.g., '{\"status\": \"success\"}'.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"---> Sending message to Discord channel '{channel_id}': '{message}'\")\n",
    "    # Mocking a successful API call\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"status\": \"success\",\n",
    "            \"channel\": channel_id,\n",
    "            \"message_preview\": f\"{message[:50]}...\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Tool Use Loop\n",
    "\n",
    "Now, let's create a scenario where we ask the agent to perform a multi-step task: find a report and then communicate its findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt: Please find the Q3 earnings report on Google Drive and send a summary of it to the #finance channel on Discord.\n",
      "\n",
      "Model's first response: id=None args={'query': 'Q3 earnings report'} name='search_google_drive'\n",
      "---> Searching Google Drive for: 'Q3 earnings report'\n",
      "\n",
      "Sending tool result back to model: {\"files\": [{\"name\": \"Q3_Earnings_Report_2024.pdf\", \"id\": \"file12345\", \"summary\": \"The Q3 earnings report shows a 20% increase in revenue and a 15% growth in user engagement, beating expectations.\"}]}\n",
      "\n",
      "Model's next response: video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={'channel_id': '#finance', 'message': 'Q3 Earnings Report Summary: Revenue increased by 20%, user engagement grew by 15%, beating expectations. File ID: file12345'}, name='send_discord_message') function_response=None text=None\n",
      "---> Sending message to Discord channel '#finance': 'Q3 Earnings Report Summary: Revenue increased by 20%, user engagement grew by 15%, beating expectations. File ID: file12345'\n",
      "\n",
      "Sending tool result back to model: {\"status\": \"success\", \"channel\": \"#finance\", \"message_preview\": \"Q3 Earnings Report Summary: Revenue increased by 2...\"}\n",
      "\n",
      "Model's next response: video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={'message': 'Q3 Earnings Report Summary: Revenue increased by 20%, user engagement grew by 15%, beating expectations. File ID: file12345', 'channel_id': '#general'}, name='send_discord_message') function_response=None text=None\n",
      "---> Sending message to Discord channel '#general': 'Q3 Earnings Report Summary: Revenue increased by 20%, user engagement grew by 15%, beating expectations. File ID: file12345'\n",
      "\n",
      "Sending tool result back to model: {\"status\": \"success\", \"channel\": \"#general\", \"message_preview\": \"Q3 Earnings Report Summary: Revenue increased by 2...\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's next response: video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={'message': 'Q3 Earnings Report Summary: Revenue increased by 20%, user engagement grew by 15%, beating expectations. Google Drive File ID: file12345', 'channel_id': '#finance'}, name='send_discord_message') function_response=None text=None\n",
      "\n",
      "--- Final Agent Response ---\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# The user's request that requires tool use\n",
    "prompt = \"Please find the Q3 earnings report on Google Drive and send a summary of it to the #finance channel on Discord.\"\n",
    "\n",
    "# Define the function declarations explicitly\n",
    "search_google_drive_declaration = {\n",
    "    \"name\": \"search_google_drive\",\n",
    "    \"description\": \"Searches for a file on Google Drive and returns its content or a summary.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search query to find the file, e.g., 'Q3 earnings report'.\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "send_discord_message_declaration = {\n",
    "    \"name\": \"send_discord_message\",\n",
    "    \"description\": \"Sends a message to a specific Discord channel.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"channel_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The ID of the channel to send the message to, e.g., '#finance'.\",\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The content of the message to send.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"channel_id\", \"message\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create a lookup for the actual Python functions\n",
    "tool_functions = {\n",
    "    func.__name__: func for func in [search_google_drive, send_discord_message]\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(**search_google_drive_declaration),\n",
    "            types.FunctionDeclaration(**send_discord_message_declaration),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=tools,\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 1. First call to the model\n",
    "print(f\"User Prompt: {prompt}\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt,\n",
    "    config=config,\n",
    ")\n",
    "response_message = response.candidates[0].content.parts[0]\n",
    "\n",
    "print(f\"\\nModel's first response: {response_message.function_call}\")\n",
    "\n",
    "# Keep a list of messages to send back to the model\n",
    "messages = [response.candidates[0].content]\n",
    "\n",
    "# Loop to handle multiple function calls\n",
    "max_iterations = 3\n",
    "while hasattr(response_message, \"function_call\") and max_iterations > 0:\n",
    "    function_call = response_message.function_call\n",
    "    function_name = function_call.name\n",
    "\n",
    "    # 2. Execute the function requested by the model\n",
    "    if function_name in tool_functions:\n",
    "        selected_function = tool_functions[function_name]\n",
    "        args = {key: value for key, value in function_call.args.items()}\n",
    "        tool_result = selected_function(**args)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown function call: {function_name}\")\n",
    "\n",
    "    # 3. Send the result back to the model\n",
    "    print(f\"\\nSending tool result back to model: {tool_result}\")\n",
    "    function_response_part = types.Part(\n",
    "        function_response=types.FunctionResponse(\n",
    "            name=function_name, response=json.loads(tool_result)\n",
    "        )\n",
    "    )\n",
    "    messages.append(function_response_part)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=messages,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # The model may call another function or return a text response\n",
    "    response_message = response.candidates[0].content.parts[0]\n",
    "    messages.append(response.candidates[0].content)\n",
    "\n",
    "    print(f\"\\nModel's next response: {response_message}\")\n",
    "\n",
    "    max_iterations -= 1\n",
    "\n",
    "# 4. Print the final, user-facing answer\n",
    "print(\"\\n--- Final Agent Response ---\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part 2: Structured Outputs with JSON\n",
    "\n",
    "Sometimes, you don't need the LLM to take an action, but you need its output in a specific, machine-readable format. Forcing the output to be JSON is a common way to achieve this.\n",
    "\n",
    "We can instruct the model to do this by:\n",
    "1.  **Prompting**: Clearly describe the desired JSON structure in the prompt.\n",
    "2.  **Configuration**: Setting `response_mime_type` to `\"application/json\"` in the generation configuration, which forces the model's output to be a valid JSON object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Extracting Metadata from a Document\n",
    "\n",
    "Let's imagine we have a markdown document and we want to extract key information like a summary, tags, and keywords into a clean JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"summary\": \"This article discusses the rise of AI agents and their ability to perform complex tasks using Large Language Models (LLMs). It covers the ReAct framework, tool use, and long-term planning challenges, suggesting a significant impact on the future of software development.\",\n",
      "  \"tags\": [\"AI\", \"agents\", \"LLMs\", \"autonomous agents\", \"software development\"],\n",
      "  \"keywords\": [\"ReAct framework\", \"tool use\", \"long-term planning\", \"artificial intelligence\", \"large language models\"]\n",
      "}\n",
      "\n",
      "--- Parsed JSON Object ---\n",
      "{'summary': 'This article discusses the rise of AI agents and their ability to perform complex tasks using Large Language Models (LLMs). It covers the ReAct framework, tool use, and long-term planning challenges, suggesting a significant impact on the future of software development.', 'tags': ['AI', 'agents', 'LLMs', 'autonomous agents', 'software development'], 'keywords': ['ReAct framework', 'tool use', 'long-term planning', 'artificial intelligence', 'large language models']}\n"
     ]
    }
   ],
   "source": [
    "document = \"\"\"\n",
    "# Article: The Rise of AI Agents\n",
    "\n",
    "This article discusses the recent advancements in AI, focusing on autonomous agents. \n",
    "We explore how Large Language Models (LLMs) are moving beyond simple text generation \n",
    "to perform complex, multi-step tasks. Key topics include the ReAct framework, \n",
    "the importance of tool use, and the challenges of long-term planning. The future \n",
    "of software development may be significantly impacted by these new AI paradigms.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract metadata from it. \n",
    "The output must be a single, valid JSON object with the following structure:\n",
    "{{ \"summary\": \"A concise summary of the article.\", \"tags\": [\"list\", \"of\", \"relevant\", \"tags\"], \"keywords\": [\"list\", \"of\", \"key\", \"concepts\"] }}\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "# Configure the model to output JSON\n",
    "config = types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(response.text)\n",
    "\n",
    "# You can now reliably parse the JSON string\n",
    "metadata_obj = json.loads(response.text)\n",
    "\n",
    "print(\"\\n--- Parsed JSON Object ---\")\n",
    "print(metadata_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Part 3: Structured Outputs with Pydantic\n",
    "\n",
    "While prompting for JSON is effective, it can be fragile. A more robust and modern approach is to use **Pydantic**. Pydantic allows you to define data structures as Python classes. This gives you:\n",
    "\n",
    "- **A single source of truth**: The Pydantic model defines the structure.\n",
    "- **Automatic schema generation**: You can easily generate a JSON Schema from the model.\n",
    "- **Data validation**: You can validate the LLM's output against the model to ensure it conforms to the expected structure and types.\n",
    "\n",
    "Let's recreate the previous example using Pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    \"\"\"A class to hold structured metadata for a document.\"\"\"\n",
    "\n",
    "    summary: str = Field(description=\"A concise, 1-2 sentence summary of the document.\")\n",
    "    tags: List[str] = Field(\n",
    "        description=\"A list of 3-5 high-level tags relevant to the document.\"\n",
    "    )\n",
    "    keywords: List[str] = Field(\n",
    "        description=\"A list of specific keywords or concepts mentioned.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Injecting Pydantic Schema into the Prompt\n",
    "\n",
    "We can generate a JSON Schema from our Pydantic model and inject it directly into the prompt. This is a more formal way of telling the LLM what structure to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"summary\": \"The article discusses the rise of AI agents, focusing on autonomous agents and the use of Large Language Models (LLMs) for complex tasks. Key aspects include the ReAct framework, tool use, and long-term planning challenges.\",\n",
      "  \"tags\": [\n",
      "    \"AI Agents\",\n",
      "    \"Large Language Models\",\n",
      "    \"Autonomous Systems\",\n",
      "    \"Artificial Intelligence\"\n",
      "  ],\n",
      "  \"keywords\": [\n",
      "    \"LLMs\",\n",
      "    \"ReAct framework\",\n",
      "    \"tool use\",\n",
      "    \"long-term planning\",\n",
      "    \"autonomous agents\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "--- Pydantic Validated Object ---\n",
      "summary='The article discusses the rise of AI agents, focusing on autonomous agents and the use of Large Language Models (LLMs) for complex tasks. Key aspects include the ReAct framework, tool use, and long-term planning challenges.' tags=['AI Agents', 'Large Language Models', 'Autonomous Systems', 'Artificial Intelligence'] keywords=['LLMs', 'ReAct framework', 'tool use', 'long-term planning', 'autonomous agents']\n",
      "\n",
      "Validation successful!\n"
     ]
    }
   ],
   "source": [
    "schema = DocumentMetadata.model_json_schema()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract metadata from it. \n",
    "The output must be a single, valid JSON object that conforms to the following JSON Schema:\n",
    "```json\n",
    "{json.dumps(schema, indent=2)}\n",
    "```\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "config = types.GenerateContentConfig(response_mime_type=\"application/json\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(response.text)\n",
    "\n",
    "# Now, we can validate the output with Pydantic\n",
    "try:\n",
    "    validated_metadata = DocumentMetadata.model_validate_json(response.text)\n",
    "    print(\"\\n--- Pydantic Validated Object ---\")\n",
    "    print(validated_metadata)\n",
    "    print(\"\\nValidation successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nValidation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Using a Pydantic Model as a Tool\n",
    "\n",
    "A more elegant and powerful pattern is to treat our Pydantic model *as a tool*. We can ask the model to \"call\" this Pydantic tool, and the arguments it generates will be our structured data.\n",
    "\n",
    "This combines the power of function calling with the robustness of Pydantic for structured data extraction. It's the recommended approach for complex data extraction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Function Call from LLM ---\n",
      "id=None args={'summary': 'The article discusses advancements in AI, focusing on autonomous agents and how LLMs are moving beyond text generation to perform complex tasks.', 'tags': ['AI', 'Autonomous Agents', 'LLMs'], 'keywords': ['AI Agents', 'Large Language Models', 'ReAct framework', 'tool use', 'long-term planning']} name='extract_metadata'\n",
      "\n",
      "--- Pydantic Validated Object ---\n",
      "summary='The article discusses advancements in AI, focusing on autonomous agents and how LLMs are moving beyond text generation to perform complex tasks.' tags=['AI', 'Autonomous Agents', 'LLMs'] keywords=['AI Agents', 'Large Language Models', 'ReAct framework', 'tool use', 'long-term planning']\n",
      "\n",
      "Summary: The article discusses advancements in AI, focusing on autonomous agents and how LLMs are moving beyond text generation to perform complex tasks.\n",
      "Tags: ['AI', 'Autonomous Agents', 'LLMs']\n"
     ]
    }
   ],
   "source": [
    "# The Pydantic class 'DocumentMetadata' is now our 'tool'\n",
    "extraction_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        types.FunctionDeclaration(\n",
    "            name=\"extract_metadata\",\n",
    "            description=\"Extracts structured metadata from a document.\",\n",
    "            parameters=DocumentMetadata.model_json_schema(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[extraction_tool],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "response_message = response.candidates[0].content.parts[0]\n",
    "\n",
    "if hasattr(response_message, \"function_call\"):\n",
    "    function_call = response_message.function_call\n",
    "    print(\"--- Function Call from LLM ---\")\n",
    "    print(function_call)\n",
    "\n",
    "    # The arguments are our structured data\n",
    "    metadata_args = {key: val for key, val in function_call.args.items()}\n",
    "\n",
    "    # We can now validate and use this data with our Pydantic model\n",
    "    try:\n",
    "        validated_metadata = DocumentMetadata(**metadata_args)\n",
    "        print(\"\\n--- Pydantic Validated Object ---\")\n",
    "        print(validated_metadata)\n",
    "        print(f\"\\nSummary: {validated_metadata.summary}\")\n",
    "        print(f\"Tags: {validated_metadata.tags}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nValidation failed: {e}\")\n",
    "else:\n",
    "    print(\"The model did not call the extraction tool.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Using a Pydantic Model as direct Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentMetadata(summary='This article examines the progress of AI agents, particularly their ability to handle complex tasks using Large Language Models. It highlights the ReAct framework, the significance of utilizing tools, and the difficulties associated with long-term planning in AI.', tags=['AI Agents', 'Large Language Models', 'Autonomous Systems', 'Software Development'], keywords=['AI', 'LLMs', 'ReAct framework', 'tool use', 'long-term planning'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = types.GenerateContentConfig(\n",
    "    response_mime_type=\"application/json\",\n",
    "    response_schema=DocumentMetadata\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please analyze the following document and extract its metadata.\n",
    "\n",
    "Document:\n",
    "--- \n",
    "{document}\n",
    "--- \n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt, config=config\n",
    ")\n",
    "response.parsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
