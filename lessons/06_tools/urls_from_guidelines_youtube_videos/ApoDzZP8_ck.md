Hello everybody, welcome to the Neural Maze. So in today's video we are going to keep working on the project of implementing the four agentic patterns from scratch that we started a week ago when we implemented the reflection pattern. So today we're going to move into the second pattern that is the tool pattern. And before we begin, I'm pretty sure that you're already familiar with this pattern in a practical sense.

[00:28] What I mean by this is that you have probably used in the past tools in LangChain, in LlamaIndex, or in CrewAI. And the thing is that in today's video, I'm not going to teach you how to use these tools in specific frameworks. I'm just going to teach you how these tools work under the hood. And I think that's really insightful because if we really understand how things work under the hood, I think it's much easier for us to learn how to apply them in the proper way.

[01:00] So, as we did in the previous video, we are going to start with a Jupyter notebook that covers all the theory step by step and then I will move into VS code where I will show you all the abstractions and all the classes that I have implemented to make this tool more robust, to try to mimic the structure that all of these frameworks offer at this moment. You know, having like a tool class and a tool agent class, very similar to what we did with the reflection pattern, but with with the tool pattern. Okay, so let's begin with the theory of the tool pattern. You have this diagram right here, that tries to offer a simplified description of what the pattern does or tries to implement under the hood.

[01:45] But basically, let's start by defining what is a tool. And a tool, let's put it in simple terms, it's just a way for the LLM to access the outside world. And what do I mean by this? Uh, remember that LLMs store all the information in their weights. So, when you ask an LLM about specific information, that information is going to be retrieved by the weights. But sometimes, the information stored in these weights is not enough. And we need a way for the LLM to access the outside world. And that's exactly what a tool does. A tool is just uh like a Python function that the LLM can access and run and fetch some relevant results using an API or uh parsing a web content or um consulting uh Wolfram Alpha to to calculate some difficult integrals. But you get the point. It's a way for the LLM to get outside the information stored in its weights.

[02:51] Okay, so let's start by defining a simple Python function. You have it in here. So, uh this Python function, which uh I'm a bit ashamed of it because it's uh too simple. Uh, basically gets the current weather. And as you can see, uh if location is uh Madrid, it's going to return a temperature of 25 uh it varies on the unit that you want to to put, but given that it's Madrid, it will be unit Celsius, so it's going to return a temperature of 25 degrees Celsius. And otherwise, it's going to return 58. So as you can see, don't pay too much attention to this function because it's trivial, but uh it will help us to illustrate how a tool works. So, if we run this as I was saying, if we run this function with location Madrid and unit Celsius, it's going to return this um dictionary, well, this string containing a dictionary with temperature 25 and unit Celsius. So, nothing to add about this thing. This is trivial, so let's proceed.

[04:03] Now the question is, how can we make this function available to an LLM? Because as you already know, LLMs are just NLP systems and natural language processing systems, so they expect text as input. But we need a way to for the LLM to really understand that this is a Python function and I can call this Python function to retrieve some relevant results. And how can we do that? Okay, so what I propose here is to use this system prompt. So as you can see, in this system prompt, we are telling the LLM to behave as a function calling AI model. We are going to provide the function signatures within this XML tags, this tools tags. And you may call one or more functions to assist with the user query, don't make assumptions about values, blah blah blah. Okay, but the important thing is that we are going to pass all the relevant information within these XML tags. and the LLM is going to return the function call inside these XML tags. Okay, this tool underscore tag, uh underscore call, sorry. You can see here an example of how we expect the LLM to return the tool call. It's going to be something like this. We are going to uh the LLM is going to provide a name, the name of the function, and also the arguments that we need to use to retrieve the relevant information with this Python function, and then a list of the available tools. In this case, uh I'm just using this one like get current weather because uh I needed to hard code everything for this tiny example, but as you will see in the VS code, we are going to make it automatic. So, given a Python function, we are going to retrieve all of this information, all of this uh function signature. It's going to be retrieved automatically in the VS Code uh implementation. But yeah, if you checked the way the information that we are providing for each tool, you can see that we are providing the name of the tool, a description. This is something that we can get from the docstring, by the way. You we will see that later. But yeah, like get the current weather in a given location, blah blah blah. and then the parameters, where we are putting all the different parameters and this is really important, the type of these parameters. In this case, both the location and the unit are going to be strings, but suppose that we are passing, I don't know, uh the month and we want it to behave like an integer, then we should put that type inside the the function signature. Okay, so now that we know how this system prompt works, let's put it into practice. Just a quick reminder. Today, we are going to use a different LLM than the previous video. On the previous video, we were using Llama-3 70 billion, but today we are going to use a slightly different LLM because it's the Llama-3 70 billion tool use. So it's a version of Llama-3 that's been uh fine-tuned for tool use and that's exactly what we want to do today, so it made sense to to use this LLM. Okay, uh we defined uh a constant, uh the system prompt, um where we copy and paste the system prompt that I shared with you uh right in the in the cell below and and now let's run this cell. We are going to ask the LLM what's the current temperature in Madrid in Celsius. We're going to add the system prompt and we are also going to add the user uh message to the history and and yeah, let's run this. Okay, so as you can see, we are having a structure similar to the one we ask for the LLM to return in the system prompt. The LLM is returning the name of the tool and it's also returning the arguments. Since we ask what's the current temperature in Madrid in Celsius, the arguments are going to be Madrid as the location and Celsius as the unit.

[08:12] Okay. But now, this is not usable for the by the LLM. I mean, we have a string and inside that string, we have this dictionary inside these two XML tags. So, we need a way to get rid of the XML tags and also transform this dictionary, this string dictionary, into a proper dictionary using the JSON package, the JSON library. And that's exactly what this function does. This function will get rid of the tool call, or to be more specific, it will gather, it will get the code inside the tool call XML tags and then it will transform the string dictionary into a proper dictionary. So, let me show you how it works. But as you can see when we call this parse tool called string this method, to the output, the output remember that it's this one here. It's going to return a proper Python dictionary. And now, if we run the get current weather, the function that we defined at the beginning of the notebook, if we run this function with the parameters that we have just parsed, it will return the result. So, temperature 25 and unit it's going to be Celsius. Okay, without any information about the XML tags, that's something that we want to get rid of.

[09:48] Nice. Okay, so now we have the result. As you can see, it's this Python dictionary right here. But we are not over because we don't want the LLM to respond with this structure. I mean, if I ask the LLM for the current temperature in Madrid, I expect the LLM to respond me something like the current temperature in Madrid, it's is 25 degrees Celsius, for example, but not something like this, not this uh dictionary. So, the last thing that we need to do is to add this observation, the dictionary in here, to the chat history. Okay, and we are going to add this by using this observation prompt. Okay, so now the only thing that's missing is to make another call to to the LLM in Groq and we will receive the output. Okay, so now that we understand how all of these classes and abstractions work, I think it's going to be really cool to see everything in action. And that's what we are going to cover next.

[18:11] So, uh, everything it's inside this section of implementing everything the good way. Of course, you have to understand that this implementation it's not like the perfect implementation because uh I'm not trying to to create another framework. I'm just trying to make something that's uh well-implemented, but at the same time easy to understand. So, so yeah, just bear in mind that we are not trying to to create another agentic framework in this case. Okay, so, uh, let's continue. Uh let's see how the tool decorator works and instead of using some dummy uh function, in this case, we are going to implement something more uh, something closer to to reality, something closer to the tools that you might be wanting to implement in the future.

[19:03] So, in this case, the the function that I have implemented is a function that fetches the top n stories from Hacker News. If you don't know what Hacker News is, it's a very famous page where you have different types of of stories and many of them uh link to some article, another to GitHub repositories, to tweets, to whatever. And it's very very used by by a lot of people. So I thought it will be cool to have this uh this function that allows you to retrieve a top number of these functions, of these uh stories, sorry. And and yeah, and to convert this to transform this function into a tool.

[19:48] Okay? So, let me show you first of all that the Python function works properly. So if we run the fetch top Hacker News stories with a top end of five, it's going to take the the top five stories. Let's check the first one. Too much efficiency makes everything worse. And if we go to Hacker News web page, you will see that yeah, that this is the first story. So everything seems to be working fine.

[20:16] Now, let's transform the fetch top Hacker News stories function into a Python tool. And we are going to do it by using this method that we covered previously. Okay, so now that we have run the tool method, the HN tool, it's going to be a tool. We can access the name of the tool and we can access the function signature that as you can see contains all the information that we put in the system prompt at the beginning of the video, but right now the cool thing is that everything has been generated automatically.

[20:55] And yeah, you can see here that uh has a description and the description has been retrieved from the docstring and we have also the parameters here. Uh in this case it's a very simple function, so we just uh need this top n argument and it's of type integer. So, everything seems to be working fine. And now, let's move into the tool agent. So, the tool agent, to instantiate this tool, we just need a a list of tools. In this case, we are only using one tool, the HN tool, and now let's uh run the agent. And in this case, uh I wanted to check that everything works properly by doing the following strategy. So first of all, I'm going to ask the agent about something that it's not related to Hacker News. So, for example, tell me your name. If everything works properly, we should see, yeah, something not related with the agent, with the tool, sorry. And as you can see, given the output, the agent has not used any kind of tool. And that's the proper way to work because uh if the user message is not related to any tool, we don't want the agent to spend time on interacting with tools.

[22:12] But what happens if we ask the same agent about the top five Hacker News stories right now? So, in this case, we should expect the agent to use the tool. And as you can see, uh I have added some logging to make it easier to see. But check this. So, the agent is using the tool, the fetch top Hacker News stories. It's using the tool with this call dict. So this is the name and the arguments, the top n with a value of five, and finally, it's generating a result. But remember that we don't want this kind of result. I mean, if I'm asking about the five top stories in Hacker News right now, I'm expecting something easier to understand.

[23:00] And that's what we achieve. If we print the output and here we have the five top stories in Hacker News. The first one is the the article about too much efficiency makes everything worse that we saw in the Hacker News page. And if we click the URL attached, you can see that everything seems to be working fine. I mean, it's not like the agent redirected us to some broken URLs. I mean, the URLs are real and it's uh it's working as expected. So, yeah, this is everything I wanted to teach you about tools. My hope is that now when you start using or keep using uh tools from LangChain, LlamaIndex, or CrewAI, you have a deeper understanding of how these objects uh work under the hood.

[23:51] And this is everything for today. I'm working on the next videos of this series, the video about the planning pattern and the video about the multi-agent pattern. I think you are also going to to enjoy uh those ones. And but yeah, this is everything for today. I hope you have enjoyed the video. Subscribe to the channel if you haven't and if you like the content. Click the like button if you've you have enjoyed this video. And I'll see you in the next video.

[24:25] [outro music]