{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 23: Evaluator-Optimizer Pattern â€” Reviewing and Editing the Brown Writing Workflow\n",
    "\n",
    "In this lesson, we'll explore how to implement the evaluator-optimizer pattern to review and edit generated articles. Building on the foundation from Lesson 22, we'll add a quality assurance layer that ensures the generated content meets all requirements.\n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "- Understand the evaluator-optimizer pattern and its real-world applications\n",
    "- Implement an article reviewing system that checks content against our writing profiles\n",
    "- Configure the entire system from a single YAML file\n",
    "- Glue everything together into a robust LangGraph workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> ðŸ’¡ Remember that you can also run `brown` as a standalone Python package by going to `lessons/writing_workflow/` and following the instructions from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we define some standard Magic Python commands to autoreload Python packages whenever they change:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Python Environment\n",
    "\n",
    "To set up your Python virtual environment using `uv` and load it into the Notebook, follow the step-by-step instructions from the `Course Admin` lesson from the beginning of the course.\n",
    "\n",
    "**TL/DR:** Be sure the correct kernel pointing to your `uv` virtual environment is selected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Gemini API\n",
    "\n",
    "To configure the Gemini API, follow the step-by-step instructions in the `Course Admin` lesson.\n",
    "\n",
    "Here is a quick checklist of what you need to run this notebook:\n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/api-keys).\n",
    "2.  From the root of your project, run: `cp .env.example .env` \n",
    "3.  Within the `.env` file, fill in the `GOOGLE_API_KEY` variable:\n",
    "\n",
    "Now, the code below will load the key from the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from `/Users/pauliusztin/Documents/01_projects/TAI/agentic-ai-engineering-course/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import env\n",
    "\n",
    "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Key Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from utils import pretty_print\n",
    "\n",
    "nest_asyncio.apply()  # Allow nested async usage in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Required Files\n",
    "\n",
    "We need to download the configuration files and input data that Brown uses for article generation and editing.\n",
    "\n",
    "First, let's download the configs folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf configs\n",
    "!curl -L -o configs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/configs.zip\n",
    "!unzip configs.zip\n",
    "!rm -rf configs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the inputs folder containing profiles, examples, and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf inputs\n",
    "!curl -L -o inputs.zip https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/data/inputs.zip\n",
    "!unzip inputs.zip\n",
    "!rm -rf inputs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify what we downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aritcle_guideline.md   \u001b[1m\u001b[36minputs\u001b[m\u001b[m/                notebook_guideline.md\n",
      "\u001b[1m\u001b[36mconfigs\u001b[m\u001b[m/               notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Directory Constants\n",
    "\n",
    "Now let's define constants to reference these directories throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs directory exists: True\n",
      "Inputs directory exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIGS_DIR = Path(\"configs\")\n",
    "INPUTS_DIR = Path(\"inputs\")\n",
    "\n",
    "print(f\"Configs directory exists: {CONFIGS_DIR.exists()}\")\n",
    "print(f\"Inputs directory exists: {INPUTS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples directory exists: True\n",
      "Profiles directory exists: True\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES_DIR = Path(\"inputs/examples/course_lessons\")\n",
    "PROFILES_DIR = Path(\"inputs/profiles\")\n",
    "\n",
    "print(f\"Examples directory exists: {EXAMPLES_DIR.exists()}\")\n",
    "print(f\"Profiles directory exists: {PROFILES_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load a simpler example that runs faster and is easier to understand. At the end, we will load a larger sample that is closer to what we do on our end to generate professional articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples directory exists: True\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_DIR = Path(\"inputs/tests/01_sample_small\")\n",
    "\n",
    "print(f\"Samples directory exists: {SAMPLE_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scoping the New Writing Workflow Architecture\n",
    "\n",
    "Before diving into the implementation, let's understand how the writing agent now incorporates the review-editing process through the evaluator-optimizer pattern.\n",
    "\n",
    "### The Extended Workflow\n",
    "\n",
    "In Lesson 22, we learned about the three-step workflow:\n",
    "\n",
    "1. **Load Context into Memory** - Gather guidelines, research, profiles, and examples\n",
    "2. **Generate Media Items** - Use the orchestrator-worker pattern to create diagrams\n",
    "3. **Write the Article** - Generate the first draft using the ArticleWriter\n",
    "\n",
    "Now we're adding a fourth and fifth step that loops multiple times:\n",
    "\n",
    "4. **Review the Article** (Evaluator) - Check the article against all profiles and guidelines\n",
    "5. **Edit the Article** (Optimizer) - Fix all identified issues based on the reviews\n",
    "\n",
    "This review-edit pattern continues for a configurable number of iterations, gradually improving the article quality.\n",
    "\n",
    "### The Evaluator-Optimizer Pattern Explained\n",
    "\n",
    "The evaluator-optimizer pattern is a fundamental AI workflow pattern that mirrors real-world quality assurance processes:\n",
    "\n",
    "- **Evaluator**: Analyzes output and identifies issues or areas for improvement\n",
    "- **Optimizer**: Takes the feedback and makes targeted improvements\n",
    "\n",
    "In our case:\n",
    "- **Article Reviewer Node** = Evaluator (checks if article follows all the standards)\n",
    "- **Article Writer Node** = Optimizer (edits the article based on reviews)\n",
    "\n",
    "This approach is extremely similar to how a real-world writing process works:\n",
    "\n",
    "1. The writer writes the article (initial draft)\n",
    "2. A reviewer provides feedback from outside eyes\n",
    "3. The same writer edits the article based on the provided feedback\n",
    "4. Repeat steps 2-3 until satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Visualization\n",
    "\n",
    "Let's visualize the complete workflow with the review-edit loop:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/iusztinpaul/agentic-ai-engineering-course-data/main/images/l23_writing_workflow.png\" alt=\"Workflow\" height=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling our Review Entities\n",
    "\n",
    "Now let's explore the new Pydantic entities we need for the review process. In Lesson 22, we already covered the core entities like `Article`, `ArticleGuideline`, and `ArticleProfiles`. Now we need entities to represent the reviewing logic.\n",
    "\n",
    "### Why Two Types of Reviews?\n",
    "\n",
    "We support two review modes:\n",
    "\n",
    "1. **Whole Article Reviews**: Review the entire article from top to bottom\n",
    "2. **Selected Text Reviews**: Review only a specific portion of the article\n",
    "\n",
    "Most of the time, only a section of the article needs editing, not the whole thing. This targeted approach saves time and reduces API costs by only reviewing what matters.\n",
    "\n",
    "### The Review Entities\n",
    "\n",
    "From `brown.entities.reviews`, we have these core entities:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Review Entity\n",
    "\n",
    "A `Review` represents a single piece of feedback about the article:\n",
    "\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from brown.entities.mixins import ContextMixin\n",
    "\n",
    "\n",
    "class Review(BaseModel, ContextMixin):\n",
    "    profile: str = Field(\n",
    "        description=\"The profile type listing the constraints based on which we will write the comment.\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        description=\"The location from within the article where the comment is made. For example, the title of a section.\"\n",
    "    )\n",
    "    comment: str = Field(\n",
    "        description=\"The comment made by the reviewer stating the issue relative to the profile.\"\n",
    "    )\n",
    "\n",
    "    def to_context(self) -> str:\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    <profile>{self.profile}</profile>\n",
    "    <location>{self.location}</location>\n",
    "    <comment>{self.comment}</comment>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Fields:**\n",
    "\n",
    "- **profile**: Which requirement was violated (e.g., \"tonality_profile\", \"article_guideline\", \"structured_profile\")\n",
    "- **location**: Where in the article the issue exists, usually the title of the article section (e.g., \"Introduction - Second paragraph\")\n",
    "- **comment**: Detailed explanation of what's wrong and why it deviates from the requirement\n",
    "\n",
    "**Example Review:**\n",
    "\n",
    "```python\n",
    "Review(\n",
    "    profile=\"tonality_profile\",\n",
    "    location=\"Introduction - First paragraph\",\n",
    "    comment=\"The tone is overly formal. The tonality profile specifies a conversational, friendly tone. The current opening reads like an academic paper rather than an engaging blog post.\"\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The ArticleReviews Entity\n",
    "\n",
    "`ArticleReviews` bundles multiple reviews for the whole article:\n",
    "\n",
    "\n",
    "```python\n",
    "class ArticleReviews(BaseModel, ContextMixin):\n",
    "    article: Article\n",
    "    reviews: list[Review]\n",
    "\n",
    "    def to_context(self, include_article: bool = False) -> str:\n",
    "        reviews_str = \"\\n\".join([review.to_context() for review in self.reviews])\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    {f\"<article>{self.article}</article>\" if include_article else \"\"}\n",
    "    <reviews>\n",
    "    {reviews_str}\n",
    "    </reviews>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Reviews(len_reviews={len(self.reviews)})\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The SelectedText Entity\n",
    "\n",
    "Before understanding `SelectedTextReviews`, we need to see the `SelectedText` entity from `brown.entities.articles` to understand how we will model the selected text relative to how we did for the whole article:\n",
    "\n",
    "\n",
    "```python\n",
    "class SelectedText(BaseModel, ContextMixin):\n",
    "    article: Article\n",
    "    content: str\n",
    "    first_line_number: int\n",
    "    last_line_number: int\n",
    "\n",
    "    def to_context(self) -> str:\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    <content>{self.content}</content>\n",
    "    <first_line_number>{self.first_line_number}</first_line_number>\n",
    "    <last_line_number>{self.last_line_number}</last_line_number>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Contains the full `article` for context\n",
    "- `content`: The specific text selection to review/edit\n",
    "- Line numbers help locate the selection within the full article\n",
    "- This enables targeted reviews of specific sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The SelectedTextReviews Entity\n",
    "\n",
    "`SelectedTextReviews` handles reviews for just a portion of the article:\n",
    "\n",
    "\n",
    "```python\n",
    "class SelectedTextReviews(BaseModel, ContextMixin):\n",
    "    article: Article\n",
    "    selected_text: SelectedText\n",
    "    reviews: list[Review]\n",
    "\n",
    "    def to_context(self, include_article: bool = False) -> str:\n",
    "        reviews_str = \"\\n\".join([review.to_context() for review in self.reviews])\n",
    "        return f\"\"\"\n",
    "<{self.xml_tag}>\n",
    "    {f\"<article>{self.article.to_context()}</article>\" if include_article else \"\"}\n",
    "    <selected_text>{self.selected_text.to_context()}</selected_text>\n",
    "    <reviews>\n",
    "    {reviews_str}\n",
    "    </reviews>\n",
    "</{self.xml_tag}>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Use Case:**\n",
    "\n",
    "When a user identifies a specific problematic section, we can:\n",
    "1. Create a `SelectedText` entity pointing to that section\n",
    "2. Review only that selection (faster, cheaper)\n",
    "3. Edit only that selection\n",
    "4. Replace the selection in the full article\n",
    "\n",
    "This is particularly useful for human-in-the-loop workflows where humans can highlight specific sections for improvement. More on this in Lesson 24.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Relationships\n",
    "\n",
    "Let's visualize how these entities relate:\n",
    "\n",
    "```\n",
    "Article\n",
    "  â””â”€â”€ ArticleReviews\n",
    "       â””â”€â”€ reviews: list[Review]\n",
    "\n",
    "Article + SelectedText\n",
    "  â””â”€â”€ SelectedTextReviews  \n",
    "       â”œâ”€â”€ selected_text: SelectedText\n",
    "       â””â”€â”€ reviews: list[Review]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing the Article Reviewer (The Evaluator)\n",
    "\n",
    "Now let's explore the `ArticleReviewer` node, which acts as the **evaluator** in our evaluator-optimizer pattern. This node analyzes articles against all requirements and generates detailed feedback.\n",
    "\n",
    "Remember that the core expectations are that the article follows the article guidelines and that all the writing profiles are respected.\n",
    "\n",
    "### Node Abstraction Recap\n",
    "\n",
    "First, a quick reminder that we leverage the same `Node` abstraction from Lesson 22 to implement all our nodes.\n",
    "\n",
    "\n",
    "```python\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any\n",
    "\n",
    "from brown.nodes.base import Node, Toolkit\n",
    "\n",
    "\n",
    "class Node(ABC):\n",
    "    def __init__(self, model: Runnable, toolkit: Toolkit) -> None:\n",
    "        self.toolkit = toolkit\n",
    "        self.model = self._extend_model(model)\n",
    "\n",
    "    def _extend_model(self, model: Runnable) -> Runnable:\n",
    "        # Can be overridden to bind tools, structured output, etc.\n",
    "        return model\n",
    "\n",
    "    @abstractmethod\n",
    "    async def ainvoke(self) -> Any:\n",
    "        pass\n",
    "```\n",
    "\n",
    "All workflow nodes inherit from this base class, providing a consistent interface throughout the system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArticleReviewer Class Structure\n",
    "\n",
    "Let's examine the `ArticleReviewer` class from `brown.nodes.article_reviewer`:\n",
    "\n",
    "**1. The Class and Initialization:**\n",
    "\n",
    "```python\n",
    "class ArticleReviewer(Node):\n",
    "    system_prompt_template = \"\"\"...\"\"\"  # We'll see this shortly\n",
    "    selected_text_system_prompt_template = \"\"\"...\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        to_review: Article | SelectedText,\n",
    "        article_guideline: ArticleGuideline,\n",
    "        model: Runnable,\n",
    "        article_profiles: ArticleProfiles,\n",
    "    ) -> None:\n",
    "        self.to_review = to_review\n",
    "        self.article_guideline = article_guideline\n",
    "        self.article_profiles = article_profiles\n",
    "\n",
    "        super().__init__(model, toolkit=Toolkit(tools=[]))\n",
    "```\n",
    "\n",
    "**Key Design Decisions:**\n",
    "\n",
    "- `to_review` can be either a full `Article` or just `SelectedText` (polymorphic design)\n",
    "- Takes all the requirements: guideline, profiles\n",
    "- No tools needed (empty toolkit), as reviewing is a pure generation task and no tools are required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Model Extension with Structured Output:**\n",
    "\n",
    "```python\n",
    "    def _extend_model(self, model: Runnable) -> Runnable:\n",
    "        model = cast(BaseChatModel, super()._extend_model(model))\n",
    "        model = model.with_structured_output(ReviewsOutput)\n",
    "        \n",
    "        return model\n",
    "```\n",
    "\n",
    "The reviewer uses structured output to ensure we get properly formatted reviews. First, we need an intermediate Pydantic model:\n",
    "\n",
    "```python\n",
    "class ReviewsOutput(BaseModel):\n",
    "    reviews: list[Review]\n",
    "```\n",
    "\n",
    "**Why an intermediate model?**\n",
    "\n",
    "The LLM outputs `ReviewsOutput`, but the node returns either `ArticleReviews` or `SelectedTextReviews` (which include the article/selected_text). This separation keeps the LLM output schema simple to avoid any potential LLM inference errors, while allowing richer node outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. The ainvoke Method:**\n",
    "\n",
    "```python\n",
    "    async def ainvoke(self) -> ArticleReviews | SelectedTextReviews:\n",
    "        # Build the main system prompt with all requirements\n",
    "        system_prompt = self.system_prompt_template.format(\n",
    "            human_feedback=self.human_feedback.to_context() if self.human_feedback else \"\",\n",
    "            article=self.article.to_context(),\n",
    "            article_guideline=self.article_guideline.to_context(),\n",
    "            character_profile=self.article_profiles.character.to_context(),\n",
    "            article_profile=self.article_profiles.article.to_context(),\n",
    "            structure_profile=self.article_profiles.structure.to_context(),\n",
    "            mechanics_profile=self.article_profiles.mechanics.to_context(),\n",
    "            terminology_profile=self.article_profiles.terminology.to_context(),\n",
    "            tonality_profile=self.article_profiles.tonality.to_context(),\n",
    "        )\n",
    "        \n",
    "        user_input_content = self.build_user_input_content(inputs=[system_prompt])\n",
    "        inputs = [{\"role\": \"user\", \"content\": user_input_content}]\n",
    "        \n",
    "        # If reviewing selected text, add additional instructions\n",
    "        if self.is_selected_text:\n",
    "            inputs.extend([\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": self.selected_text_system_prompt_template.format(\n",
    "                        selected_text=self.to_review.to_context()\n",
    "                    ),\n",
    "                }\n",
    "            ])\n",
    "        \n",
    "        # Generate reviews\n",
    "        reviews = await self.model.ainvoke(inputs)\n",
    "        if not isinstance(reviews, ReviewsOutput):\n",
    "            raise InvalidOutputTypeException(ReviewsOutput, type(reviews))\n",
    "        \n",
    "        # Return appropriate review type\n",
    "        if self.is_selected_text:\n",
    "            return SelectedTextReviews(\n",
    "                article=self.article,\n",
    "                selected_text=cast(SelectedText, self.to_review),\n",
    "                reviews=reviews.reviews,\n",
    "            )\n",
    "        else:\n",
    "            return ArticleReviews(\n",
    "                article=self.article,\n",
    "                reviews=reviews.reviews,\n",
    "            )\n",
    "```\n",
    "\n",
    "**Flow:**\n",
    "\n",
    "1. Format the system prompt with all requirements\n",
    "2. If reviewing selected text, add special instructions\n",
    "3. Generate structured reviews from the LLM\n",
    "4. Package the output entity into the appropriate review type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The System Prompt (Main Review Logic):**\n",
    "\n",
    "Here's the system prompt which is carefully designed to create thorough, actionable reviews based on the article guideline and writing profiles:\n",
    "\n",
    "```python\n",
    "class ArticleReviewer(Node):\n",
    "    system_prompt_template = \"\"\"\n",
    "You are Brown, an expert article writer, editor and reviewer specialized in reviewing technical, educative and informational articles.\n",
    "\n",
    "Your task is to review a given article against a set of expected requirements and provide detailed feedback \n",
    "about any deviations. You will act as a quality assurance reviewer, identifying specific issues and suggesting \n",
    "how the article fails to meet the expected requirements.\n",
    "\n",
    "These reviews will further be used to edit the article, ensuring it follows all the requirements.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "The requirements are a set of rules, guidelines or profiles that the article should follow. Here they are:\n",
    "\n",
    "- **article guideline:** the user intent describing how the article should look like. Specific to this particular article.\n",
    "- **article profile:** rules specific to writing articles. Generic for all articles.\n",
    "- **character profile:** the character you will impersonate while writing. Generic for all content.\n",
    "- **structure profile:** Structure rules guiding the final output format. Generic for all content.\n",
    "- **mechanics profile:** Mechanics rules guiding the writing process. Generic for all content.\n",
    "- **terminology profile:** Terminology rules guiding word choice and phrasing. Generic for all content.\n",
    "- **tonality profile:** Tonality rules guiding the writing style. Generic for all content.\n",
    "\n",
    "## Article to Review\n",
    "\n",
    "Here is the article that needs to be reviewed:\n",
    "\n",
    "{article}\n",
    "\n",
    "## Article Guideline\n",
    "\n",
    "The <article_guideline> represents the user intent, describing how the actual article should look like.\n",
    "\n",
    "The <article_guideline> will ALWAYS contain:\n",
    "- all the sections of the article expected to be written, in the correct order\n",
    "- a level of detail for each section, describing what each section should contain. Depending on how much detail you have in a\n",
    "particular section of the <article_guideline>, you will use more or less information from the <research> tags to write the section.\n",
    "\n",
    "The <article_guideline> can ALSO contain:\n",
    "- length constraints for each section, such as the number of characters, words or reading time. If present, you will respect them.\n",
    "- important (golden) references as URLs or titles present in the <research> tags. If present, always prioritize them over anything else \n",
    "from the <research>.\n",
    "- information about anchoring the article into a series such as a course or a book. Extremely important when the article is part of \n",
    "something bigger and we have to anchor the article into the learning journey of the reader. For example, when introducing concepts\n",
    "in previous articles that we don't want to reintroduce into the current one.\n",
    "- concrete information about writing the article. If present, you will ALWAYS priotize the instructions from the <article_guideline> \n",
    "over any other instructions.\n",
    "\n",
    "Here is the article guideline:\n",
    "{article_guideline}\n",
    "\n",
    "## Character Profile\n",
    "\n",
    "To make the writing more personable, we impersonated the following character profile when writing the article:\n",
    "{character_profile}\n",
    "\n",
    "## Terminology Profile\n",
    "\n",
    "Here is the terminology profile, describing how to choose the right words and phrases:\n",
    "to the target audience:\n",
    "{terminology_profile}\n",
    "\n",
    "## Tonality Profile\n",
    "\n",
    "Here is the tonality profile, describing the tone, voice and style of the writing:\n",
    "{tonality_profile}\n",
    "\n",
    "## Mechanics Profile\n",
    "\n",
    "Here is the mechanics profile, describing how the sentences and words should be written:\n",
    "{mechanics_profile}\n",
    "\n",
    "## Structure Profile\n",
    "\n",
    "Here is the structure profile, describing general rules on how to structure text, such as the sections, paragraphs, lists,\n",
    "code blocks, or media items:\n",
    "{structure_profile}\n",
    "\n",
    "## Article Profile\n",
    "\n",
    "Here is the article profile, describing particularities on how the end-to-end article should look like:\n",
    "{article_profile}\n",
    "\n",
    "## Reviewing Process\n",
    "\n",
    "You will review the article against all the requirements above, creating a one-to-many relationship between each requirement and the \n",
    "number of required reviews. In other words, for each requirement, you will create 0 to N reviews. If the article follows the \n",
    "requirement 100%, you will not create any reviews for it. If it doesn't follow the requirement, you will create as many reviews \n",
    "as required to ensure the article follows the requirement.\n",
    "\n",
    "Remember that these reviews will further be used to edit the article, ensuring it follows all the requirements. Thus, it's\n",
    "important to make a thorough review, covering all the requirements and not missing any detail.\n",
    "\n",
    "## Reviewing Rules\n",
    "\n",
    "- **The first most important rule:** The requirements can contain some special sections labeled as \"rules\" or \n",
    "\"correction rules\". You should look for <(.*)?rules(.*)?> XML tags like <correction_media_rules>, \n",
    "<abbreviations_or_acronyms_never_to_expand_rules>, <correction_reference_rules>. These are special highlights that \n",
    "should always be prioritized over other rules during the review process. They should be respected at all costs when \n",
    "writing the article. You will always prioritize these rules over other rules from the requirements making them your \n",
    "No.1 focus.\n",
    "- **The second most important rule:** The adherence to the <article_guideline>.\n",
    "- **The third most important rule:** The adherence to the <article_profile>.\n",
    "- **The fourth most important rule:** The adherence to the rest of the requirements.\n",
    "\n",
    "Other more generic rules:\n",
    "- Be thorough but fair - only flag genuine issues\n",
    "- Emphasize WHY something is wrong, not just WHAT is wrong\n",
    "- Focus on significant deviations, not minor nitpicks \n",
    "\n",
    "## Output Format\n",
    "\n",
    "For each issue you identify, create a review with:\n",
    "- **profile**: The requirement where the issue was found (e.g., \"human_feedback\", \"article_guideline\", \"character_profile\", \n",
    "\"article_profile\", \"structure_profile\", \"mechanics_profile\", \"terminology_profile\", \"tonality_profile\")\n",
    "- **location**: The section title where the issue was found and the paragraph number. For example, \"Introduction - First paragraph\" \n",
    "or \"Implementing GraphRAG - Third paragraph\"\n",
    "- **comment**: A detailed explanation of why it's wrong, what's wrong and how it deviates from the requirement.\n",
    "\n",
    "## Chain of Thoughts\n",
    "\n",
    "1. Read and analyze the article.\n",
    "2. Read and analyze the <human_feedback>.\n",
    "3. Read and analyze all the requirements considering the <human_feedback> as a guiding force.\n",
    "4. Carefully compare the article against the requirements as instructed by the rules above.\n",
    "5. For each requirement, create 0 to N reviews\n",
    "6. Return the reviews of the article.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Prompt Engineering Techniques:**\n",
    "\n",
    "1. **Clear Role**: Expert reviewer with specific expertise\n",
    "2. **Explicit Priority System**: Rules are ranked (special rules > guideline > article profile > other profiles)\n",
    "3. **Output**: Clear instructions on what we want the LLM to fill for each attribute\n",
    "5. **Chain of Thought**: Explicit reasoning steps that glue together all the other sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. The Selected Text System Prompt:**\n",
    "\n",
    "When reviewing only a selected portion, we append additional instructions:\n",
    "\n",
    "```python\n",
    "class ArticleReviewer(Node):\n",
    "    system_prompt_template = \"\"\"...\"\"\"\n",
    "    \n",
    "    selected_text_system_prompt_template = \"\"\"\n",
    "You already reviewed and edited the whole article. Now we want to further review only a specific portion\n",
    "of the article, which we label as the <selected_text>. Despite reviewing the selected text, instead of the\n",
    "article as a whole, you will follow the exact same instructions from above as if you were reviewing the article as a whole.\n",
    "\n",
    "## Selected Text to Review\n",
    "\n",
    "Here is the selected text that needs to be reviewed:\n",
    "\n",
    "{selected_text}\n",
    "\n",
    "As pointed out before, the selected text is part of the larger <article> that is already reviewed.\n",
    "You will use the full <article> as context and anchoring the reviewing process within the bigger picture.\n",
    "\n",
    "The <first_line_number> and <last_line_number> numbers from the <selected_text> indicate the first and \n",
    "last line/row numbers of the selected text from the <article>. Use them to locate the selected text within the <article>.\n",
    "\n",
    "## Chain of Thoughts\n",
    "\n",
    "Here is the new chain of thoughts logic you will follow when reviewing the selected text. You can ignore the\n",
    "previous chain of thoughts:\n",
    "\n",
    "1. Read and analyze the article.\n",
    "2. Locate the <selected_text> within the <article> based on the <first_line_number> and <last_line_number>.\n",
    "3. Read and analyze the <human_feedback>.\n",
    "4. Read and analyze all the requirements considering the <human_feedback> as a guiding force.\n",
    "5. Carefully compare the selected text against the requirements as instructed by the rules above.\n",
    "6. For each requirement, create 0 to N reviews\n",
    "7. Return the reviews of the selected text.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "This allows focused reviews on specific sections while maintaining context of the full article. As this system prompt is passed together with the `system_prompt_template` system prompt it has to act only as an extension on explaining what to do with a selected text.\n",
    "\n",
    "The special trick here is that it adds a new `Chain of Thoughts` section that overrides the one from the original system prompts adding specialized instructions on how to reason across the new task, while still having all the context from both system prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Reviewing a Whole Article\n",
    "\n",
    "Now let's see the `ArticleReviewer` in action by reviewing a sample article.\n",
    "\n",
    "First load the sample article guideline and the standard profiles:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 17:56:51.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbrown.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mLoading environment file from `.env`\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------- Sample article guideline -------------------------------------\u001b[0m\n",
      "  ## Outline\n",
      "\n",
      "1. Introduction: The Critical Decision Every AI Engineer Faces\n",
      "2. Understanding the Spectrum: From Workflows to Agents\n",
      "3. Choosing Your Path\n",
      "4. Conclusion: The Challenges of Every AI Engineer\n",
      "\n",
      "## Section 1 - Introduction: The Critical Decision Every AI Engineer Faces\n",
      "\n",
      "- **The Problem:** When building AI applications, engineers face a critical architectural decision early in their development process. Should they create a predictable, step-by-step workflow where they control every action, or should they build an autonomous agent that can think and decide for itself? This is one of the key decisions that will impact everything from the product such as development time and costs to reliability and user experience.\n",
      "- Quick walkthrough of what we'll learn by the end of this lesson\n",
      "\n",
      "- **Section length:** 100 words\n",
      "\n",
      "## Section 2 - Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "- In this section we want to take a brief look at what LLM workflows and AI agents are. At this po\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.loaders import MarkdownArticleGuidelineLoader, MarkdownArticleLoader, MarkdownArticleProfilesLoader\n",
    "from brown.models import SupportedModels, get_model\n",
    "from brown.nodes import ArticleReviewer\n",
    "\n",
    "# Load the article guideline\n",
    "guideline_loader = MarkdownArticleGuidelineLoader(uri=Path(\"article_guideline.md\"))\n",
    "article_guideline = guideline_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load the article profiles\n",
    "profiles_input = {\n",
    "    \"article\": PROFILES_DIR / \"article_profile.md\",\n",
    "    \"character\": PROFILES_DIR / \"character_profiles\" / \"paul_iusztin.md\",\n",
    "    \"mechanics\": PROFILES_DIR / \"mechanics_profile.md\",\n",
    "    \"structure\": PROFILES_DIR / \"structure_profile.md\",\n",
    "    \"terminology\": PROFILES_DIR / \"terminology_profile.md\",\n",
    "    \"tonality\": PROFILES_DIR / \"tonality_profile.md\",\n",
    "}\n",
    "profiles_loader = MarkdownArticleProfilesLoader(uri=profiles_input)\n",
    "article_profiles = profiles_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "pretty_print.wrapped(article_guideline.content[:1000], title=\"Sample article guideline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load a sample article to review (that we already generated based on the same logic from lesson 22):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------- Sample article to review (first 3000 characters) -------------------------\u001b[0m\n",
      "  # Workflows vs. Agents: The Critical Decision Every AI Engineer Faces\n",
      "### How to choose between predictable control and autonomous flexibility when building AI applications.\n",
      "\n",
      "When building AI applications, engineers face a critical architectural decision early on. Should you create a predictable, step-by-step workflow where you control every action, or build an autonomous agent that can think and decide for itself? This choice impacts everything from development time and cost to reliability and user experience. It is a fundamental decision that often determines if an AI application will be successful in production.\n",
      "\n",
      "By the end of this lesson, you will understand the fundamental differences between LLM workflows and AI agents, know when to use each, and recognize how to combine their strengths in hybrid approaches.\n",
      "\n",
      "## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a database or calling an API. Think of it like a recipe where each step is explicitly defined. The key characteristic is that the path is determined in advance, resulting in a deterministic or rule-based system. This gives you predictable execution, explicit control over the application's flow, and makes the system easier to test and debug. Because you control every step, you know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. Instead, the agent uses a reasoning process to plan its actions based on the task and the current state of its environment. This process is often modeled on frameworks like ReAct (Reason, Act, Observe). This allows agents to be adaptive and capable of handling new or unexpected situations through LLM-driven autonomy. They can select tools, execute actions, evaluate the outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s).\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"Agent (LLM) Receives Goal\"]\n",
      "    B --> C[\"Plan/Reason (LLM)\"]\n",
      "    C --> D[\"Select Tool\"]\n",
      "    D --> E[\"Execute Action (Tool Call)\"]\n",
      "    E --> F[\"Observe Environment/Feedback\"]\n",
      "    F --> G{\"Evaluate Outcome\"}\n",
      "    G -->|\"Satisfactory\"| H[\"Stop/Achieve Goal\"]\n",
      "    G -->|\"Needs Adjustment\"| C\n",
      "```\n",
      "Image 2: Flowchart illustrating an AI agent's dynamic decis...\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "article_loader = MarkdownArticleLoader(uri=Path(\"article.md\"))\n",
    "article = article_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "pretty_print.wrapped(f\"{article.content[:3000]}...\", title=\"Sample article to review (first 3000 characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the article reviewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing article...\n",
      "\u001b[93m----------------------------------------- Article reviews -----------------------------------------\u001b[0m\n",
      "  Generated 49 reviews:\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 1 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Article level - Outline\",\n",
      "  \"Comment\": \"The article's main title is 'Workflows vs. Agents: The Critical Decision Every AI Engineer Faces'. However, the guideline specifies the title for Section 1 as 'Introduction: The Critical Decision Ever...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 2 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\",\n",
      "  \"Comment\": \"The article's introduction contains 84 words, which is within the 100-word limit. However, the guideline specifies the content for the 'The Problem' part of the introduction. The article's content lar...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 3 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - First paragraph\",\n",
      "  \"Comment\": \"The article states 'To make the right choice, you first need to understand what LLM workflows and AI agents are. We will look at their core properties and how they are used, rather than their technica...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 4 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"LLM Workflows - First paragraph\",\n",
      "  \"Comment\": \"The article's definition of LLM workflows ('An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a datab...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 5 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"LLM Workflows - Mermaid diagram\",\n",
      "  \"Comment\": \"The article includes a Mermaid diagram for LLM Workflows. The guideline specifically requests 'Add a Mermaid diagram' for LLM workflows. The diagram content seems appropriate.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 6 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"AI Agents - First paragraph\",\n",
      "  \"Comment\": \"The article's definition of AI agents ('AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined.') aligns wit...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 7 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"AI Agents - Mermaid diagram\",\n",
      "  \"Comment\": \"The article includes a Mermaid diagram for AI Agents. The guideline specifically requests 'Add a Mermaid diagram' for AI agents. The diagram content seems appropriate.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 8 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Article level\",\n",
      "  \"Comment\": \"The section 'Understanding the Spectrum: From Workflows to Agents' contains approximately 270 words (excluding diagram code and captions), which exceeds the guideline's specified length of '200 words ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 9 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - First paragraph\",\n",
      "  \"Comment\": \"The article correctly introduces the core difference: 'The core difference between these two approaches lies in a single trade-off: developer-defined logic versus LLM-driven autonomy'. This aligns wit...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 10 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Image 3\",\n",
      "  \"Comment\": \"The article includes an image 'Image 3: The trade-off between an agent's level of control and application reliability.' with a link and proper citation. The guideline requests to 'Attach an image from...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 11 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"When to use LLM workflows - Examples\",\n",
      "  \"Comment\": \"The article provides examples for LLM workflows: 'Workflows are ideal for repeatable tasks with defined steps, like data extraction, report generation, or content repurposing.' The guideline's example...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 12 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"When to use LLM workflows - Strengths\",\n",
      "  \"Comment\": \"The article lists strengths as 'predictability, ensuring reliable results, easier debugging, and lower costs by using specialized models.' The guideline includes 'potentially lower operational costs a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 13 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"When to use LLM workflows - Weaknesses\",\n",
      "  \"Comment\": \"The article mentions 'rigidity; they cannot handle unexpected scenarios, and adding features can become complex.' The guideline details more weaknesses: 'Potentially more development time required as ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 14 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"When to use AI agents - Examples\",\n",
      "  \"Comment\": \"The article gives examples: 'Agents excel at dynamic problem-solving like open-ended research or complex customer support'. The guideline's examples are more detailed: 'Open-ended research and synthes...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 15 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"When to use AI agents - Strengths\",\n",
      "  \"Comment\": \"The article states the strength as 'flexibility in handling ambiguity.' The guideline also adds 'Adaptability to new situations and the flexibility to handle ambiguity and complexity as the steps are ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 16 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"When to use AI agents - Weaknesses\",\n",
      "  \"Comment\": \"The article covers several weaknesses: 'less reliable, harder to debug, and costlier due to non-deterministic behavior. Without proper guardrails, they also pose security risks, especially with operat...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 17 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Hybrid Approaches - First paragraph\",\n",
      "  \"Comment\": \"The article describes hybrid approaches: 'Most real-world systems are not purely one or the other. They often blend elements of both, creating a hybrid system. A common pattern is to use a workflow fo...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 18 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Hybrid Approaches - Mermaid diagram\",\n",
      "  \"Comment\": \"The article includes a Mermaid diagram for a 'AI generation and human verification loop with iterative refinement.' The guideline specifically requests to 'Generate a mermaid to illustrate the AI gene...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 19 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Article level\",\n",
      "  \"Comment\": \"The section 'Choosing Your Path' contains approximately 460 words (excluding the image and diagram code). The guideline specifies a length of '200 words'. This section significantly exceeds the word l...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 20 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The article states: 'Understanding the spectrum from workflows to agents is a core part of AI engineering. This choice helps determine if your application will succeed in production.' This aligns with...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 21 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"The Challenges of Every AI Engineer - Daily challenges\",\n",
      "  \"Comment\": \"The article presents daily challenges: 'building pipelines to pull information from Slack, web APIs, SQL databases, and data lakes; managing the cost-performance trap where sophisticated agents become...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 22 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"The Challenges of Every AI Engineer - Transition to next lesson\",\n",
      "  \"Comment\": \"The article concludes: 'In our next lesson, we will explore a foundational skill for building both workflows and agents: context engineering.' This aligns perfectly with the guideline's instruction to...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 23 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"The Challenges of Every AI Engineer - Article level\",\n",
      "  \"Comment\": \"The section 'The Challenges of Every AI Engineer' contains approximately 105 words. The guideline specifies a length of '100 words'. This is a minor deviation, but it would be ideal to be within or ve...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 24 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"References - Golden Sources\",\n",
      "  \"Comment\": \"The article includes a reference to 'Google. (n.d.). Gemini CLI. GitHub. https://github.com/google-gemini/gemini-cli/blob/main/README.md' which is listed as a Golden Source in the article guideline, b...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 25 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"character_profile\",\n",
      "  \"Location\": \"Article level\",\n",
      "  \"Comment\": \"The article maintains a professional, informative, and direct tone, which aligns with the 'Paul Iusztin' character profile. It avoids excessive hype and focuses on technical explanations.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 26 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Article level\",\n",
      "  \"Comment\": \"The article generally uses simple, direct language. However, it uses the phrase 'critical decision with confidence' in the title's subtitle and the introductory paragraph 'critical architectural decis...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 27 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\",\n",
      "  \"Comment\": \"The phrase 'critical architectural decision' is used, which is close to the banned 'critical decision with confidence'. While not exactly the same, it shares the word 'critical' and implies a similar ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 28 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'The core difference between these two approaches lies in a single trade-off: developer-defined logic versus LLM-driven autonomy' uses the word 'lies', which is not explicitly banned but ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 29 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"When to use AI agents - First paragraph\",\n",
      "  \"Comment\": \"The article states 'Agents excel at dynamic problem-solving'. The word 'excel' is not on the banned list, but it leans towards marketing-y or exaggerated language that the terminology profile aims to ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 30 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"tonality_profile\",\n",
      "  \"Location\": \"Article level\",\n",
      "  \"Comment\": \"The article maintains a conversational yet authoritative voice, using plain English with precise technical nouns, which aligns with the tonality profile. It does not sound like marketing a product rel...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 31 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Workflows vs. Agents: The Critical Decision Every AI Engineer Faces - Subtitle\",\n",
      "  \"Comment\": \"The subtitle 'How to choose between predictable control and autonomous flexibility when building AI applications.' is correctly not capitalized, aligning with the 'Capitalization patterns' rule.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 32 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Workflows vs. Agents: The Critical Decision Every AI Engineer Faces - Title\",\n",
      "  \"Comment\": \"The main title 'Workflows vs. Agents: The Critical Decision Every AI Engineer Faces' is capitalized as per the 'Capitalization patterns' rule.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 33 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - First paragraph\",\n",
      "  \"Comment\": \"The article uses 'you' and 'we' consistently with the 'Point of View' rule, addressing the reader directly and using 'we' for the team/authors.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 34 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"AI Agents - First paragraph\",\n",
      "  \"Comment\": \"The article uses the citation format '[[1]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s)' at the end of a sentence before the period, which generally follows the 'Citation Rules'. However, the id...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 35 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Choosing Your Path - First paragraph\",\n",
      "  \"Comment\": \"The article uses citations '[[2]](https://decodingml.substack.com/p/llmops-for-production-agentic-rag), [[3]](https://towardsdatascience.com/a-developers-guide-to-building-scalable-ai-workflows-vs-age...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 36 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"References - Article level\",\n",
      "  \"Comment\": \"The references section includes '4. Google. (n.d.). Gemini CLI. GitHub. https://github.com/google-gemini/gemini-cli/blob/main/README.md'. This source is listed in the <article_guideline> Golden Source...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 37 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"References - Article level\",\n",
      "  \"Comment\": \"The numbering of references in the 'References' section does not align with the provided Golden Sources. The golden sources are 1, 2, 3, 4. The article has 1, 2, 3, 4. However, the content of referenc...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 38 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"References - Article level\",\n",
      "  \"Comment\": \"The 'References' section lists citations 1-4. The formatting for the reference '3. (n.d.). A developer\\u2019s guide to building scalable AI: Workflows vs agents. Towards Data Science. https://towardsdatasc...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 39 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"References - Article level\",\n",
      "  \"Comment\": \"The 'References' section lists citations 1-4. The article uses a mix of author names and '(n.d.)' for titles or dates. The `references_rules` state: 'If the author, publish date or full title is missi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 40 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\",\n",
      "  \"Comment\": \"The introduction's first paragraph has 84 words. The 'Sentence and paragraph length patterns' rule states 'Keep paragraphs \\u2264 80 words'. This paragraph slightly exceeds the limit. It should be condense...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 41 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Article level\",\n",
      "  \"Comment\": \"The section 'Understanding the Spectrum: From Workflows to Agents' has 270 words (excluding diagrams), which exceeds the 80-word paragraph rule in some of its sub-paragraphs, and also the overall sect...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 42 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"When to use AI agents - Second paragraph\",\n",
      "  \"Comment\": \"The paragraph discussing the weaknesses of AI agents ('Agents excel at dynamic problem-solving like open-ended research or complex customer support [[3]](https://towardsdatascience.com/a-developers-gu...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 43 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Article level\",\n",
      "  \"Comment\": \"The section 'Choosing Your Path' contains 460 words (excluding image/diagrams), significantly exceeding the article guideline's 200-word limit. Additionally, individual paragraphs within this section ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 44 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Image 1, Image 2, Image 3, Image 4\",\n",
      "  \"Comment\": \"The image captions follow the specified format, including 'Image <media_identifier>: <diagram description>' or 'Image <media_identifier>: <image description> (Image by <author_name> from [<citation_na...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 45 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Article level\",\n",
      "  \"Comment\": \"The article is structured with an introduction, sections, and a conclusion, using H2 and H3 headers, which aligns with the 'Article Template' and 'Sections Sub-Heading Formatting' rules. The flow betw...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 46 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\",\n",
      "  \"Comment\": \"The introduction covers the 'why' and 'what' by presenting the problem and its impacts, aiming to captivate the reader. It sets the stage for the rest of the article as per the 'Introduction Guideline...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 47 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The conclusion provides a short wrap-up of what was learned and connects to future lessons, aligning with the 'Conclusion Guidelines'. It reinforces the core ideas and transitions to the bigger pictur...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 48 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_profile\",\n",
      "  \"Location\": \"References - Article level\",\n",
      "  \"Comment\": \"The 'References' section is present at the end of the article, listing all sources. This aligns with the 'General Article Structure' and 'References Rules'.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 49 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"abbreviation_acronym_rules\",\n",
      "  \"Location\": \"Article level\",\n",
      "  \"Comment\": \"The acronyms LLM and AI are used without expansion throughout the article, which aligns with the `abbreviations_or_acronyms_never_to_expand_rules`.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "reviewer = ArticleReviewer(\n",
    "    to_review=article,\n",
    "    article_guideline=article_guideline,\n",
    "    article_profiles=article_profiles,\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "print(\"Reviewing article...\")\n",
    "article_reviews = await reviewer.ainvoke()\n",
    "\n",
    "pretty_print.wrapped(f\"Generated {len(article_reviews.reviews)} reviews:\", title=\"Article reviews\")\n",
    "for i, review in enumerate(article_reviews.reviews, 1):\n",
    "    review_dict = {\n",
    "        \"Profile\": review.profile,\n",
    "        \"Location\": review.location,\n",
    "        \"Comment\": review.comment[:200] + \"...\" if len(review.comment) > 200 else review.comment,\n",
    "    }\n",
    "    pretty_print.wrapped(review_dict, title=f\"Review {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Reviewing Selected Text\n",
    "\n",
    "Now let's review only a specific section of the article:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------- Selected text to review -------------------------------------\u001b[0m\n",
      "  Selected text: 2414 characters\n",
      "Lines: 11-44\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------- Selected text context (first 1500 characters) --------------------------\u001b[0m\n",
      "  \n",
      "<selected_text>\n",
      "    \n",
      "    <content>### LLM Workflows\n",
      "\n",
      "An LLM workflow is a sequence of tasks orchestrated by developer-written code. It can include LLM calls, but also other operations like reading from a database or calling an API. Think of it like a recipe where each step is explicitly defined. The key characteristic is that the path is determined in advance, resulting in a deterministic or rule-based system. This gives you predictable execution, explicit control over the application's flow, and makes the system easier to test and debug. Because you control every step, you know exactly where a failure occurred and how to fix it.\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    A[\"Start\"] --> B[\"LLM Call\"]\n",
      "    B --> C[\"Process Data\"]\n",
      "    C --> D[\"Store Data\"]\n",
      "    D --> E[\"End\"]\n",
      "```\n",
      "Image 1: A flowchart illustrating a deterministic LLM workflow with clear start and end points, including an LLM call and data operations.\n",
      "\n",
      "### AI Agents\n",
      "\n",
      "AI agents are systems where an LLM dynamically decides the sequence of steps, reasoning, and actions to achieve a goal. The path is not predefined. Instead, the agent uses a reasoning process to plan its actions based on the task and the current state of its environment. This process is often modeled on frameworks like ReAct (Reason, Act, Observe). This allows agents to be adaptive and capable of handling new or unexpected situations through LLM-driven autonomy. They can select tools, execute actions, evaluate the outcomes, and correct their course until the goal is achieved [[1]](https://www.youtube.co\n",
      "...</content>\n",
      "    <first_line_number>11</first_line_number>\n",
      "    <last_line_number>44</last_line_number>\n",
      "</selected_text>\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.entities.articles import SelectedText\n",
    "\n",
    "# Let's extract a specific section to review\n",
    "article_lines = article.content.split(\"\\n\")\n",
    "first_line_number = 11\n",
    "last_line_number = 44\n",
    "selected_content = \"\\n\".join(article_lines[first_line_number:last_line_number])\n",
    "\n",
    "selected_text = SelectedText(\n",
    "    article=article,\n",
    "    content=selected_content,\n",
    "    first_line_number=first_line_number,\n",
    "    last_line_number=last_line_number,\n",
    ")\n",
    "\n",
    "cropped_selected_text = selected_text.model_copy()\n",
    "cropped_selected_text.content = f\"{cropped_selected_text.content[:1500]}\\n...\"\n",
    "\n",
    "text = [\n",
    "    f\"Selected text: {len(selected_content)} characters\",\n",
    "    f\"Lines: {selected_text.first_line_number}-{selected_text.last_line_number}\",\n",
    "]\n",
    "pretty_print.wrapped(\"\\n\".join(text), title=\"Selected text to review\")\n",
    "pretty_print.wrapped(cropped_selected_text.to_context(), title=\"Selected text context (first 1500 characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's review the selected text (note how we used the same `ArticleReviewer` class for both inputs containing the business logic in a single place):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing selected text...\n",
      "\u001b[93m-------------------------------------- Selected text reviews --------------------------------------\u001b[0m\n",
      "  Generated 2 reviews for selected text:\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 1 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - LLM Workflows sub-section\",\n",
      "  \"Comment\": \"The caption for Image 1 is missing the citation requirements (`Source`, `Image by`, `citation_name`, `citation_identifier`, `citation_url`). The guideline specifies that all media items should contain...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 2 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - AI Agents sub-section\",\n",
      "  \"Comment\": \"The caption for Image 2 is missing the citation requirements (`Source`, `Image by`, `citation_name`, `citation_identifier`, `citation_url`). The guideline specifies that all media items should contain...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "reviewer = ArticleReviewer(\n",
    "    to_review=selected_text,  # Now passing SelectedText instead of Article\n",
    "    article_guideline=article_guideline,\n",
    "    article_profiles=article_profiles,\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "print(\"Reviewing selected text...\")\n",
    "selected_text_reviews = await reviewer.ainvoke()\n",
    "\n",
    "pretty_print.wrapped(\n",
    "    f\"Generated {len(selected_text_reviews.reviews)} reviews for selected text:\", title=\"Selected text reviews\"\n",
    ")\n",
    "for i, review in enumerate(selected_text_reviews.reviews, 1):\n",
    "    review_dict = {\n",
    "        \"Profile\": review.profile,\n",
    "        \"Location\": review.location,\n",
    "        \"Comment\": review.comment[:200] + \"...\" if len(review.comment) > 200 else review.comment,\n",
    "    }\n",
    "    pretty_print.wrapped(review_dict, title=f\"Review {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hooking the Reviews to the Article Writer (The Optimizer) \n",
    "\n",
    "Now let's see how the `ArticleWriter` node handles reviews to act as the **optimizer** in our evaluator-optimizer pattern.\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "To keep the \"writing\" logic contained and avoid duplicated code, the `ArticleWriter` serves dual purposes:\n",
    "\n",
    "1. **Writer**: Generates the initial article draft\n",
    "2. **Editor**: Edits the article based on reviews\n",
    "\n",
    "This mirrors real-world writing processes where the original author both writes and edits their own work based on feedback. It keeps all writing knowledge in one place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes to ArticleWriter __init__\n",
    "\n",
    "The `ArticleWriter` now accepts an optional `reviews` parameter:\n",
    "```python\n",
    "class ArticleWriter(Node):\n",
    "    def __init__(\n",
    "        self,\n",
    "        article_guideline: ArticleGuideline,\n",
    "        research: Research,\n",
    "        article_profiles: ArticleProfiles,\n",
    "        media_items: MediaItems,\n",
    "        article_examples: ArticleExamples,\n",
    "        model: Runnable,\n",
    "        reviews: ArticleReviews | SelectedTextReviews | None = None,  # NEW!\n",
    "    ) -> None:\n",
    "        super().__init__(model, toolkit=Toolkit(tools=[]))\n",
    "        \n",
    "        self.article_guideline = article_guideline\n",
    "        self.research = research\n",
    "        self.article_profiles = article_profiles\n",
    "        self.media_items = media_items\n",
    "        self.article_examples = article_examples\n",
    "        self.reviews = reviews  # Store reviews for editing mode\n",
    "```\n",
    "\n",
    "**Key Insight:**\n",
    "\n",
    "When `reviews=None`, the writer generates a new article from scratch. When reviews are provided, it edits the existing article based on the feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes to the ainvoke Method\n",
    "\n",
    "The `ainvoke` method now handles both writing and editing:\n",
    "```python\n",
    "async def ainvoke(self) -> Article | SelectedText:\n",
    "    # Step 1: Build the main system prompt (same as before)\n",
    "    system_prompt = self.system_prompt_template.format(\n",
    "        article_guideline=self.article_guideline.to_context(),\n",
    "        research=self.research.to_context(),\n",
    "        # ... all other context ...\n",
    "    )\n",
    "    \n",
    "    user_input_content = self.build_user_input_content(\n",
    "        inputs=[system_prompt], \n",
    "        image_urls=self.research.image_urls\n",
    "    )\n",
    "    inputs = [{\"role\": \"user\", \"content\": user_input_content}]\n",
    "    \n",
    "    # Step 2: If reviews exist, add them to the conversation\n",
    "    if self.reviews:\n",
    "        # First, provide the previously written article as the assistant's response.\n",
    "        # This is important because the editing will be done relative to the article.\n",
    "        # Thus, we have to anchor the reviews on the evaluated article.\n",
    "        inputs.extend([\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": self.reviews.article.to_context(),\n",
    "            },\n",
    "        ])\n",
    "        \n",
    "        # Then, provide the reviews as user feedback, along with a new system prompt that\n",
    "        # instructs the agent on how to edit the article. In this way, we can \"hijack\"\n",
    "        # the original system template to edit the article instead of writing it from scratch.\n",
    "        if isinstance(self.reviews, ArticleReviews):\n",
    "            reviews_prompt = self.article_reviews_prompt_template.format(\n",
    "                reviews=self.reviews.to_context(include_article=False),\n",
    "            )\n",
    "        elif isinstance(self.reviews, SelectedTextReviews):\n",
    "            reviews_prompt = self.selected_text_reviews_prompt_template.format(\n",
    "                selected_text=self.reviews.selected_text.to_context(),\n",
    "                reviews=self.reviews.to_context(include_article=False),\n",
    "            )\n",
    "        \n",
    "        inputs.extend([{\"role\": \"user\", \"content\": reviews_prompt}])\n",
    "    \n",
    "    # Step 3: Generate/edit the article\n",
    "    written_output = await self.model.ainvoke(inputs)\n",
    "    written_output = cast(str, written_output.text)\n",
    "    \n",
    "    # Step 4: Return appropriate type\n",
    "    if isinstance(self.reviews, SelectedTextReviews):\n",
    "        return SelectedText(\n",
    "            article=self.reviews.article,\n",
    "            content=written_output,\n",
    "            first_line_number=self.reviews.selected_text.first_line_number,\n",
    "            last_line_number=self.reviews.selected_text.last_line_number,\n",
    "        )\n",
    "    else:\n",
    "        return Article(content=written_output)\n",
    "```\n",
    "\n",
    "**Context engineering for editing:**\n",
    "\n",
    "1. **User**: System prompt with all context (guidelines, profiles, etc.)\n",
    "2. **Assistant**: The previously written article\n",
    "3. **User**: The reviews with specific issues to fix\n",
    "4. **Assistant**: The edited article (generated by LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Review Prompt Templates\n",
    "\n",
    "The writer has two additional prompt templates for handling reviews. One for editing the whole article and whole for the selected text.\n",
    "\n",
    "**1. Article Reviews Prompt:**\n",
    "\n",
    "```python\n",
    "article_reviews_prompt_template = \"\"\"\n",
    "We personally reviewed the article and compiled a list of reviews based on which you have to \n",
    "edit the article you wrote one step before.\n",
    "\n",
    "## Reviewing Logic\n",
    "\n",
    "Here is how we created the feedback reviews:\n",
    "- We compared the article against the <article_guideline> to ensure it follows user intent\n",
    "- We compared against all profile constraints\n",
    "- Manual human reviews create special \"human_feedback\" reviews (highest priority)\n",
    "- For each broken rule, we created a review\n",
    "\n",
    "## Ranking the Importance of the Reviews\n",
    "\n",
    "1. Always prioritize the human feedback reviews above everything else\n",
    "2. Next prioritize reviews based on the <article_guideline>\n",
    "3. Finally prioritize reviews based on other profiles\n",
    "\n",
    "## Reviews\n",
    "\n",
    "Here are the reviews you have to fix:\n",
    "{reviews}\n",
    "\n",
    "## Chain of Thought\n",
    "\n",
    "1. Analyze the reviews to understand what needs to be changed\n",
    "2. Prioritize the reviews based on the importance ranking\n",
    "3. Apply necessary edits while following all instructions from profiles and guidelines\n",
    "4. Ensure edited text is still anchored in <research> and <article_guideline>\n",
    "5. Ensure edited text flows naturally with surrounding content\n",
    "6. Return the fully edited article\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Explains the review creation process\n",
    "- Provides clear priority ranking\n",
    "- New chain of thought section adding the new reasoning steps and final task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Selected Text Reviews Prompt:**\n",
    "\n",
    "```python\n",
    "selected_text_reviews_prompt_template = \"\"\"\n",
    "We personally reviewed only a portion of the article and compiled reviews for editing just that \n",
    "selected text.\n",
    "\n",
    "## Selected Text to Edit\n",
    "\n",
    "{selected_text}\n",
    "\n",
    "Remember this selected text is part of the article from one step before. Anchor your editing within \n",
    "the broader context of the article.\n",
    "\n",
    "Selected text editing guidelines:\n",
    "- Keep selected text consistent with surrounding article context\n",
    "- Use first and last line numbers to locate the selection\n",
    "- Only edit the selected text, don't modify the entire article\n",
    "\n",
    "## [Rest similar to article reviews prompt - reviewing logic, priority ranking, etc.]\n",
    "\n",
    "{reviews}\n",
    "\n",
    "## Chain of Thought\n",
    "\n",
    "1. Place the selected text in context of the full article\n",
    "2. Analyze the reviews\n",
    "3. Prioritize reviews based on importance ranking\n",
    "4. Apply edits while following all instructions\n",
    "5. Ensure edited selected text is still anchored in research/guideline\n",
    "6. Ensure edited selected text flows naturally with surrounding content\n",
    "7. Return the fully edited selected text\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "The prompt is similar to the one for editing the whole article, but we added special details on clearly explaining how to manipulate the selected text. Remember that LLMs have zero clue of what is going on within your application and business logic. Thus, you have to explain all your processes super clearly for this to work well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running an End-to-End Example: Review and Edit Loop\n",
    "\n",
    "Now let's run a complete example showing the full workflow: generate media, write article, review, and edit. First, let's run it without LangGraph. Next, we will glue everything together into a standalone LangGraph workflow that can further be shipped to production.\n",
    "\n",
    "This time, we will use a more comprehensive test sample containing a more detailed `article_guideline.md` and more facts within the `research.md` file to show what a professional input would look like. \n",
    "\n",
    "We recommend opening the new `article_guideline.md` from `02_sample_medium` and comparing it to the one from `01_sample_small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_DIR = Path(\"inputs/tests/02_sample_medium\")\n",
    "SAMPLE_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load all necessary context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 1: Loading Context\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Guideline: 22,854 characters\n",
      "âœ“ Research: 211,790 characters, 14 images\n",
      "âœ“ Profiles: 6 profiles loaded\n",
      "âœ“ Examples: 2 article examples\n"
     ]
    }
   ],
   "source": [
    "from brown.loaders import (\n",
    "    MarkdownArticleExampleLoader,\n",
    "    MarkdownArticleGuidelineLoader,\n",
    "    MarkdownArticleProfilesLoader,\n",
    "    MarkdownResearchLoader,\n",
    ")\n",
    "\n",
    "pretty_print.wrapped(\"STEP 1: Loading Context\", width=100)\n",
    "\n",
    "# Load guideline\n",
    "guideline_loader = MarkdownArticleGuidelineLoader(uri=Path(\"article_guideline.md\"))\n",
    "article_guideline = guideline_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load research\n",
    "research_loader = MarkdownResearchLoader(uri=Path(\"research.md\"))\n",
    "research = research_loader.load(working_uri=SAMPLE_DIR)\n",
    "\n",
    "# Load profiles\n",
    "profiles_input = {\n",
    "    \"article\": PROFILES_DIR / \"article_profile.md\",\n",
    "    \"character\": PROFILES_DIR / \"character_profiles\" / \"paul_iusztin.md\",\n",
    "    \"mechanics\": PROFILES_DIR / \"mechanics_profile.md\",\n",
    "    \"structure\": PROFILES_DIR / \"structure_profile.md\",\n",
    "    \"terminology\": PROFILES_DIR / \"terminology_profile.md\",\n",
    "    \"tonality\": PROFILES_DIR / \"tonality_profile.md\",\n",
    "}\n",
    "profiles_loader = MarkdownArticleProfilesLoader(uri=profiles_input)\n",
    "article_profiles = profiles_loader.load()\n",
    "\n",
    "# Load examples\n",
    "examples_loader = MarkdownArticleExampleLoader(uri=EXAMPLES_DIR)\n",
    "article_examples = examples_loader.load()\n",
    "\n",
    "print(f\"âœ“ Guideline: {len(article_guideline.content):,} characters\")\n",
    "print(f\"âœ“ Research: {len(research.content):,} characters, {len(research.image_urls)} images\")\n",
    "print(f\"âœ“ Profiles: {len(profiles_input)} profiles loaded\")\n",
    "print(f\"âœ“ Examples: {len(article_examples.examples)} article examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate media items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Analyzing article guideline for media requirements...\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Found {len(media_jobs)} media items to generate\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 1 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart illustrating a typical LLM workflow. It should show a sequence of tasks involving LLM ca...\",\n",
      "  \"Section\": \"LLM Workflow\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 2 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart showing the AI generation and human verification loop. It should illustrate an iterative...\",\n",
      "  \"Section\": \"AI Generation and Human Verification Loop\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 3 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart illustrating the Chaining and Routing pattern for LLM workflows. Show multiple LLM calls...\",\n",
      "  \"Section\": \"Chaining and Routing LLM Workflow Pattern\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 4 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart illustrating the Orchestrator-Worker pattern in LLM workflows. Show a central Orchestrat...\",\n",
      "  \"Section\": \"Orchestrator-Worker LLM Workflow Pattern\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 5 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart illustrating the Evaluator-Optimizer loop for LLM outputs. Show a Generator LLM producin...\",\n",
      "  \"Section\": \"Evaluator-Optimizer Loop LLM Workflow Pattern\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 6 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A high-level diagram illustrating the core components and dynamics of an AI agent based on the ReAct...\",\n",
      "  \"Section\": \"Core Components of an AI Agent (ReAct Pattern Overview) \"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 7 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A simple flowchart illustrating the Document Summarization and Analysis workflow by Gemini in Google...\",\n",
      "  \"Section\": \"Gemini Document Summarization and Analysis Workflow\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 8 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart illustrating the operational loop of the Gemini CLI coding assistant based on the ReAct ...\",\n",
      "  \"Section\": \"Gemini CLI Coding Assistant Operational Loop (ReAct Pattern) \"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Job 9 ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Tool\": \"mermaid_diagram_generator_tool\",\n",
      "  \"Description\": \"A flowchart illustrating the iterative multi-step process of Perplexity's Deep Research agent. The d...\",\n",
      "  \"Section\": \"Perplexity Deep Research Agent: Iterative Multi-Step Process (Hybrid System) \"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Generating media items in parallel...\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  Generated 9 media items successfully!\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from brown.entities.media_items import MediaItems\n",
    "from brown.models import SupportedModels, get_model\n",
    "from brown.nodes import MediaGeneratorOrchestrator, MermaidDiagramGenerator, Toolkit\n",
    "\n",
    "# Create worker tool\n",
    "diagram_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "mermaid_generator = MermaidDiagramGenerator(model=diagram_model)\n",
    "toolkit = Toolkit(tools=[mermaid_generator.as_tool()])\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "orchestrator = MediaGeneratorOrchestrator(\n",
    "    article_guideline=article_guideline,\n",
    "    research=research,\n",
    "    model=orchestrator_model,\n",
    "    toolkit=toolkit,\n",
    ")\n",
    "\n",
    "# Get media generation jobs\n",
    "pretty_print.wrapped(\"Analyzing article guideline for media requirements...\")\n",
    "media_jobs = await orchestrator.ainvoke()\n",
    "\n",
    "\n",
    "pretty_print.wrapped(\"Found {len(media_jobs)} media items to generate\")\n",
    "media_jobs_dict = {}\n",
    "for i, job in enumerate(media_jobs):\n",
    "    pretty_print.wrapped(\n",
    "        {\n",
    "            \"Tool\": job[\"name\"],\n",
    "            \"Description\": job[\"args\"].get(\"description_of_the_diagram\", \"N/A\")[:100] + \"...\",\n",
    "            \"Section\": job[\"args\"].get(\"section_title\", \"N/A\"),\n",
    "        },\n",
    "        title=f\"Job {i + 1}\",\n",
    "    )\n",
    "\n",
    "pretty_print.wrapped(\"Generating media items in parallel...\")\n",
    "coroutines = []\n",
    "for job in media_jobs:\n",
    "    tool = orchestrator.toolkit.get_tool_by_name(job[\"name\"])\n",
    "    if tool:\n",
    "        coroutines.append(tool.ainvoke(job[\"args\"]))\n",
    "\n",
    "media_items = await asyncio.gather(*coroutines)\n",
    "media_items = MediaItems.build(media_items=media_items)\n",
    "\n",
    "pretty_print.wrapped(f\"Generated {len(media_items.media_items)} media items successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write the first draft of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 3: Writing Article (First Draft)\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "This may take 1-2 minutes...\n",
      "âœ“ Article generated: 29,441 characters\n",
      "\u001b[93m-------------------------------------------- First Draft (First 1000 chars) --------------------------------------------\u001b[0m\n",
      "  # Workflows vs. Agents: The AI Engineer's Critical Choice\n",
      "\n",
      "Every AI engineer eventually confronts a pivotal architectural decision: Will you build a predictable, step-by-step workflow where you dictate every action, or will you create an autonomous agent that thinks and decides for itself? This choice isn't just a technical detail; it shapes everything from development time and operational costs to the application's reliability and user experience.\n",
      "\n",
      "Opting for the wrong approach can lead to significant setbacks. You might end up with a system too rigid to adapt, breaking down when users deviate from expected patterns, or an agent that performs brilliantly 80% of the time but fails spectacularly when it matters most. This can result in months of wasted development, frustrated users, and executives questioning the value proposition of AI investments. Across 2024-2025, billion-dollar AI startups have seen their successâ€”or failureâ€”hinge primarily on this architectural distinction. The most\n",
      "\u001b[93m------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.nodes import ArticleWriter\n",
    "\n",
    "pretty_print.wrapped(\"STEP 3: Writing Article (First Draft)\", width=100)\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "writer_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_writer = ArticleWriter(\n",
    "    article_guideline=article_guideline,\n",
    "    research=research,\n",
    "    article_profiles=article_profiles,\n",
    "    media_items=media_items,\n",
    "    article_examples=article_examples,\n",
    "    model=writer_model,\n",
    "    reviews=None,  # No reviews for first draft\n",
    ")\n",
    "\n",
    "article = await article_writer.ainvoke()\n",
    "\n",
    "print(f\"âœ“ Article generated: {len(article.content):,} characters\")\n",
    "pretty_print.wrapped(article.content[:1000], title=\"First Draft (First 1000 chars)\", width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Review the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 4: Reviewing Article\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "âœ“ Generated 95 reviews\n",
      "\u001b[93m--------------------------------------------- Review 1 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Article Level\",\n",
      "  \"Comment\": \"The article is missing an explicit subtitle as specified in the article template: '### Subtitle' after the main title.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 2 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\",\n",
      "  \"Comment\": \"The introduction's first paragraph uses the wording 'Every AI engineer eventually confronts a pivotal architectural decision: Will you build a predict...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 3 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'This choice isn't just a technical detail; it shapes everything from development time and operational costs to the application's reliabi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 4 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Second paragraph\",\n",
      "  \"Comment\": \"The article guideline for 'Why This Decision Matters' specifies 'Frustrated executives who cannot affort to keep the AI agent running as the costs are...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 5 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Second paragraph\",\n",
      "  \"Comment\": \"The word 'spectacularly' in 'fails spectacularly' is considered dramatic language and should be avoided according to the terminology profile.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 6 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Third paragraph\",\n",
      "  \"Comment\": \"The article guideline specifies 'Make a quick reference to the real-world where in 2024-2025 billion-dollar AI startups succeed or fail based primaril...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 7 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Third paragraph\",\n",
      "  \"Comment\": \"The word 'primarily' is listed as an AI slop word to avoid. It should be replaced with a more direct alternative.\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 8 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Section Length\",\n",
      "  \"Comment\": \"The introduction has approximately 174 words, which is significantly below the 300-word length constraint specified in the article guideline. The intr...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------- Review 9 ---------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Third paragraph\",\n",
      "  \"Comment\": \"The word 'effectively' in 'combine both approaches effectively' is a common AI slop word and should be replaced with a simpler term or rephrased for d...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 10 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Fourth paragraph\",\n",
      "  \"Comment\": \"The phrase 'By the end of this lesson, you will grasp the fundamental differences and optimal use cases for LLM workflows and AI agents, enabling you ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 11 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Introduction: The Critical Decision Every AI Engineer Faces - Fourth paragraph\",\n",
      "  \"Comment\": \"The sentence 'We'll explore their characteristics, practical examples, and the patterns that define them.' uses 'We'll', which is a contraction and de...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 12 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - First paragraph\",\n",
      "  \"Comment\": \"The phrase 'To make informed architectural decisions, we first need a clear understanding of what LLM workflows and AI agents actually are.' uses 'inf...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 13 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'To make informed architectural decisions, we first need a clear understanding of what LLM workflows and AI agents actually are.' uses 'w...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 14 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - LLM Workflows - Definition\",\n",
      "  \"Comment\": \"The article guideline for LLM Workflows states 'It is largely predefined and orchestrated by developer-written code.' The article states 'Developer-wr...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 15 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - LLM Workflows - Characteristics\",\n",
      "  \"Comment\": \"The analogy 'You can think of a workflow as a factory assembly line:' uses 'You can think of X as', which is a banned AI slop phrase. It should be rep...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 16 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - LLM Workflows - Characteristics\",\n",
      "  \"Comment\": \"The sentence 'In future lessons, we will explore key workflow concepts like chaining, routing, and orchestrator-worker patterns.' uses 'we will explor...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 17 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - LLM Workflows - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline specifically asks to 'Generate a mermaid diagram with an LLM workflow'. The current diagram is present, but the caption is 'Imag...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 18 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - AI Agents - Characteristics\",\n",
      "  \"Comment\": \"The analogy 'An agent is like a skilled human expert tackling an unfamiliar problem, adapting on the moment after each 'Eureka!' moment.' uses 'adapti...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 19 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - AI Agents - Characteristics\",\n",
      "  \"Comment\": \"The sentence 'Later in this course, we will explore concepts crucial to agents, such as tools, memory, and the ReAct framework.' uses 'we will explore...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 20 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - AI Agents - Image\",\n",
      "  \"Comment\": \"The article guideline asks to 'Attach an image from the research of how a simple Agentic System looks.' The article provides 'Image 2: The components ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 21 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Understanding the Spectrum: From Workflows to Agents - Section Length\",\n",
      "  \"Comment\": \"The section 'Understanding the Spectrum: From Workflows to Agents' has approximately 329 words, which is below the 400-word target specified in the ar...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 22 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Choosing Your Path - First paragraph\",\n",
      "  \"Comment\": \"The transition from the previous section should be smoother and more explicit, as per `transition_rules`. The current paragraph 'We have defined LLM w...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 23 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Choosing Your Path - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'Now, let's explore their core differences: developer-defined logic versus LLM-driven autonomy in reasoning and action selection.' uses '...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 24 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Image\",\n",
      "  \"Comment\": \"The article guideline specifies 'Attach an image from the research showing the gradient between LLM workflows and AI agents.' The article provides 'Im...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 25 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use LLM Workflows - Strengths\",\n",
      "  \"Comment\": \"The phrase 'Ultimately, using smaller models reduces infrastructure overhead.' contains 'Ultimately,' which is an AI slop word and should be avoided a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 26 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use LLM Workflows - Strengths\",\n",
      "  \"Comment\": \"The guideline mentions 'Ultimately, because we can leverage smaller models, the infrastructure overhead is smaller.' The article says 'Ultimately, usi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 27 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use LLM Workflows - Weaknesses\",\n",
      "  \"Comment\": \"The phrase 'The user experience is rigid as it cannot handle unexpected scenarios.' uses 'rigid', which is an AI slop word. It should be replaced with...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 28 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use AI Agents - Weaknesses\",\n",
      "  \"Comment\": \"The phrase 'The system is more prone to errors.' is too generic and could be rephrased to be more precise, perhaps 'AI agents are more prone to errors...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 29 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use AI Agents - Weaknesses\",\n",
      "  \"Comment\": \"The phrase 'AI agents usually require more LLM calls to understand the user intent and take various actions, which can result again in bigger costs pe...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 30 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use AI Agents - Weaknesses\",\n",
      "  \"Comment\": \"The sentence 'If not designed well, there can be huge security concerns, especially on write operations, where it can delete all our data or send inap...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 31 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - When to Use AI Agents - Weaknesses\",\n",
      "  \"Comment\": \"The phrase 'Ultimately, a huge disadvantage of AI agents is that they are hard to debug and evaluate.' uses 'Ultimately,' which is an AI slop word. It...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 32 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Hybrid Approaches\",\n",
      "  \"Comment\": \"The article guideline explicitly states: 'Use the Cursor (CMD+K, CMD+L, CMD+I) and Perplexity (search, research, deep research) examples from the Andr...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 33 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"citation_guideline_technical_requirements\",\n",
      "  \"Location\": \"Choosing Your Path - Hybrid Approaches\",\n",
      "  \"Comment\": \"The citations `[[3]](https://www.youtube.com/watch?v=kQxr-uOxw2o&t=1s)` are used twice within the same paragraph for different examples (Cursor and Pe...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 34 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Hybrid Approaches\",\n",
      "  \"Comment\": \"The phrase 'The ultimate goal is to accelerate the AI generation-human verification loop.' uses 'ultimate goal', which is an AI slop phrase. It should...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 35 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Choosing Your Path - Hybrid Approaches - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Generate a mermaid to illustrate the AI generation and human verification loop.' The current diagram is present, but th...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 36 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Choosing Your Path - Section Length\",\n",
      "  \"Comment\": \"The section 'Choosing Your Path' has approximately 886 words. This significantly exceeds the 500-word length constraint specified in the article guide...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 37 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'To introduce you to the AI engineering world, we will present common patterns used to build AI agents and LLM workflows.' uses 'we will ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 38 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'We will explain them as if this is the first time you are hearing about them.' uses 'We will explain', which violates the mechanics prof...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 39 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflows - Chaining and Routing - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Draw a mermaid diagram' for Chaining and Routing. The current diagram is present, but the caption 'Image 5: A flowchart...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 40 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflows - Orchestrator-Worker Pattern\",\n",
      "  \"Comment\": \"The phrase 'making a smooth transition between the workflows and agentic world' from the article guideline uses 'smooth transition', which could be co...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 41 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflows - Orchestrator-Worker Pattern - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Draw a mermaid diagram' for Orchestrator-Worker. The current diagram is present, but the caption 'Image 6: A flowchart ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 42 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - LLM Workflows - Evaluator-Optimizer Loop - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Draw a mermaid diagram' for Evaluator-Optimizer Loop. The current diagram is present, but the caption 'Image 7: A flowc...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 43 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'Almost all modern agents in the industry use the ReAct pattern because it has shown the most potential.' contains 'shown the most potent...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 44 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - Long-term memory\",\n",
      "  \"Comment\": \"The description of long-term memory 'This is used to access factual data about the external world, such as public websites or private company database...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 45 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - Long-term memory\",\n",
      "  \"Comment\": \"The article guideline for long-term memory specifies 'This is used to access factual data about the external world (such as public websites from the i...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 46 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Exploring Common Patterns - Core Components of a ReAct AI Agent - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Draw a mermaid diagram showing the dynamics between the core components of an AI agent illustrating the ReAct pattern a...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 47 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Conclusion paragraph\",\n",
      "  \"Comment\": \"The sentence 'The goal of this section is not for you to fully understand how these patterns work. It is to build an intuition about the various LLM w...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 48 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Conclusion paragraph\",\n",
      "  \"Comment\": \"The sentence 'In future lessons, we will delve into all the necessary details of each pattern, including the ReAct pattern in Lessons 7 and 8.' uses '...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 49 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Exploring Common Patterns - Section Length\",\n",
      "  \"Comment\": \"The section 'Exploring Common Patterns' has approximately 490 words. This is below the 550-word target specified in the article guideline. It needs to...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 50 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - First paragraph\",\n",
      "  \"Comment\": \"The phrase 'we will introduce some concrete examples' uses 'we will introduce', which violates the mechanics profile's point of view rules. It should ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 51 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'The reader is not yet aware of any complex topics and knows about LLM workflows or AI agents only what was explained previously in this ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 52 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - First paragraph\",\n",
      "  \"Comment\": \"The sentence 'Explain everything as if speaking to a 7-year-old.' is an instruction to me, not content for the article. It should not appear in the ge...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 53 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Document Summarization and Analysis Workflow by Gemini in Google Workspace - Problem\",\n",
      "  \"Comment\": \"The article guideline for the problem states 'When working in teams and looking for the right document, it can transform into a time-consuming process...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 54 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Document Summarization and Analysis Workflow by Gemini in Google Workspace - Problem\",\n",
      "  \"Comment\": \"The article guideline specifies 'Thus, a quick, embedded summarization can guide us and our search strategies.' The article states 'A quick, embedded ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 55 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Document Summarization and Analysis Workflow by Gemini in Google Workspace - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Create a suggestive mermaid diagram highlighting that this is a workflow.' The current diagram is present, but the capt...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 56 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Problem\",\n",
      "  \"Comment\": \"The article guideline states: 'When working on new code bases, understanding it is a slow process.' The article's phrasing 'Understanding new codebase...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 57 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Problem\",\n",
      "  \"Comment\": \"The article guideline states: 'When working with a new programming language, to write high-quality code, you first need a bootcamp on it before writin...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 58 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Problem\",\n",
      "  \"Comment\": \"The sentence 'That's where a coding assistant helps speed up code writing on existing and new codebases.' uses 'That's where X comes in', which is a b...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 59 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant\",\n",
      "  \"Comment\": \"The article guideline states: 'This is how Gemini CLI works based on our latest research from August 2025.' The article uses 'Here is how Gemini CLI w...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 60 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Use cases\",\n",
      "  \"Comment\": \"The article guideline for use cases includes 'Writing code from scratch, without requiring any coding experience (known as vibe coding).' The article ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 61 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Use cases\",\n",
      "  \"Comment\": \"The article guideline for use cases includes 'Assisting an engineer to write code faster by writing only specific functions or classes.' The article u...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 62 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Use cases\",\n",
      "  \"Comment\": \"The use case 'Support for writing documentation' uses 'Support for', which is an AI slop opening. It should be rephrased to 'Documentation generation'...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 63 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Parallels\",\n",
      "  \"Comment\": \"The article guideline specifies 'To keep the examples light and intuitive, use parallels such as: tools as actions, context as state or working memory...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 64 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Evaluation\",\n",
      "  \"Comment\": \"The sentence 'The agent dynamically evaluates whether the generated code is correct by running or compiling the code.' uses 'dynamically evaluates whe...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 65 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Gemini CLI Coding Assistant - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Create a mermaid diagram showing how the operational loop works.' The current diagram is present, but the caption 'Imag...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 66 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Problem\",\n",
      "  \"Comment\": \"The article guideline states: 'Researching a brand new topic is a scary thing to do.' The article uses 'Researching a brand-new topic can be daunting....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 67 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Problem\",\n",
      "  \"Comment\": \"The article guideline states: 'Most of the time we don't know where to start. What is the right blog, paper, YouTube video or course to start reading?...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 68 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Problem\",\n",
      "  \"Comment\": \"The article guideline states: 'Also, for more trivial questions, most of the time, we don't have the time to dig into too many resources.' The article...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 69 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Problem\",\n",
      "  \"Comment\": \"The sentence 'That's why having a research assistant that quickly scans the internet into a report can provide a huge boost in your learning process o...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 70 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research)\",\n",
      "  \"Comment\": \"The article guideline states: 'This is how Perplexity Deep Research agent works based on our latest research from August 2025.' The article uses 'Here...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 71 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research)\",\n",
      "  \"Comment\": \"The article guideline states: 'Also, specify that the solution is closed-source. Thus, everything that we write here is an assumption based on what we...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 72 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Research Planning & Decomposition\",\n",
      "  \"Comment\": \"The article guideline specifies 'Highlight how the orchestrator leverages the orchestrator-worker pattern to deploy multiple research agents with diff...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 73 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Parallel Information Gathering\",\n",
      "  \"Comment\": \"The article guideline specifies 'For each sub-question, to optimize and move faster in the search space, we run in parallel specialized search agents ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 74 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Parallel Information Gathering\",\n",
      "  \"Comment\": \"The article guideline states 'As the research agents are isolated between each other, the input tokens are smaller, helping the LLM to stay focused.' ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 75 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Analysis & Synthesis\",\n",
      "  \"Comment\": \"The article guideline specifies 'After gathering bulks of sources, each agent validates and scores each source using strategies such as domain credibi...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 76 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Iterative Refinement & Gap Analysis\",\n",
      "  \"Comment\": \"The article guideline specifies 'The orchestrator gathers the information from all the agents which ran in parallel and tries to identify knowledge ga...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 77 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Mermaid Diagram Caption\",\n",
      "  \"Comment\": \"The article guideline asks to 'Create a mermaid diagram showing how the iterative multi-step process works.' The current diagram is present, but the c...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 78 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Perplexity Deep Research (for scientific, financial, social research) - Final paragraph\",\n",
      "  \"Comment\": \"The article guideline specifies 'Highlight how the deep research agent operates as a hybrid between workflows and agents combining structured planning...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 79 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Zooming In on Our Favorite Examples - Section Length\",\n",
      "  \"Comment\": \"The section 'Zooming In on Our Favorite Examples' has approximately 1076 words. This significantly exceeds the 900-word length constraint specified in...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 80 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The phrase 'Now that you understand the spectrum from LLM workflows to AI agents, it is important to recognize that every AI engineer\\u2014whether working ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 81 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The article guideline states: 'These are one of the core decisions that determine whether your AI application succeeds in production or fails spectacu...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 82 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - First paragraph\",\n",
      "  \"Comment\": \"The word 'spectacularly' in 'fails spectacularly' is considered dramatic language and should be avoided according to the terminology profile. The guid...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 83 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Reliability Issues\",\n",
      "  \"Comment\": \"The phrase 'LLM reasoning failures can compound through multi-step processes, leading to unexpected and costly outcomes.' uses 'compound', which is a ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 84 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Context Limits\",\n",
      "  \"Comment\": \"The phrase 'Ensuring consistent output quality across different agent specializations presents a continuous challenge.' uses 'presents a continuous ch...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 85 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"terminology_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Cost-Performance Trap\",\n",
      "  \"Comment\": \"The phrase 'Sophisticated agents can deliver impressive results but cost a fortune per user interaction, making them economically unfeasible for many ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 86 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - The Good News\",\n",
      "  \"Comment\": \"The sentence 'The good news is that these challenges are solvable.' uses 'The good news is that', which is a banned AI slop phrase. It should be rephr...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 87 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Your Path Forward\",\n",
      "  \"Comment\": \"The sentence 'By the end of this course, you will have the knowledge to architect AI systems that are not only powerful but also robust, efficient, an...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 88 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Your Path Forward\",\n",
      "  \"Comment\": \"The article guideline states: 'You'll know when to use workflows versus agents and how to build effective hybrid systems that work in the real world.'...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 89 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"article_guideline\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Transition to Next Lesson\",\n",
      "  \"Comment\": \"The article guideline explicitly states: 'To transition from this lesson to the next, specify what we will learn in future lessons. First mention what...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 90 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"mechanics_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Transition to Next Lesson\",\n",
      "  \"Comment\": \"The sentence 'In our next lesson, we will explore context engineering in detail, showing how to manage the information ecosystem to ensure your LLM ge...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 91 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"structure_profile\",\n",
      "  \"Location\": \"Conclusion: The Challenges of Every AI Engineer - Section Length\",\n",
      "  \"Comment\": \"The section 'Conclusion: The Challenges of Every AI Engineer' has approximately 264 words, which is below the 350-word target specified in the article...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 92 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"citation_guideline_technical_requirements\",\n",
      "  \"Location\": \"References - General\",\n",
      "  \"Comment\": \"The citations within the article are missing the bracketed citation identifiers. For example, '[[1]](https://github.com/google-gemini/gemini-cli/blob/...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 93 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"citation_guideline_technical_requirements\",\n",
      "  \"Location\": \"References - General\",\n",
      "  \"Comment\": \"There is a general issue with citation placement and formatting throughout the article. Many citations are placed incorrectly, often within sentences ...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 94 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"references_rules\",\n",
      "  \"Location\": \"References - General\",\n",
      "  \"Comment\": \"The references list is not formatted correctly according to APA 7th edition and the `references_rules`. Many entries are missing full author names (e....\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m-------------------------------------------- Review 95 --------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"Profile\": \"correction_reference_rules\",\n",
      "  \"Location\": \"References - General\",\n",
      "  \"Comment\": \"The numbering of the images in the article is inconsistent and restarts in some sections, or doesn't follow a continuous sequence for diagrams as dist...\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\"STEP 4: Reviewing Article\", width=100)\n",
    "\n",
    "reviewer_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_reviewer = ArticleReviewer(\n",
    "    to_review=article,\n",
    "    article_guideline=article_guideline,\n",
    "    article_profiles=article_profiles,\n",
    "    model=reviewer_model,\n",
    ")\n",
    "\n",
    "article_reviews = await article_reviewer.ainvoke()\n",
    "\n",
    "print(f\"âœ“ Generated {len(article_reviews.reviews)} reviews\")\n",
    "for i, review in enumerate(article_reviews.reviews, 1):\n",
    "    pretty_print.wrapped(\n",
    "        {\n",
    "            \"Profile\": review.profile,\n",
    "            \"Location\": review.location,\n",
    "            \"Comment\": review.comment[:150] + \"...\" if len(review.comment) > 150 else review.comment,\n",
    "        },\n",
    "        title=f\"Review {i}\",\n",
    "        width=100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Edit the article based on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  STEP 5: Editing Article Based on Reviews\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  This may take 1-2 minutes...\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[93m------------------------------------------ Edited Article ------------------------------------------\u001b[0m\n",
      "  âœ“ Article edited: {len(edited_article.content)\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------ Edited Article (First 3000 chars) ------------------------------------------\u001b[0m\n",
      "  # Workflows vs. Agents: The AI Engineer's Critical Choice\n",
      "### The AI Engineer's Guide to Architectural Choices\n",
      "\n",
      "When building AI applications, engineers face a critical architectural decision early in their development process. Should they create a predictable, step-by-step workflow where they control every action, or should they build an autonomous agent that can think and decide for itself? This choice impacts everything from development time and operational costs to the application's reliability and user experience.\n",
      "\n",
      "Choosing the wrong approach can lead to significant setbacks. You might end up with an overly rigid system that breaks when users deviate from expected patterns, or an unpredictable agent that performs brilliantly 80% of the time but fails drastically when it matters most. This can result in months of wasted development, frustrated users, and frustrated executives who cannot afford to keep the AI agent running as the costs are too high relative to the profits. Across 2024-2025, billion-dollar AI startups have seen their successâ€”or failureâ€”depend mainly on this architectural distinction. The most successful companies and engineering teams understand when to deploy workflows, when to lean on agents, and, importantly, how to combine both approaches well.\n",
      "\n",
      "This architectural decision is paramount. It determines the system's ability to scale, its cost-effectiveness, and its long-term maintainability. An early misstep can lead to expensive refactoring and missed market opportunities. By the end of this lesson, you will understand the key differences and best use cases for LLM workflows and AI agents, allowing you to make architectural decisions confidently. We explore their characteristics, practical examples, and the patterns that define them. This knowledge will equip you to design AI systems that work in the unpredictable real world.\n",
      "\n",
      "## Understanding the Spectrum: From Workflows to Agents\n",
      "\n",
      "To make architectural decisions, you first need a clear understanding of what LLM workflows and AI agents are. At this stage, we focus on their core properties and how they are typically used, rather than diving into deep technical specifics.\n",
      "\n",
      "### LLM Workflows\n",
      "\n",
      "An LLM workflow is a predefined sequence of tasks that often involves LLM calls or other operations, such as reading from or writing data to a database or file system. Developer-written code largely orchestrates these steps, making the entire process explicit and controllable. The process is largely predefined and orchestrated by developer-written code.\n",
      "\n",
      "Workflows are characterized by their deterministic or rule-based paths. This means each step is defined in advance, resulting in predictable execution and explicit control flow. A workflow is like a factory assembly line: each component moves through a series of stations, undergoing specific transformations in a predetermined order. Future lessons explore key workflow concepts like chaining, routing, and orchestrator-worker patterns.\n",
      "\n",
      "<mer\n",
      "\u001b[93m------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print.wrapped(\"STEP 5: Editing Article Based on Reviews\", width=100)\n",
    "pretty_print.wrapped(\"This may take 1-2 minutes...\", width=100)\n",
    "print()\n",
    "\n",
    "editor_model = get_model(SupportedModels.GOOGLE_GEMINI_25_FLASH)\n",
    "article_editor = ArticleWriter(\n",
    "    article_guideline=article_guideline,\n",
    "    research=research,\n",
    "    article_profiles=article_profiles,\n",
    "    media_items=media_items,\n",
    "    article_examples=article_examples,\n",
    "    model=editor_model,\n",
    "    reviews=article_reviews,  # Pass reviews to trigger editing mode\n",
    ")\n",
    "\n",
    "edited_article = await article_editor.ainvoke()\n",
    "\n",
    "pretty_print.wrapped(\"âœ“ Article edited: {len(edited_article.content)\", title=\"Edited Article\", width=100)\n",
    "pretty_print.wrapped(edited_article.content[:3000], title=\"Edited Article (First 3000 chars)\", width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compare original vs edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m---------------------------------- COMPARISON: Original vs Edited ----------------------------------\u001b[0m\n",
      "  Original length: 29,441 characters\n",
      "Edited length: 30,860 characters\n",
      "Difference: +1,419 characters\n",
      "\n",
      "Number of reviews addressed: 95\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "comparison_text = f\"\"\"Original length: {len(article.content):,} characters\n",
    "Edited length: {len(edited_article.content):,} characters\n",
    "Difference: {len(edited_article.content) - len(article.content):+,} characters\n",
    "\n",
    "Number of reviews addressed: {len(article_reviews.reviews)}\"\"\"\n",
    "\n",
    "pretty_print.wrapped(comparison_text, title=\"COMPARISON: Original vs Edited\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Save the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------- First Draft -------------------------------------------\u001b[0m\n",
      "  âœ“ Saved first draft to: inputs/tests/02_sample_medium/article_draft.md\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m------------------------------------------ Edited Version ------------------------------------------\u001b[0m\n",
      "  âœ“ Saved edited version to: inputs/tests/02_sample_medium/article_edited.md\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.renderers import MarkdownArticleRenderer\n",
    "\n",
    "renderer = MarkdownArticleRenderer()\n",
    "\n",
    "# Save first draft\n",
    "first_draft_path = SAMPLE_DIR / \"article_draft.md\"\n",
    "renderer.render(article, output_uri=first_draft_path)\n",
    "\n",
    "# Save edited version\n",
    "edited_path = SAMPLE_DIR / \"article_edited.md\"\n",
    "renderer.render(edited_article, output_uri=edited_path)\n",
    "\n",
    "pretty_print.wrapped(f\"âœ“ Saved first draft to: {first_draft_path}\", title=\"First Draft\", width=100)\n",
    "pretty_print.wrapped(f\"âœ“ Saved edited version to: {edited_path}\", title=\"Edited Version\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can you easily check what actually changed after the review?\n",
    "\n",
    "As you can see in the comparison above, there is a difference in characters between the two files. But how can you actually see what has changed?\n",
    "\n",
    "To do so, go over the reviews, and for each review, you can locate the change using the `location` field, while you can understand the intent of the review based on the `profile` and `comment` fields. \n",
    "\n",
    "Next, open both files from the paths listed above and try to spot the difference by looking at the first 10 reviews. \n",
    "\n",
    "To streamline this process, we recommend using a diff tool, such as the one in your IDE or one you find online.\n",
    "\n",
    "After we integrate Brown with Cursor by serving it as an MCP server, all of this will be automated! For now, we cannot add any diffs on our end because every time you run the reviews-edit step, the results will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Centralizing Our App Configuration\n",
    "\n",
    "Before gluing everything together into a LangGraph workflow, let's explore our centralized configuration system. This allows us to configure the entire application from a single YAML file.\n",
    "\n",
    "### Why Centralized Configuration?\n",
    "\n",
    "As our system grows more complex, we need:\n",
    "\n",
    "- **Single source of truth**: One file that controls everything\n",
    "- **Easy experimentation**: Change models, parameters without touching code\n",
    "- **Environment-specific configs**: Different settings for dev/prod\n",
    "- **Version control**: Track configuration changes over time\n",
    "\n",
    "The Brown agent uses a Pydantic-based configuration system that validates all settings at load time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The AppConfig Class Structure\n",
    "\n",
    "From `brown.config_app`, here's the configuration class hierarchy:\n",
    "\n",
    "**1. Context Configuration:**\n",
    "```python\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, DirectoryPath, Field\n",
    "from typing import Literal, Annotated\n",
    "\n",
    "\n",
    "class Context(BaseModel):\n",
    "    # Article guideline\n",
    "    article_guideline_loader: Literal[\"markdown\"]\n",
    "    article_guideline_uri: Path\n",
    "\n",
    "    # Research\n",
    "    research_loader: Literal[\"markdown\"]\n",
    "    research_uri: Path\n",
    "\n",
    "    # Article\n",
    "    article_loader: Literal[\"markdown\"]\n",
    "    article_renderer: Literal[\"markdown\"]\n",
    "    article_uri: Path\n",
    "\n",
    "    # Profiles\n",
    "    profiles_loader: Literal[\"markdown\"]\n",
    "    profiles_uri: Annotated[DirectoryPath, Field(description=\"URI to profiles directory\")]\n",
    "    character_profile: str\n",
    "\n",
    "    # Examples\n",
    "    examples_loader: Literal[\"markdown\"]\n",
    "    examples_uri: Annotated[DirectoryPath, Field(description=\"URI to examples directory\")]\n",
    "\n",
    "    def build_article_uri(self, iteration: int) -> Path:\n",
    "        return self.article_uri.with_stem(f\"{self.article_uri.stem}_{iteration:03d}\")\n",
    "```\n",
    "\n",
    "This defines all the paths and loaders for different content types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Node and Tool Configuration:**\n",
    "```python\n",
    "from brown.models.config import ModelConfig, SupportedModels\n",
    "\n",
    "\n",
    "class ToolConfig(BaseModel):\n",
    "    name: str\n",
    "    model_id: SupportedModels\n",
    "    config: ModelConfig\n",
    "\n",
    "\n",
    "class NodeConfig(BaseModel):\n",
    "    model_id: SupportedModels\n",
    "    config: ModelConfig\n",
    "    tools: dict[str, ToolConfig]\n",
    "```\n",
    "\n",
    "Each node can have its own model and configuration. Tools (like diagram generators) have their own configs too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Memory Configuration:**\n",
    "```python\n",
    "class Memory(BaseModel):\n",
    "    checkpointer: Literal[\"in_memory\", \"sqlite\"]\n",
    "```\n",
    "\n",
    "Controls which checkpointing strategy to use for workflow state persistence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The Main AppConfig Class:**\n",
    "```python\n",
    "from annotated_types import Ge\n",
    "\n",
    "\n",
    "class AppConfig(BaseModel):\n",
    "    context: Context\n",
    "    memory: Memory\n",
    "    \n",
    "    num_reviews: Annotated[int, Ge(1), Field(\n",
    "        description=\"The number of reviews to perform while generating the article\"\n",
    "    )]\n",
    "    nodes: dict[str, NodeConfig]\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, file_path: Path) -> \"AppConfig\":\n",
    "        \"\"\"Load configuration from a YAML file.\"\"\"\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"Configuration file not found: {file_path}\")\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        return cls(**data)\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- `num_reviews`: How many review-edit iterations to run\n",
    "- `nodes`: Configuration for each workflow node\n",
    "- `from_yaml()`: Load configuration from YAML file\n",
    "- Full Pydantic validation ensures type safety\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Configuration File\n",
    "\n",
    "Let's look at an actual configuration file from `configs/course.yaml`:\n",
    "\n",
    "```yaml\n",
    "context:\n",
    "  article_guideline_loader: \"markdown\"\n",
    "  article_guideline_uri: \"article_guideline.md\"\n",
    "  research_loader: \"markdown\"\n",
    "  research_uri: \"research.md\"\n",
    "  article_loader: \"markdown\"\n",
    "  article_renderer: \"markdown\"\n",
    "  article_uri: \"article.md\"\n",
    "  profiles_loader: \"markdown\"\n",
    "  profiles_uri: \"inputs/profiles\"\n",
    "  character_profile: \"paul_iusztin.md\"\n",
    "  examples_loader: \"markdown\"\n",
    "  examples_uri: \"inputs/examples/course_lessons\"\n",
    "\n",
    "memory:\n",
    "  checkpointer: \"in_memory\"\n",
    "\n",
    "num_reviews: 2\n",
    "\n",
    "nodes:\n",
    "  generate_media_items:\n",
    "    model_id: \"google_genai:gemini-2.5-flash\"\n",
    "    model_config:\n",
    "      temperature: 0.0\n",
    "      include_thoughts: false\n",
    "      thinking_budget: null\n",
    "    tools:\n",
    "      mermaid_diagram_generator:\n",
    "        model_id: \"google_genai:gemini-2.5-flash\"\n",
    "        config:\n",
    "          temperature: 0.0\n",
    "          include_thoughts: false\n",
    "\n",
    "  write_article:\n",
    "    model_id: \"google_genai:gemini-2.5-pro\"\n",
    "    model_config:\n",
    "      temperature: 0.7\n",
    "      include_thoughts: false\n",
    "\n",
    "  review_article:\n",
    "    model_id: \"google_genai:gemini-2.5-pro\"\n",
    "    model_config:\n",
    "      temperature: 0.0\n",
    "      include_thoughts: false\n",
    "\n",
    "  edit_article:\n",
    "    model_id: \"google_genai:gemini-2.5-pro\"\n",
    "    model_config:\n",
    "      temperature: 0.1\n",
    "      include_thoughts: false\n",
    "```\n",
    "\n",
    "**Configuration Highlights:**\n",
    "\n",
    "- **Media generation**: Uses fast Flash model with 0 temperature (deterministic)\n",
    "- **Article writing**: Uses Pro model with higher temperature (0.7) for creativity\n",
    "- **Reviewing**: Uses Pro model with 0 temperature (strict adherence to rules)\n",
    "- **Editing**: Uses Pro model with low temperature (0.1) for focused changes\n",
    "- **2 review iterations**: Runs the review-edit loop twice\n",
    "\n",
    "This fine-grained control lets you optimize for quality, speed, and cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Using the Configuration\n",
    "\n",
    "Let's load a configuration file and examine it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m------------------------------------------ Configuration ------------------------------------------\u001b[0m\n",
      "  \n",
      "Configuration loaded successfully!\n",
      "Num review iterations: 2\n",
      "Memory checkpointer: in_memory\n",
      "Character profile: paul_iusztin.md\n",
      "\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------- Configured nodes -----------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"generate_media_items\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.0,\n",
      "    \"Tools\": [\n",
      "      \"mermaid_diagram_generator\"\n",
      "    ]\n",
      "  },\n",
      "  \"write_article\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.7\n",
      "  },\n",
      "  \"review_article\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.0\n",
      "  },\n",
      "  \"edit_article\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.1\n",
      "  },\n",
      "  \"review_selected_text\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.0\n",
      "  },\n",
      "  \"edit_selected_text\": {\n",
      "    \"Model\": \"google_genai:gemini-2.5-flash\",\n",
      "    \"Temperature\": 0.1\n",
      "  }\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from brown.config_app import AppConfig\n",
    "\n",
    "# Load configuration from YAML\n",
    "config_path = CONFIGS_DIR / \"course.yaml\"\n",
    "app_config = AppConfig.from_yaml(config_path)\n",
    "\n",
    "text = f\"\"\"\n",
    "Configuration loaded successfully!\n",
    "Num review iterations: {app_config.num_reviews}\n",
    "Memory checkpointer: {app_config.memory.checkpointer}\n",
    "Character profile: {app_config.context.character_profile}\n",
    "\"\"\"\n",
    "pretty_print.wrapped(text, title=\"Configuration\", width=100)\n",
    "\n",
    "node_info = {}\n",
    "for node_name, node_config in app_config.nodes.items():\n",
    "    node_dict = {\n",
    "        \"Model\": node_config.model_id,\n",
    "        \"Temperature\": node_config.config.temperature,\n",
    "    }\n",
    "    if node_config.tools:\n",
    "        node_dict[\"Tools\"] = list(node_config.tools.keys())\n",
    "    node_info[node_name] = node_dict\n",
    "pretty_print.wrapped(node_info, title=\"Configured nodes\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of This Approach\n",
    "\n",
    "1. **Experimentation**: Change models/temperatures without editing code\n",
    "2. **Cost optimization**: Use cheaper models for simple tasks\n",
    "3. **Quality tuning**: Adjust temperatures per task\n",
    "4. **Environment flexibility**: Different configs for dev/staging/prod\n",
    "5. **Reproducibility**: Version control your configurations\n",
    "6. **Global overview**: You can see the whole setup in a glance\n",
    "\n",
    "This configuration-driven approach makes the system highly flexible and easy to iterate on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Glueing Everything Into Our LangGraph Workflow\n",
    "\n",
    "Now let's explore how everything is glued together into a robust LangGraph workflow. The complete workflow is in `brown.workflows.generate_article`.\n",
    "\n",
    "### Workflow Architecture\n",
    "\n",
    "The workflow uses LangGraph's Function API to orchestrate the complete article generation process. Let's break down the key components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Workflow\n",
    "\n",
    "**1. The Build Function:**\n",
    "```python\n",
    "from langgraph.func import entrypoint\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "\n",
    "\n",
    "def build_generate_article_workflow(checkpointer: BaseCheckpointSaver):\n",
    "    \"\"\"Create a generate article workflow with optional checkpointer.\n",
    "    \n",
    "    Args:\n",
    "        checkpointer: Checkpointer to use for workflow state persistence\n",
    "        \n",
    "    Returns:\n",
    "        Configured workflow entrypoint\n",
    "    \"\"\"\n",
    "    return entrypoint(checkpointer=checkpointer)(_generate_article_workflow)\n",
    "```\n",
    "\n",
    "**Why This Pattern?**\n",
    "\n",
    "We could directly decorate `_generate_article_workflow` with `@entrypoint`, but this builder function allows us to:\n",
    "\n",
    "1. **Inject dependencies at runtime**: Pass the checkpointer when building the workflow\n",
    "2. **Follow clean architecture**: Separate infrastructure (checkpointer) from business logic\n",
    "3. **Enable testing**: Easily swap checkpointers for different environments\n",
    "\n",
    "This pattern makes sense when you see how it's called in the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. The Workflow Input:**\n",
    "\n",
    "```python\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class GenerateArticleInput(TypedDict):\n",
    "    dir_path: Path\n",
    "```\n",
    "\n",
    "Simple typed input containing just the directory path where all resources are located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. The Main Workflow Function:**\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.config import get_stream_writer, RunnableConfig\n",
    "\n",
    "\n",
    "async def _generate_article_workflow(inputs: GenerateArticleInput, config: RunnableConfig) -> str:\n",
    "    dir_path = inputs[\"dir_path\"]\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    writer = get_stream_writer()\n",
    "    \n",
    "    # Step 1: Load context\n",
    "    writer(WorkflowProgress(progress=0, message=\"Loading context\").model_dump(mode=\"json\"))\n",
    "    context = {}\n",
    "    loaders = build_loaders(app_config)\n",
    "    for context_name in [\"article_guideline\", \"research\", \"profiles\", \"examples\"]:\n",
    "        loader = cast(Loader, loaders[context_name])\n",
    "        context[context_name] = loader.load(working_uri=dir_path)\n",
    "    writer(WorkflowProgress(progress=2, message=\"Loaded context\").model_dump(mode=\"json\"))\n",
    "    \n",
    "    # Step 2: Generate media items\n",
    "    writer(WorkflowProgress(progress=3, message=\"Generating media items\").model_dump(mode=\"json\"))\n",
    "    media_items = await generate_media_items(context[\"article_guideline\"], context[\"research\"])\n",
    "    writer(WorkflowProgress(progress=10, message=\"Generated media items\").model_dump(mode=\"json\"))\n",
    "    \n",
    "    # Step 3: Write article\n",
    "    writer(WorkflowProgress(progress=15, message=\"Writing article\").model_dump(mode=\"json\"))\n",
    "    article = await write_article(...) \n",
    "    writer(WorkflowProgress(progress=20, message=\"Written raw article\").model_dump(mode=\"json\"))\n",
    "    \n",
    "    # Save iteration 0\n",
    "    article_path = dir_path / app_config.context.build_article_uri(0)\n",
    "    article_renderer = build_article_renderer(app_config)\n",
    "    article_renderer.render(article, output_uri=article_path)\n",
    "    \n",
    "    # Steps 4-5: Review and edit loop\n",
    "    for i in range(1, app_config.num_reviews + 1):\n",
    "        # Review\n",
    "        reviews = await generate_reviews(article, context[\"article_guideline\"], context[\"profiles\"])\n",
    "        \n",
    "        # Edit\n",
    "        article = await edit_based_on_reviews(...)\n",
    "        \n",
    "        # Save iteration i\n",
    "        article_path = dir_path / app_config.context.build_article_uri(i)\n",
    "        article_renderer.render(article, output_uri=article_path)\n",
    "    \n",
    "    # Save final article\n",
    "    article_path = dir_path / app_config.context.article_uri\n",
    "    article_renderer.render(article, output_uri=article_path)\n",
    "    \n",
    "    return f\"Final article rendered to `{article_path}`.\"\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "1. **Progress reporting**: Uses `get_stream_writer()` to send progress updates\n",
    "2. **Iterative refinement**: Loops through review-edit cycles\n",
    "3. **Version saving**: Saves each iteration for comparison\n",
    "4. **Configuration-driven**: Uses `app_config` for all settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The Task Functions with Retry Policies:**\n",
    "\n",
    "Each major step is wrapped in a `@task` decorator with retry policies:\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.func import task\n",
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "retry_policy = RetryPolicy(max_attempts=3, retry_on=Exception)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_media_items(article_guideline: ArticleGuideline, research: Research) -> MediaItems:\n",
    "    writer = get_stream_writer()\n",
    "    \n",
    "    model, toolkit = build_model(app_config, node=\"generate_media_items\")\n",
    "    media_generator_orchestrator = MediaGeneratorOrchestrator(...)\n",
    "    media_items_to_generate_jobs = await media_generator_orchestrator.ainvoke()\n",
    "    \n",
    "    # Generate media items in parallel\n",
    "    coroutines = [tool.ainvoke(job[\"args\"]) for job in media_items_to_generate_jobs]\n",
    "    media_items = await asyncio.gather(*coroutines)\n",
    "    \n",
    "    return MediaItems.build(media_items)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def write_article(...) -> Article:\n",
    "    model, _ = build_model(app_config, node=\"write_article\")\n",
    "    article_writer = ArticleWriter(...)\n",
    "    article = await article_writer.ainvoke()\n",
    "    return cast(Article, article)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def generate_reviews(...) -> ArticleReviews:\n",
    "    model, _ = build_model(app_config, node=\"review_article\")\n",
    "    article_reviewer = ArticleReviewer(...)\n",
    "    reviews = await article_reviewer.ainvoke()\n",
    "    return cast(ArticleReviews, reviews)\n",
    "\n",
    "\n",
    "@task(retry_policy=retry_policy)\n",
    "async def edit_based_on_reviews(...) -> Article:\n",
    "    model, _ = build_model(app_config, node=\"edit_article\")\n",
    "    article_writer = ArticleWriter(..., reviews=reviews)\n",
    "    article = await article_writer.ainvoke()\n",
    "    return cast(Article, article)\n",
    "```\n",
    "\n",
    "**Why Retry Policies?**\n",
    "\n",
    "- **Resilience**: API failures, rate limits, network issues happen\n",
    "- **Automatic recovery**: Retry failed steps without manual intervention\n",
    "- **Task-level granularity**: Only retry the failed step, not the entire workflow\n",
    "- **Production-ready**: Makes the system robust for real-world use\n",
    "\n",
    "Having each step as a separate task with single responsibility makes retry policies extremely effective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Adding Short-Term Memory\n",
    "\n",
    "Before running the complete workflow, let's understand the checkpointing system that provides workflow state persistence.\n",
    "\n",
    "### Why Checkpointing?\n",
    "\n",
    "Checkpointing serves several purposes:\n",
    "\n",
    "1. **Resume from failure**: If a workflow crashes, resume from the last checkpoint. For example, resume from the last `generate_reviews` step that crashed.\n",
    "2. **State inspection**: Examine workflow state at any point\n",
    "3. **Debugging**: Step through workflow execution\n",
    "4. **Human-in-the-loop**: Pause for human input, then resume\n",
    "\n",
    "For our use case, checkpointing enables the review-edit iterations to maintain state between steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InMemory Checkpointer\n",
    "\n",
    "From `brown.memory`, we have a simple in-memory checkpointer factory:\n",
    "\n",
    "\n",
    "```python\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import AsyncIterator\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def build_in_memory_checkpointer() -> AsyncIterator[InMemorySaver]:\n",
    "    \"\"\"Build an in-memory checkpointer.\n",
    "    \n",
    "    Returns an async context manager that yields an InMemorySaver.\n",
    "    \n",
    "    Yields:\n",
    "        InMemorySaver instance\n",
    "    \"\"\"\n",
    "    yield InMemorySaver()\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "\n",
    "- **Ephemeral**: State lost when process ends\n",
    "- **Development-friendly**: Perfect for testing and iteration\n",
    "- **No persistence**: Not suitable for production long-running workflows\n",
    "\n",
    "**When to use**: Development, testing, short-lived workflows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite Checkpointers\n",
    "\n",
    "Also in `brown.memory`, we have another factory method that builds the SQLite checkpouinter in a similar fashion:\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "\n",
    "@asynccontextmanager\n",
    "async def build_sqlite_checkpointer(\n",
    "    uri: Path = Path(\"outputs\") / \"short_term_memory\" / \"checkpoints.sqlite\",\n",
    ") -> AsyncIterator[AsyncSqliteSaver]:\n",
    "    \"\"\"Build an async SQLite checkpointer.\n",
    "\n",
    "    Returns an async context manager that yields an AsyncSqliteSaver.\n",
    "    This must be used with `async with` in an async context.\n",
    "\n",
    "    Args:\n",
    "        uri: Path to the SQLite database file. Defaults to outputs/short_term_memory/checkpoints.sqlite.\n",
    "            The parent directory will be created if it doesn't exist.\n",
    "\n",
    "    Yields:\n",
    "        AsyncSqliteSaver instance configured with the given database path\n",
    "\n",
    "    Example:\n",
    "        from pathlib import Path\n",
    "\n",
    "        async with build_sqlite_checkpointer(Path(\"checkpoints.db\")) as checkpointer:\n",
    "            workflow = build_generate_article_workflow(checkpointer=checkpointer)\n",
    "            await workflow.ainvoke(...)\n",
    "    \"\"\"\n",
    "\n",
    "    uri.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    async with AsyncSqliteSaver.from_conn_string(str(uri)) as checkpointer:\n",
    "        yield checkpointer\n",
    "```\n",
    "\n",
    "**Characteristics:**\n",
    "\n",
    "- **Durable**: State stored on disk between processes\n",
    "- **Development-friendly**: Easy to set up, as the database is just a file\n",
    "\n",
    "**When to use**: SQLite can get you up to dozens of users before scaling. Thus, it's extremely powerful when first deploying your application, as it avoids setting up a database such as Postgres. It's also super easy to use when testing locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Running the New Writing Workflow\n",
    "\n",
    "Now let's run the complete workflow with LangGraph integration! This brings together everything we've learned.\n",
    "\n",
    "> [!NOTE]\n",
    "> Remember that the number of articles reviewed is controlled by the `num_reviews` attribute from the config. By default, we set it to `num_reviews=2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  COMPLETE WORKFLOW WITH LANGGRAPH\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "from brown.memory import build_in_memory_checkpointer\n",
    "from brown.workflows.generate_article import GenerateArticleInput, build_generate_article_workflow\n",
    "\n",
    "pretty_print.wrapped(\"COMPLETE WORKFLOW WITH LANGGRAPH\", width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Building workflow...\n",
      "2. Configuring workflow...\n",
      "   âœ“ Thread ID: 117e4a32-7f19-471c-a549-27e13c522a64\n",
      "3. Running workflow...\n",
      "   This will take several minutes...\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 0,\n",
      "  \"message\": \"Loading context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 2,\n",
      "  \"message\": \"Loaded context\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 3,\n",
      "  \"message\": \"Genererating media items\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  Found 9 media items to generate using the following tool configurations:\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 1: mermaid_diagram_generator_tool - A flowchart illustrating a simple LLM workflow. It should start with a '_start_' node, proceed to a 'tool_calling_llm' node, then to a 'tools' node representing external operations, and finally conclude with an '_end_' node. This diagram should visually represent a predefined, sequential process where an LLM orchestrates tasks and interacts with external tools or data operations.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 2: mermaid_diagram_generator_tool - A flowchart illustrating the AI generation and human verification loop. The loop should start with 'AI Generation', lead to 'Human Review/Verification' (with options to 'Accept' or 'Reject'), and then loop back to 'AI Generation' if rejected, or proceed to 'Task Completion' if accepted. The diagram should emphasize the iterative nature and the human-in-the-loop aspect.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 3: mermaid_diagram_generator_tool - A flowchart illustrating an LLM workflow with chaining and routing. It should start with an 'Input' node, lead to an 'LLM Call Router' node that dynamically routes to different 'Specialized LLM Call' nodes (e.g., 'LLM Call A', 'LLM Call B', 'LLM Call C') based on conditions. Each specialized LLM call should then chain to subsequent 'Processing Step' nodes, and finally converge to an 'Output' node.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 4: mermaid_diagram_generator_tool - A flowchart illustrating the Orchestrator-Worker LLM pattern. It should start with a 'User Query' node, leading to an 'Orchestrator LLM' node. The Orchestrator LLM should then dynamically delegate tasks to multiple 'Worker LLM' nodes (e.g., 'Worker LLM 1', 'Worker LLM 2') which might interact with 'Tools/Data Sources'. The results from the Worker LLMs should then be sent back to the Orchestrator LLM for 'Synthesis' into a 'Final Answer'.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 5: mermaid_diagram_generator_tool - A flowchart illustrating the Evaluator-Optimizer loop pattern. It should start with an 'Initial LLM Output' node, leading to an 'Evaluator LLM' node. The Evaluator LLM should generate 'Feedback/Error Report', which then loops back to the 'Initial LLM Output' (or a 'Generator LLM' that produces the initial output) for 'Refinement/Correction'. This loop should continue until the output meets the desired criteria, leading to a 'Final Output' node.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 6: mermaid_diagram_generator_tool - A flowchart illustrating the high-level dynamics of a ReAct AI agent. It should start with a 'Task/Goal' node, leading to an 'Agent (LLM)' node. The Agent should perform 'Reasoning' (deciding what to do), then 'Act' (calling 'Tools' or interacting with 'External Environment'). The 'Tools' or 'External Environment' should provide 'Observation/Feedback' back to the 'Agent (LLM)', which then updates its 'Memory' (Short-term and Long-term) and continues the 'Reasoning' process in a loop until the 'Task Completed' node is reached.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 7: mermaid_diagram_generator_tool - A flowchart illustrating a document summarization and analysis workflow. It should start with 'Read Document', proceed sequentially through 'Summarize (LLM Call)', 'Extract Key Points (LLM Call)', 'Save Results to Database', and finally 'Show Results to User'. This diagram should clearly represent a linear, predefined workflow.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 8: mermaid_diagram_generator_tool - A flowchart illustrating the operational loop of the Gemini CLI coding assistant, based on the ReAct pattern. It should start with 'User Input/Task', leading to 'Context Gathering' (loading directory, tools, history). Then, 'LLM Reasoning' (Gemini analyzes input, plans actions). Next, 'Human in the Loop' (user validates plan). If approved, 'Tool Execution' (file operations, web requests, code generation). After execution, 'Evaluation' (running/compiling code). Finally, 'Loop Decision' (agent determines if task is complete or repeats reasoning/acting). This forms a continuous loop until task completion.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "    â€¢ Tool 9: mermaid_diagram_generator_tool - A flowchart illustrating the iterative multi-step process of Perplexity's Deep Research agent, highlighting its hybrid nature. It should start with 'Research Question', leading to 'Research Planning & Decomposition' (Orchestrator breaks into sub-questions). Then, 'Parallel Information Gathering' (multiple 'Specialized Search Agents' use 'Tools' like web search/document retrieval). Next, 'Analysis & Synthesis' (agents validate, score, rank, summarize sources). Followed by 'Iterative Refinement & Gap Analysis' (Orchestrator identifies gaps, generates follow-up queries, looping back to planning if needed). Finally, 'Report Generation' (Orchestrator compiles final report with citations).\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  Executing 9 media item generation jobs in parallel.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  Generated 9 media items.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 10,\n",
      "  \"message\": \"Generated media items\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 15,\n",
      "  \"message\": \"Writing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 20,\n",
      "  \"message\": \"Written raw article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 25,\n",
      "  \"message\": \"Rendered raw article to `inputs/tests/02_sample_medium/article_000.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 37,\n",
      "  \"message\": \"Rewiewing article [Iteration 1 / 2]\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 37,\n",
      "  \"message\": \"Generated reviews\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 50,\n",
      "  \"message\": \"Editing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 50,\n",
      "  \"message\": \"Edited article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 62,\n",
      "  \"message\": \"Rendered article to `inputs/tests/02_sample_medium/article_001.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 75,\n",
      "  \"message\": \"Rewiewing article [Iteration 2 / 2]\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 75,\n",
      "  \"message\": \"Generated reviews\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 87,\n",
      "  \"message\": \"Editing article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 87,\n",
      "  \"message\": \"Edited article\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 99,\n",
      "  \"message\": \"Rendered article to `inputs/tests/02_sample_medium/article_002.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Event ----------------------------------------------\u001b[0m\n",
      "  {\n",
      "  \"progress\": 100,\n",
      "  \"message\": \"Final article rendered to `inputs/tests/02_sample_medium/article.md`\"\n",
      "}\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m---------------------------------------------- Output ----------------------------------------------\u001b[0m\n",
      "  Final article rendered to`inputs/tests/02_sample_medium/article.md`.\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "  WORKFLOW COMPLETE - Check `inputs/tests/02_sample_medium` for generated articles\n",
      "\u001b[93m----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async with build_in_memory_checkpointer() as checkpointer:\n",
    "    print(\"1. Building workflow...\")\n",
    "    workflow = build_generate_article_workflow(checkpointer=checkpointer)\n",
    "\n",
    "    print(\"2. Configuring workflow...\")\n",
    "    thread_id = str(uuid.uuid4())\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    print(f\"   âœ“ Thread ID: {thread_id}\")\n",
    "\n",
    "    print(\"3. Running workflow...\")\n",
    "    print(\"   This will take several minutes...\")\n",
    "\n",
    "    inputs = GenerateArticleInput(dir_path=SAMPLE_DIR)\n",
    "\n",
    "    async for event in workflow.astream(inputs, config=config, stream_mode=[\"custom\", \"values\"]):\n",
    "        event_type, event_data = event\n",
    "        if event_type == \"custom\":\n",
    "            pretty_print.wrapped(event_data, title=\"Event\")\n",
    "        elif event_type == \"values\":\n",
    "            pretty_print.wrapped(event_data, title=\"Output\")\n",
    "\n",
    "pretty_print.wrapped(f\"WORKFLOW COMPLETE - Check `{SAMPLE_DIR}` for generated articles\", width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!WARNING]\n",
    "> If the workflows fail due to API limits, timeouts or take more than 15 minutes to run, that's totally normal. Just retry the workflow. If after retrying it still fails, wait for a bit and retry again. Unfortunately, these are the downsides of working with APIs rather than your own self-hosted open-source LLMs, which you control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the generated articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated article files:\n",
      "  - article.md: 18,869 bytes\n",
      "  - article_000.md: 24,835 bytes\n",
      "  - article_001.md: 26,277 bytes\n",
      "  - article_002.md: 18,869 bytes\n",
      "  - article_draft.md: 29,451 bytes\n",
      "  - article_edited.md: 30,870 bytes\n",
      "  - article_guideline.md: 22,858 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerated article files:\")\n",
    "article_files = sorted(SAMPLE_DIR.glob(\"article*.md\"))\n",
    "for article_file in article_files:\n",
    "    size = article_file.stat().st_size\n",
    "    print(f\"  - {article_file.name}: {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the articles are available within the following directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('inputs/tests/02_sample_medium')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend opening up each checkpoint and seeing how the article evolved after each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "Let's break down the workflow execution:\n",
    "\n",
    "**Infrastructure Setup:**\n",
    "1. Created an in-memory checkpointer for state persistence\n",
    "2. Built the workflow by injecting the checkpointer\n",
    "3. Generated a unique thread ID for this workflow run\n",
    "\n",
    "**Workflow Execution:**\n",
    "1. **Loaded Context** (Progress: 0-2%): All guidelines, research, profiles, examples\n",
    "2. **Generated Media** (Progress: 3-10%): Orchestrator identified and delegated media generation\n",
    "3. **Wrote Article** (Progress: 15-20%): ArticleWriter created first draft\n",
    "4. **Review-Edit Loop** (Progress: 25-99%): For each iteration:\n",
    "   - ArticleReviewer analyzed the article\n",
    "   - ArticleWriter edited based on reviews\n",
    "   - Saved intermediate version\n",
    "5. **Final Save** (Progress: 100%): Saved the final refined article\n",
    "\n",
    "**Key LangGraph Features Used:**\n",
    "- **Checkpointing**: State persistence between steps\n",
    "- **Streaming**: Real-time progress updates\n",
    "- **Retry policies**: Automatic recovery from failures\n",
    "- **Tasks**: Composable, retryable workflow steps\n",
    "- **Configuration**: Thread-based workflow isolation\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "Saved to the sample input directory:\n",
    "\n",
    "- `article_000.md`: Initial draft\n",
    "- `article_001.md`: After first review-edit iteration\n",
    "- `article_002.md`: After second review-edit iteration (if num_reviews=2).\n",
    "- `article.md`: Final refined article. It's the same with `article_002.md`.\n",
    "\n",
    "This demonstrates a production-ready implementation of the evaluator-optimizer pattern!\n",
    "\n",
    "We recommend opening up each checkpoint and seeing how the article evolved after each iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Future Steps\n",
    "\n",
    "Congratulations! You've learned how to implement the evaluator-optimizer pattern and integrate it into a production-ready workflow.\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "**1. The Evaluator-Optimizer Pattern:**\n",
    "- Evaluator (ArticleReviewer) identifies issues against requirements\n",
    "- Optimizer (ArticleWriter) fixes issues based on feedback\n",
    "- Iterative refinement gradually improves quality\n",
    "- Transparent, debuggable, and improvable process\n",
    "\n",
    "**2. Centralized Configuration:**\n",
    "- Single YAML file controls everything\n",
    "- Per-node model and parameter configuration\n",
    "- Easy experimentation and optimization\n",
    "- Type-safe with Pydantic validation\n",
    "\n",
    "**3. LangGraph Integration:**\n",
    "- Workflow orchestration with Function API\n",
    "- Task-based architecture with retry policies\n",
    "- Checkpointing for state persistence\n",
    "- Streaming for progress reporting\n",
    "- Production-ready error handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for Extension\n",
    "\n",
    "Now that you understand the system, here are ways to extend it:\n",
    "\n",
    "**1. Different AI Frameworks:**\n",
    "\n",
    "Replace LangGraph Function API with LangGraph Graph API. Try PydanticAI or other frameworks. The clean architecture makes swapping easy.\n",
    "\n",
    "**2. Improve the Reviewer:**\n",
    "\n",
    "Play around with the reviewer, get a feeling of how it extract the reviews from the profiles and tweak either the profiles or the reviewer for better results.\n",
    "\n",
    "**3. Modify the configuration:**\n",
    "\n",
    "Change models, temperatures, num_reviews from the `configs/course.yaml` file and see how the output of the article changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next in the Course\n",
    "\n",
    "In **Lesson 24: Human-in-the-Loop**, we'll explore:\n",
    "\n",
    "- Adding two new workflows for iteratively editing the whole article or just a selected piece of text.\n",
    "- Properly add humans in the loop between the generated article and future edit iterations.\n",
    "- Expose the workflows as MCP tools.\n",
    "\n",
    "You'll see why having a fixed number of review iterations (rather than scoring until \"good enough\") makes perfect sense when humans are in the loop.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Brown Package**: Explore `lessons/writing_workflow`\n",
    "- **Configuration Examples**: Check `configs/` for different configurations\n",
    "- **Test Data**: Use `inputs/tests/` for additional testing scenarios\n",
    "- **Writing Profiles**: Check `inputs/profiles/` for more profile templates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
